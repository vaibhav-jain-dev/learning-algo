# DSAlgo Learn Platform - Docker Compose
# Fast Code Runner with persistent kernel pools
# Memory limit: 2GB total
#
# FAST BUILD: Uses BuildKit for parallel builds and caching
# Just run: docker compose up -d --build
#
# To enable BuildKit permanently (one-time setup):
#   echo '{"features":{"buildkit":true}}' | sudo tee /etc/docker/daemon.json
#   sudo systemctl restart docker

networks:
  dsalgo-learn-network:
    name: dsalgo-learn-network
    driver: bridge

volumes:
  dsalgo-learn-go-cache:
    name: dsalgo-learn-go-cache
  dsalgo-learn-state:
    name: dsalgo-learn-state
  dsalgo-learn-postgres-data:
    name: dsalgo-learn-postgres-data
  dsalgo-learn-elasticsearch-data:
    name: dsalgo-learn-elasticsearch-data
  dsalgo-learn-redis-data:
    name: dsalgo-learn-redis-data
  # dsalgo-learn-kibana-data:
  #   name: dsalgo-learn-kibana-data

services:
  # PostgreSQL Database for SQL Learning
  dsalgo-postgres:
    image: postgres:15-alpine
    container_name: dsalgo-postgres
    hostname: dsalgo-postgres
    environment:
      - POSTGRES_USER=dsalgo
      - POSTGRES_PASSWORD=dsalgo_secret
      - POSTGRES_DB=order_management
    volumes:
      - dsalgo-learn-postgres-data:/var/lib/postgresql/data
      - ./backend/db/migrations:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    networks:
      - dsalgo-learn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dsalgo -d order_management"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Elasticsearch for Search Learning (using smaller 7.x OSS version)
  dsalgo-elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.18
    container_name: dsalgo-elasticsearch
    hostname: dsalgo-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms256m -Xmx256m"
      - cluster.name=dsalgo-learn-cluster
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - dsalgo-learn-elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - dsalgo-learn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"\\|\"status\":\"yellow\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # ==========================================================================
  # Kibana for Elasticsearch Visualization (COMMENTED OUT - uncomment if needed)
  # Saves ~430MB in image pulls
  # ==========================================================================
  # dsalgo-kibana:
  #   image: docker.elastic.co/kibana/kibana:7.17.18
  #   container_name: dsalgo-kibana
  #   hostname: dsalgo-kibana
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://dsalgo-elasticsearch:9200
  #     - SERVER_NAME=dsalgo-kibana
  #     - SERVER_HOST=0.0.0.0
  #     - XPACK_SECURITY_ENABLED=false
  #     - TELEMETRY_ENABLED=false
  #   ports:
  #     - "5601:5601"
  #   networks:
  #     - dsalgo-learn-network
  #   depends_on:
  #     dsalgo-elasticsearch:
  #       condition: service_healthy
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -s http://localhost:5601/api/status | grep -q 'available'"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 90s
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '1'
  #         memory: 512M
  #       reservations:
  #         cpus: '0.25'
  #         memory: 256M

  # Redis for Caching and Data Structures Learning
  dsalgo-redis:
    image: redis:7-alpine
    container_name: dsalgo-redis
    hostname: dsalgo-redis
    command: redis-server --appendonly yes --maxmemory 200mb --maxmemory-policy allkeys-lru
    volumes:
      - dsalgo-learn-redis-data:/data
    ports:
      - "6379:6379"
    networks:
      - dsalgo-learn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  dsalgo-learn-app:
    build:
      context: .
      dockerfile: Dockerfile
    image: dsalgo-learn-platform:latest
    container_name: dsalgo-learn-app
    hostname: dsalgo-learn-app
    labels:
      - "cloudflare:learn.arvaibhav.cloud:8080"
      - "cloudflare:learn-api.arvaibhav.cloud:8080"
    # No dependencies - app starts immediately and handles service connections gracefully
    # Services (Postgres, Redis, Elasticsearch) are available but app doesn't wait for them
    ports:
      - "8080:8080"
    volumes:
      # PRODUCTION: Only persistent data volumes, no code mounts
      # Code is COPY'd in Dockerfile for consistent deployments
      # Go build cache for kernel warmup
      - dsalgo-learn-go-cache:/app/.go-cache
      # State persistence for execution tracking
      - dsalgo-learn-state:/app/state
    environment:
      - PORT=8080
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # CORS - Allowed origins (comma-separated)
      # Domain: *.arvaibhav.cloud
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:8080,http://localhost:3000,http://127.0.0.1:8080,https://learn.arvaibhav.cloud,https://learn-api.arvaibhav.cloud,https://*.arvaibhav.cloud,*}
      # Kernel pool configuration
      - PYTHON_KERNEL_COUNT=3
      - GO_KERNEL_COUNT=2
      - KERNEL_MEMORY_LIMIT=256M
      # State persistence directory
      - STATE_DIR=/app/state
      # PDF generation settings
      - BASE_URL=http://localhost:8080
      - PDF_DIR=/tmp/pdf-exports
      # PostgreSQL connection - override via env vars for external DB
      - DB_HOST=${DB_HOST:-dsalgo-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_USER=${DB_USER:-dsalgo}
      - DB_PASSWORD=${DB_PASSWORD:-dsalgo_secret}
      - DB_NAME=${DB_NAME:-order_management}
      # Elasticsearch connection - override via ES_URL env var for external
      - ES_URL=${ES_URL:-http://dsalgo-elasticsearch:9200}
      # Kibana URL (for reference in app) - disabled by default
      - KIBANA_URL=${KIBANA_URL:-}
      # Redis connection - override via REDIS_URL env var for external
      - REDIS_URL=${REDIS_URL:-redis://dsalgo-redis:6379}
    networks:
      - dsalgo-learn-network
    restart: unless-stopped
    # Security settings
    security_opt:
      - no-new-privileges:true
    # Temporary filesystem for code execution (500MB for kernels)
    tmpfs:
      - /tmp:size=500M,mode=1777
    # Resource limits - 2GB total
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Development mode with hot reload
  dsalgo-learn-dev:
    profiles:
      - dev
    build:
      context: .
      dockerfile: Dockerfile.dev
    image: dsalgo-learn-platform:dev
    container_name: dsalgo-learn-dev
    labels:
      - "cloudflare:learn.arvaibhav.cloud:8080"
      - "cloudflare:learn-api.arvaibhav.cloud:8080"
    # No dependencies - app starts immediately and handles service connections gracefully
    # Services (Postgres, Redis, Elasticsearch) are available but app doesn't wait for them
    ports:
      - "8080:8080"
    volumes:
      # DEV: Mount source code for hot reload (air watches for changes)
      # Code changes trigger automatic server restart via air
      - ./backend:/app/backend:ro
      - ./frontend:/app/frontend:ro
      - ./problems:/app/problems:ro
      - ./topics:/app/topics:ro
      - ./docs:/app/docs:ro
      # Persistent data volumes
      - dsalgo-learn-go-cache:/app/.go-cache
      - dsalgo-learn-state:/app/state
    environment:
      - PORT=8080
      - DEV_MODE=true
      - STATE_DIR=/app/state
      # PDF generation settings
      - BASE_URL=http://localhost:8080
      - PDF_DIR=/tmp/pdf-exports
      # CORS - Allowed origins (comma-separated)
      # Domain: *.arvaibhav.cloud
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:8080,http://localhost:3000,http://127.0.0.1:8080,https://learn.arvaibhav.cloud,https://learn-api.arvaibhav.cloud,https://*.arvaibhav.cloud,*}
      # PostgreSQL connection - override via env vars for external DB
      - DB_HOST=${DB_HOST:-dsalgo-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_USER=${DB_USER:-dsalgo}
      - DB_PASSWORD=${DB_PASSWORD:-dsalgo_secret}
      - DB_NAME=${DB_NAME:-order_management}
      # Elasticsearch connection - override via ES_URL env var for external
      - ES_URL=${ES_URL:-http://dsalgo-elasticsearch:9200}
      # Kibana URL (for reference in app) - disabled by default
      - KIBANA_URL=${KIBANA_URL:-}
      # Redis connection - override via REDIS_URL env var for external
      - REDIS_URL=${REDIS_URL:-redis://dsalgo-redis:6379}
    networks:
      - dsalgo-learn-network
    tmpfs:
      - /tmp:size=500M,mode=1777
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
