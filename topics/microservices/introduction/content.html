<h1 id="introduction-to-microservices-architecture">Introduction to Microservices Architecture</h1>
<h2 id="overview">Overview</h2>
<p><strong>Microservices architecture</strong> is a distributed systems approach that decomposes applications into small, autonomous services organized around business capabilities. Each service encapsulates a bounded context, owns its data, and communicates through well-defined contracts. Unlike simple &quot;small services,&quot; true microservices embody specific organizational, operational, and technical principles that enable independent evolution at scale.</p>
<p><strong>Tags:</strong> Architecture, Distributed Systems, System Design, Interview Essential</p>
<hr />
<h2 id="core-principles-the-deep-mechanics">Core Principles: The Deep Mechanics</h2>
<h3 id="1-single-responsibility-and-service-boundaries">1. Single Responsibility and Service Boundaries</h3>
<p>The Single Responsibility Principle in microservices extends beyond code-level concerns to <strong>business capability ownership</strong>. A service should represent a single bounded context from Domain-Driven Design, not merely a single function.</p>
<div>
<h4>Service Boundary Decision Framework</h4>
<div>
<div>
<div>Cohesion Indicators (Keep Together)</div>
<div>
<div>Data that changes together</div>
<div>Features deployed together</div>
<div>Functionality sharing transactions</div>
<div>Same team ownership</div>
<div>Common release cycles</div>
</div>
</div>
<div>
<div>Coupling Indicators (Split Apart)</div>
<div>
<div>Different rates of change</div>
<div>Different scaling requirements</div>
<div>Different security boundaries</div>
<div>Different team expertise</div>
<div>Independent business value</div>
</div>
</div>
</div>
<div>
<div><span>Critical Insight:</span> The boundary is correct when you can explain what the service does without using "and" - "This service manages order lifecycle" vs "This service manages orders and sends notifications and updates inventory"</div>
</div>
</div>
<p><strong>The Granularity Trap</strong>: Services that are too fine-grained create a &quot;distributed monolith&quot; - the worst of both worlds. Signs include:<br />
- Every business operation requires orchestrating 5+ services<br />
- Circular dependencies between services<br />
- Cannot deploy one service without deploying others<br />
- Distributed transactions spanning multiple services</p>
<pre><code class="language-python"># Anti-pattern: Nano-services creating tight coupling
class OrderService:
    def create_order(self, order_data):
        # Orchestrating too many fine-grained services
        customer = self.customer_service.get(order_data.customer_id)
        address = self.address_service.validate(order_data.address)
        inventory = self.inventory_service.check(order_data.items)
        pricing = self.pricing_service.calculate(order_data.items)
        tax = self.tax_service.calculate(pricing, address)
        discount = self.discount_service.apply(customer, pricing)
        # If any service fails, entire operation fails
        # This is distributed monolith behavior

# Better: Coarser boundaries with internal cohesion
class OrderService:
    def create_order(self, order_data):
        # Order service owns the order lifecycle completely
        # Calls external services only at true boundaries
        customer_snapshot = self.customer_client.get_snapshot(order_data.customer_id)

        # Order calculation is internal - no external calls
        order = Order.create(order_data, customer_snapshot)
        order.calculate_totals()  # Internal logic, not external service

        self.repository.save(order)
        self.event_bus.publish(OrderCreated(order))
        return order
</code></pre>
<div>
<h4>Interview Questions: Service Boundaries (3-Level Deep)</h4>
<div>
<div>Level 1: How do you determine service boundaries in a microservices architecture?</div>
<div>
  Use Domain-Driven Design's bounded contexts. Identify distinct business capabilities with their own ubiquitous language, data ownership, and team alignment. Apply the "can explain without 'and'" test.
</div>
<div>Level 2: What happens when you discover the boundary is wrong after deployment? How do you refactor?</div>
<div>
  Refactoring requires the Strangler Fig pattern: create new service with correct boundary, route traffic gradually using feature flags, maintain backward compatibility through API versioning, use change data capture to sync during transition, deprecate old service only after full migration verification.
</div>
<div>Level 3: How do you handle data that was shared between the old services during the split? What about in-flight transactions?</div>
<div>
  For shared data: establish data ownership first, then replicate needed data via events (eventual consistency) or API calls (synchronous). For in-flight transactions during cutover: implement dual-write during transition with reconciliation jobs, use distributed sagas with compensation for new flows, maintain audit logs with correlation IDs to trace and replay failed operations. Consider "freeze" windows for complex migrations.
</div>
</div>
</div>
<hr />
<h3 id="2-decentralized-data-management">2. Decentralized Data Management</h3>
<p>Each microservice must own its data exclusively. This principle has profound implications for consistency, querying, and operational complexity.</p>
<div>
<h4>Data Ownership Patterns</h4>
<div>
<div>
<div>Database per Service</div>
<div>
<div>Order Service</div>
<div>PostgreSQL</div>
</div>
<div>Complete isolation, different DB tech per service</div>
</div>
<div>
<div>Schema per Service</div>
<div>
<div>Shared PostgreSQL</div>
<div>Separate schemas</div>
</div>
<div>Logical isolation, shared infrastructure</div>
</div>
<div>
<div>Private Tables</div>
<div>
<div>Shared Schema</div>
<div>Table ownership rules</div>
</div>
<div>Weak isolation, transition pattern only</div>
</div>
</div>
</div>
<p><strong>The CAP Theorem Reality</strong>: With distributed data, you must choose between consistency and availability during network partitions. Most microservices choose <strong>eventual consistency</strong> with the following implications:</p>
<pre><code class="language-python"># Eventual consistency example: Order and Inventory
class OrderService:
    def place_order(self, order_request):
        # Step 1: Reserve inventory optimistically
        reservation = self.inventory_client.reserve(
            order_request.items,
            reservation_ttl=timedelta(minutes=15)
        )

        if not reservation.success:
            raise InsufficientInventoryError(reservation.unavailable_items)

        # Step 2: Create order with reservation reference
        order = Order(
            items=order_request.items,
            reservation_id=reservation.id,
            status=OrderStatus.PENDING_PAYMENT
        )
        self.repository.save(order)

        # Step 3: Publish event for downstream processing
        # Other services will eventually be consistent
        self.events.publish(OrderCreated(
            order_id=order.id,
            reservation_id=reservation.id,
            customer_id=order_request.customer_id
        ))

        return order

    # Compensation handler for failed payments
    @event_handler(PaymentFailed)
    def handle_payment_failed(self, event):
        order = self.repository.get(event.order_id)
        order.status = OrderStatus.CANCELLED
        self.repository.save(order)

        # Release the inventory reservation
        self.inventory_client.release_reservation(order.reservation_id)

        self.events.publish(OrderCancelled(order_id=order.id))
</code></pre>
<p><strong>Cross-Service Queries</strong>: When you need data from multiple services, you have several patterns:</p>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Use Case</th>
<th>Trade-offs</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>API Composition</strong></td>
<td>Real-time aggregation</td>
<td>Latency accumulates, partial failures complex</td>
</tr>
<tr>
<td><strong>CQRS Read Models</strong></td>
<td>Query-heavy workloads</td>
<td>Eventual consistency, additional infrastructure</td>
</tr>
<tr>
<td><strong>Data Replication</strong></td>
<td>Frequently joined data</td>
<td>Stale data risk, storage overhead</td>
</tr>
<tr>
<td><strong>Materialized Views</strong></td>
<td>Reporting, analytics</td>
<td>Build complexity, sync lag</td>
</tr>
</tbody>
</table>
<div>
<h4>Interview Questions: Data Management (3-Level Deep)</h4>
<div>
<div>Level 1: Why should each microservice own its database? What problems does shared databases cause?</div>
<div>
  Shared databases create hidden coupling through schema dependencies, prevent independent deployment (schema changes affect all services), eliminate technology choice, create scaling bottlenecks, and make ownership unclear. Separate databases enable true autonomy.
</div>
<div>Level 2: How do you handle transactions that span multiple services when each has its own database?</div>
<div>
  Use the [[Saga Pattern]](/microservices/patterns/saga) with either choreography (event-driven) or orchestration (central coordinator). Each service performs local transactions and publishes events. Compensating transactions handle rollback. Avoid distributed transactions (2PC) as they don't scale and create tight coupling.
</div>
<div>Level 3: What happens if a compensating transaction fails? How do you handle "uncompensatable" operations like sending emails?</div>
<div>
  Compensating transaction failures require: (1) Retry with exponential backoff and dead letter queues, (2) Manual intervention workflows with admin dashboards, (3) Eventual reconciliation jobs that compare states. For uncompensatable operations: use semantic locks (mark operation as "pending" until saga completes), design operations to be reversible (send "order cancelled" email instead of unsending), or accept business-level compensation (refunds, credits). Implement idempotency keys throughout.
</div>
</div>
</div>
<hr />
<h3 id="3-design-for-failure">3. Design for Failure</h3>
<p>In distributed systems, failure is not exceptional - it is the norm. Network partitions, service crashes, and slow dependencies will occur. The system must be designed to degrade gracefully rather than fail catastrophically.</p>
<div>
<h4>Failure Handling Mechanisms</h4>
<div>
<div>
<div>Circuit Breaker States</div>
<div>
<div>CLOSED: Normal operation</div>
<div>HALF-OPEN: Testing recovery</div>
<div>OPEN: Failing fast</div>
</div>
<div>Threshold: 50% failures in 10 requests triggers OPEN. Reset timeout: 30 seconds to HALF-OPEN.</div>
</div>
<div>
<div>Bulkhead Isolation</div>
<div>
  Isolate failures by partitioning resources:
<div>
  Thread pool per dependency<br/>
  Connection pool limits<br/>
  Separate process/container<br/>
  Queue per operation type
</div>
</div>
</div>
<div>
<div>Retry Strategy</div>
<div>
<div>
  delay = min(base * 2^attempt, max)<br/>
  delay += random(0, delay * 0.1)  # jitter
</div>
<div>Max 3 retries, base 100ms, max 10s, with jitter to prevent thundering herd</div>
</div>
</div>
<div>
<div>Timeout Hierarchy</div>
<div>
<div>
<div><span>Connection timeout:</span><span>1-5s</span></div>
<div><span>Read timeout:</span><span>5-30s</span></div>
<div><span>Overall request:</span><span>30-60s</span></div>
<div><span>Circuit breaker:</span><span>30-60s</span></div>
</div>
</div>
</div>
</div>
</div>
<pre><code class="language-python"># Production-grade resilience implementation
from circuitbreaker import circuit
from tenacity import retry, stop_after_attempt, wait_exponential
import asyncio

class ResilientServiceClient:
    def __init__(self, service_name: str, base_url: str):
        self.service_name = service_name
        self.base_url = base_url
        self.circuit_breaker = CircuitBreaker(
            failure_threshold=5,
            recovery_timeout=30,
            expected_exceptions=(ServiceUnavailableError, TimeoutError)
        )
        # Bulkhead: separate semaphore per service
        self.semaphore = asyncio.Semaphore(10)

    @circuit
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=0.1, max=10),
        retry=retry_if_exception_type((TransientError, TimeoutError))
    )
    async def call(self, endpoint: str, method: str = &quot;GET&quot;, **kwargs):
        # Bulkhead: limit concurrent calls
        async with self.semaphore:
            # Timeout: prevent hanging
            try:
                async with asyncio.timeout(30):
                    response = await self._make_request(endpoint, method, **kwargs)
                    return response
            except asyncio.TimeoutError:
                self._record_failure(&quot;timeout&quot;)
                raise TimeoutError(f&quot;{self.service_name} timeout&quot;)

    async def call_with_fallback(self, endpoint: str, fallback_fn, **kwargs):
        &quot;&quot;&quot;Call with graceful degradation&quot;&quot;&quot;
        try:
            return await self.call(endpoint, **kwargs)
        except CircuitBreakerOpenError:
            # Circuit is open - use fallback immediately
            logger.warning(f&quot;Circuit open for {self.service_name}, using fallback&quot;)
            return await fallback_fn()
        except Exception as e:
            logger.error(f&quot;Call failed to {self.service_name}: {e}&quot;)
            return await fallback_fn()

# Usage with fallback
class ProductService:
    async def get_product_with_reviews(self, product_id: str):
        product = await self.product_repo.get(product_id)

        # Reviews are non-critical - use fallback on failure
        reviews = await self.review_client.call_with_fallback(
            f&quot;/products/{product_id}/reviews&quot;,
            fallback_fn=lambda: {&quot;reviews&quot;: [], &quot;cached&quot;: True}
        )

        return {**product, **reviews}
</code></pre>
<div>
<h4>Interview Questions: Failure Handling (3-Level Deep)</h4>
<div>
<div>Level 1: What is a circuit breaker and when should you use it?</div>
<div>
  A circuit breaker prevents cascading failures by stopping calls to failing services. It has three states: CLOSED (normal), OPEN (failing fast), HALF-OPEN (testing recovery). Use it for all inter-service communication to prevent one failing service from bringing down the entire system.
</div>
<div>Level 2: How do you configure circuit breaker thresholds? What happens when the circuit opens during a traffic spike?</div>
<div>
  Thresholds depend on SLAs and traffic patterns: typically 50% failure rate over 20 requests, with 30-second recovery timeout. During traffic spikes with open circuit: (1) Return cached data if available, (2) Serve degraded response, (3) Queue requests if latency-tolerant. Configure sliding window for failure counting to avoid single burst triggering. Use separate circuits per endpoint, not per service.
</div>
<div>Level 3: How do you prevent thundering herd when the circuit transitions from OPEN to HALF-OPEN? What about circuit breakers in async/event-driven systems?</div>
<div>
  Thundering herd prevention: (1) Allow only single probe request in HALF-OPEN, (2) Add jitter to recovery timeouts across instances, (3) Gradual ramp-up from HALF-OPEN (10% traffic initially). For async systems: circuit breakers apply to message processing - track consumer failure rates, pause consumption when circuit opens (let messages queue in broker), resume with backpressure. Use dead letter queues for persistent failures. Consider per-partition circuits in Kafka.
</div>
</div>
</div>
<hr />
<h3 id="4-smart-endpoints-and-dumb-pipes">4. Smart Endpoints and Dumb Pipes</h3>
<p>Microservices favor simple communication mechanisms (HTTP, message queues) with intelligent services. Avoid putting business logic in middleware, ESBs, or API gateways.</p>
<div>
<h4>Communication Philosophy Comparison</h4>
<div>
<div>
<div>ESB Anti-Pattern (Smart Pipes)</div>
<div>
<div>Routing logic in middleware</div>
<div>Transformation in bus</div>
<div>Orchestration in ESB</div>
<div>Vendor lock-in, centralized bottleneck</div>
</div>
</div>
<div>
<div>Microservices (Dumb Pipes)</div>
<div>
<div>Simple HTTP or message queues</div>
<div>Services own transformation</div>
<div>Choreography or service orchestration</div>
<div>Decentralized, independently evolvable</div>
</div>
</div>
</div>
</div>
<p><strong>Where logic CAN live in infrastructure:</strong></p>
<ul>
<li><a href="/system-design/api-gateway">[API Gateway]</a>: Authentication, rate limiting, SSL termination (cross-cutting concerns, not business logic)</li>
<li><a href="/microservices/patterns/service-mesh">[Service Mesh]</a>: mTLS, observability, retries (infrastructure concerns)</li>
<li>Message Broker: Message routing, dead letters (delivery concerns)</li>
</ul>
<p><strong>Where logic must NOT live:</strong></p>
<ul>
<li>Business rules</li>
<li>Data transformation/enrichment</li>
<li>Workflow orchestration</li>
<li>Validation logic</li>
</ul>
<hr />
<h2 id="when-to-use-microservices-the-decision-framework">When to Use Microservices: The Decision Framework</h2>
<h3 id="the-microservices-premium">The Microservices Premium</h3>
<p>Microservices have significant overhead costs. You must earn the right to use them by having problems that justify the complexity:</p>
<div>
<h4>Microservices Overhead Costs</h4>
<div>
<div>
<div>Operational Complexity</div>
<div>N services = N deployments, N monitoring setups, N failure modes, N log aggregations</div>
</div>
<div>
<div>Network Overhead</div>
<div>Latency, serialization, network failures, distributed tracing complexity</div>
</div>
<div>
<div>Data Consistency</div>
<div>No ACID transactions, eventual consistency, saga complexity, debugging difficulty</div>
</div>
<div>
<div>Testing Complexity</div>
<div>Integration tests, contract tests, end-to-end tests, test environment management</div>
</div>
<div>
<div>Infrastructure Cost</div>
<div>Service mesh, API gateway, message brokers, container orchestration, monitoring stack</div>
</div>
<div>
<div>Cognitive Load</div>
<div>Understanding system topology, debugging across services, onboarding new developers</div>
</div>
</div>
</div>
<h3 id="decision-matrix">Decision Matrix</h3>
<table>
<thead>
<tr>
<th>Factor</th>
<th>Favors Monolith</th>
<th>Favors Microservices</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Team Size</strong></td>
<td>&lt; 10 engineers</td>
<td>&gt; 30 engineers, multiple teams</td>
</tr>
<tr>
<td><strong>Domain Complexity</strong></td>
<td>Simple, well-understood</td>
<td>Complex, multiple bounded contexts</td>
</tr>
<tr>
<td><strong>Scale Requirements</strong></td>
<td>Uniform scaling sufficient</td>
<td>Components need independent scaling</td>
</tr>
<tr>
<td><strong>Release Cadence</strong></td>
<td>Monthly releases acceptable</td>
<td>Multiple deploys per day needed</td>
</tr>
<tr>
<td><strong>Technology Needs</strong></td>
<td>Single stack sufficient</td>
<td>Different components need different tech</td>
</tr>
<tr>
<td><strong>Organization</strong></td>
<td>Single team</td>
<td>Multiple autonomous teams</td>
</tr>
<tr>
<td><strong>Domain Knowledge</strong></td>
<td>Still discovering boundaries</td>
<td>Clear, stable domain boundaries</td>
</tr>
</tbody>
</table>
<div>
<div>Critical Assumption: The Monolith-First Approach</div>
<div>
    Martin Fowler recommends starting with a well-modularized monolith and extracting microservices only when you have: (1) clear domain boundaries validated through production usage, (2) team growth requiring organizational decoupling, (3) scaling bottlenecks that cannot be solved by vertical scaling. Premature decomposition leads to distributed monoliths and boundary mistakes that are expensive to fix.
</div>
</div>
<h3 id="real-world-extraction-patterns">Real-World Extraction Patterns</h3>
<pre><code class="language-python"># Phase 1: Modular Monolith - Clear internal boundaries
# /monolith/src/
#   /orders/         &lt;- Future microservice
#     __init__.py    &lt;- Public API
#     service.py     &lt;- Business logic
#     repository.py  &lt;- Data access
#     models.py      &lt;- Domain models
#   /inventory/      &lt;- Future microservice
#   /payments/       &lt;- Future microservice

# orders/__init__.py - Only expose public interface
from .service import OrderService
from .models import Order, OrderStatus
__all__ = ['OrderService', 'Order', 'OrderStatus']

# orders/service.py - No direct imports from other modules
class OrderService:
    def __init__(
        self,
        inventory_service,  # Interface, not concrete import
        payment_service,    # Dependency injection
        event_publisher     # For future event-driven
    ):
        self._inventory = inventory_service
        self._payment = payment_service
        self._events = event_publisher

    def place_order(self, order_request):
        # All external module access through interfaces
        inventory_result = self._inventory.reserve(order_request.items)
        # Business logic stays here
        order = Order.create(order_request, inventory_result)
        self._repository.save(order)
        self._events.publish(OrderCreated(order))
        return order

# Phase 2: Extract to separate service when ready
# The interface stays the same - just implementation changes
</code></pre>
<div>
<h4>Interview Questions: When to Use Microservices (3-Level Deep)</h4>
<div>
<div>Level 1: When would you choose microservices over a monolith?</div>
<div>
  When you have multiple teams needing independent deployment, different scaling requirements per component, polyglot technology needs, and well-understood domain boundaries. The organizational need for autonomy often drives the technical decision.
</div>
<div>Level 2: Your startup has 8 engineers and wants to use microservices for "future scalability." How do you advise them?</div>
<div>
  Advise against it. With 8 engineers, coordination overhead outweighs benefits. Recommend a modular monolith with clear internal boundaries, dependency injection, and event publishing internally. This provides future extraction paths without current complexity. Microservices are a solution to organizational scaling problems they don't yet have.
</div>
<div>Level 3: The company grows to 50 engineers. How do you identify which modules to extract first and in what sequence?</div>
<div>
  Prioritize extraction by: (1) Team ownership clarity - modules owned by distinct teams extract first, (2) Change frequency - high-churn modules benefit most from independent deployment, (3) Scaling requirements - components needing different scaling extract early, (4) Coupling analysis - use static analysis to find modules with fewest inbound dependencies. Sequence: extract leaf services (few dependencies) first, core services last. Each extraction should reduce coupling for subsequent extractions.
</div>
</div>
</div>
<hr />
<h2 id="team-organization-conways-law-in-practice">Team Organization: Conway's Law in Practice</h2>
<h3 id="conways-law">Conway's Law</h3>
<blockquote>
<p>&quot;Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.&quot; - Melvin Conway</p>
</blockquote>
<p>This isn't just an observation - it's a tool. <strong>Inverse Conway Maneuver</strong>: Design your team structure to get the architecture you want.</p>
<div>
<h4>Team Structure vs Architecture Alignment</h4>
<div>
<div>
<div>Misaligned: Component Teams</div>
<div>
<div>Frontend Team</div>
<div>Backend Team</div>
<div>Database Team</div>
</div>
<div>Every feature requires 3 teams to coordinate</div>
</div>
<div>
<div>Aligned: Stream-Aligned Teams</div>
<div>
<div>Orders Team (full stack)</div>
<div>Payments Team (full stack)</div>
<div>Search Team (full stack)</div>
</div>
<div>Each team delivers features independently</div>
</div>
</div>
</div>
<h3 id="team-topologies-model">Team Topologies Model</h3>
<p>The Team Topologies framework defines four fundamental team types:</p>
<div>
<h4>Four Team Types</h4>
<div>
<div>
<div>Stream-Aligned Teams</div>
<div>
  Primary value-delivery teams. Own one or more services end-to-end. Aligned to business flow (Orders, Checkout, Search). Should be 80%+ of engineering.
</div>
</div>
<div>
<div>Platform Teams</div>
<div>
  Provide internal platforms as products. Kubernetes, CI/CD, observability. Enable stream-aligned teams through self-service. Minimize cognitive load for feature teams.
</div>
</div>
<div>
<div>Enabling Teams</div>
<div>
  Help stream-aligned teams adopt new capabilities. Temporary engagement model. Examples: helping adopt Kubernetes, implementing observability. Goal: make themselves unnecessary.
</div>
</div>
<div>
<div>Complicated Subsystem Teams</div>
<div>
  Own complex technical components requiring specialist skills. Examples: ML models, video encoding, compiler. Provide APIs consumed by stream-aligned teams.
</div>
</div>
</div>
</div>
<h3 id="team-size-two-pizza-rule-and-beyond">Team Size: Two-Pizza Rule and Beyond</h3>
<p>Amazon's &quot;two-pizza team&quot; (6-10 people) isn't arbitrary. It's based on communication overhead:</p>
<p><strong>Metcalfe's Law</strong>: Communication paths = n(n-1)/2</p>
<table>
<thead>
<tr>
<th>Team Size</th>
<th>Communication Paths</th>
<th>Coordination Overhead</th>
</tr>
</thead>
<tbody>
<tr>
<td>5 people</td>
<td>10 paths</td>
<td>Low - verbal sync works</td>
</tr>
<tr>
<td>8 people</td>
<td>28 paths</td>
<td>Medium - need some structure</td>
</tr>
<tr>
<td>12 people</td>
<td>66 paths</td>
<td>High - meetings dominate</td>
</tr>
<tr>
<td>20 people</td>
<td>190 paths</td>
<td>Unsustainable - must split</td>
</tr>
</tbody>
</table>
<p><strong>Optimal microservices team</strong>: 5-8 engineers owning 2-5 services, with full-stack capability (frontend, backend, data, ops).</p>
<div>
<div>Critical Trade-off: Team Autonomy vs Consistency</div>
<div>
    Full autonomy leads to fragmentation: different logging formats, incompatible error handling, duplicated solutions. But too much standardization kills innovation and creates bottlenecks. Balance through: (1) Mandated standards for cross-cutting concerns (logging format, tracing IDs, error codes), (2) Recommended patterns with escape hatches, (3) Inner-source shared libraries, (4) Architecture Decision Records (ADRs) for transparency.
</div>
</div>
<div>
<h4>Interview Questions: Team Organization (3-Level Deep)</h4>
<div>
<div>Level 1: What is Conway's Law and how does it affect microservices architecture?</div>
<div>
  Conway's Law states that system design mirrors organizational communication structures. For microservices, this means team boundaries should match service boundaries. A team split by technical layers (frontend/backend/DB) will struggle with microservices; teams split by business capability will naturally create aligned services.
</div>
<div>Level 2: Your organization has 5 services but only 3 teams. Two services have no clear owner. How do you handle this?</div>
<div>
  Options: (1) Merge unowned services into related owned services - reduce service count to match teams, (2) Assign shared ownership with rotation - but risks "tragedy of the commons", (3) Create virtual team with members from existing teams - temporary for maintenance. Long-term: services should never exceed team capacity. If you can't staff a service, it shouldn't exist separately.
</div>
<div>Level 3: How do you handle cross-cutting changes that span multiple teams' services (like adding a new authentication method)?</div>
<div>
  Pattern depends on change type: (1) For infrastructure changes (new auth), platform team provides library/sidecar, stream teams integrate on their schedule with deadline. (2) For coordinated features, create temporary "virtual team" with representatives from each affected team - they coordinate implementation and return to home teams. (3) Use feature flags for gradual rollout, allowing teams to integrate independently. (4) Establish architectural runway - platform/enabling teams prepare capabilities ahead of stream teams' needs. Key: avoid synchronous dependencies between teams' work.
</div>
</div>
</div>
<hr />
<h2 id="deployment-strategies-zero-downtime-release-patterns">Deployment Strategies: Zero-Downtime Release Patterns</h2>
<h3 id="strategy-comparison">Strategy Comparison</h3>
<div>
<h4>Deployment Strategy Spectrum</h4>
<div>
<div>
<div>Rolling Deployment</div>
<div>Gradually replace instances of old version with new version</div>
<div>
<div>v2</div>
<div>v2</div>
<div>v1</div>
<div>v1</div>
</div>
<div>+ No extra infrastructure</div>
<div>- Version mixing during rollout</div>
</div>
<div>
<div>Blue-Green Deployment</div>
<div>Run two identical environments, switch traffic atomically</div>
<div>
<div>
<div>Blue (v1)</div>
<div>standby</div>
</div>
<div>
<div>Green (v2)</div>
<div>active</div>
</div>
</div>
<div>+ Instant rollback</div>
<div>- 2x infrastructure cost</div>
</div>
<div>
<div>Canary Deployment</div>
<div>Route small % of traffic to new version, gradually increase</div>
<div>
<div>v1 (90%)</div>
<div>v2</div>
</div>
<div>+ Early problem detection</div>
<div>- Complex traffic routing</div>
</div>
<div>
<div>Feature Flags</div>
<div>Deploy code to all, enable features selectively via configuration</div>
<div>
  if (flags.newCheckout) { ... }
</div>
<div>+ Decouple deploy from release</div>
<div>- Code complexity, flag debt</div>
</div>
</div>
</div>
<h3 id="blue-green-deployment-deep-dive">Blue-Green Deployment Deep Dive</h3>
<pre><code class="language-yaml"># Kubernetes Blue-Green with Service switch
# blue-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-blue
  labels:
    app: myapp
    version: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: myapp
        image: myapp:1.0.0
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
---
# green-deployment.yaml (new version)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-green
  labels:
    app: myapp
    version: green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: myapp
        image: myapp:2.0.0
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
---
# service.yaml - Switch by changing selector
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
    version: green  # Change to 'blue' to rollback
  ports:
  - port: 80
    targetPort: 8080
</code></pre>
<p><strong>Blue-Green Database Challenge</strong>: The hardest part is database schema changes. Solutions:</p>
<ol>
<li>
<p><strong>Expand-Contract Pattern</strong>:</p>
<ul>
<li>Phase 1: Add new columns/tables (backward compatible)</li>
<li>Phase 2: Deploy application using new schema</li>
<li>Phase 3: Migrate data</li>
<li>Phase 4: Remove old columns/tables</li>
</ul>
</li>
<li>
<p><strong>Database per Environment</strong>: Expensive but cleanest - each color has own database with sync</p>
</li>
</ol>
<h3 id="canary-deployment-with-automated-rollback">Canary Deployment with Automated Rollback</h3>
<pre><code class="language-python"># Canary deployment controller
class CanaryController:
    def __init__(self, metrics_client, deployment_client):
        self.metrics = metrics_client
        self.deploy = deployment_client

    async def progressive_rollout(
        self,
        service: str,
        new_version: str,
        stages: list[CanaryStage]
    ):
        &quot;&quot;&quot;
        Progressive canary with automatic rollback
        stages = [
            CanaryStage(traffic_pct=1, duration_min=5, error_threshold=0.01),
            CanaryStage(traffic_pct=10, duration_min=15, error_threshold=0.01),
            CanaryStage(traffic_pct=50, duration_min=30, error_threshold=0.005),
            CanaryStage(traffic_pct=100, duration_min=0, error_threshold=0.005),
        ]
        &quot;&quot;&quot;
        for stage in stages:
            logger.info(f&quot;Canary stage: {stage.traffic_pct}% traffic to {new_version}&quot;)

            # Shift traffic
            await self.deploy.set_traffic_split(
                service,
                canary_version=new_version,
                canary_percent=stage.traffic_pct
            )

            # Monitor for stage duration
            if stage.duration_min &gt; 0:
                healthy = await self._monitor_health(
                    service,
                    new_version,
                    duration_minutes=stage.duration_min,
                    error_threshold=stage.error_threshold
                )

                if not healthy:
                    logger.error(f&quot;Canary failed at {stage.traffic_pct}%, rolling back&quot;)
                    await self._rollback(service, new_version)
                    raise CanaryFailedError(service, new_version, stage)

        logger.info(f&quot;Canary successful, {new_version} is now production&quot;)
        await self.deploy.promote_canary(service, new_version)

    async def _monitor_health(
        self,
        service: str,
        version: str,
        duration_minutes: int,
        error_threshold: float
    ) -&gt; bool:
        &quot;&quot;&quot;Monitor error rate, latency, and custom metrics&quot;&quot;&quot;
        end_time = datetime.now() + timedelta(minutes=duration_minutes)

        while datetime.now() &lt; end_time:
            metrics = await self.metrics.query(
                service=service,
                version=version,
                window_minutes=5
            )

            # Check error rate
            if metrics.error_rate &gt; error_threshold:
                logger.warning(f&quot;Error rate {metrics.error_rate} exceeds threshold&quot;)
                return False

            # Check latency regression
            baseline = await self.metrics.get_baseline(service)
            if metrics.p99_latency &gt; baseline.p99_latency * 1.5:
                logger.warning(f&quot;Latency regression: {metrics.p99_latency}ms&quot;)
                return False

            # Check custom business metrics
            if metrics.conversion_rate &lt; baseline.conversion_rate * 0.95:
                logger.warning(&quot;Conversion rate dropped&quot;)
                return False

            await asyncio.sleep(30)

        return True
</code></pre>
<h3 id="gitops-deployment-pipeline">GitOps Deployment Pipeline</h3>
<div>
<h4>GitOps Deployment Flow</h4>
<div>
<div>
<div>Developer Push</div>
<div>-></div>
<div>git push triggers CI pipeline</div>
</div>
<div>
<div>CI Pipeline</div>
<div>-></div>
<div>Test, build image, push to registry, update manifest repo</div>
</div>
<div>
<div>GitOps Agent</div>
<div>-></div>
<div>ArgoCD/Flux detects manifest change, syncs to cluster</div>
</div>
<div>
<div>Kubernetes</div>
<div>-></div>
<div>Rolling update with health checks, automatic rollback on failure</div>
</div>
</div>
<div>
<div>Key Principle</div>
<div>Git is the single source of truth. All changes go through git. Cluster state converges to git state. Audit trail is automatic.</div>
</div>
</div>
<div>
<h4>Interview Questions: Deployment Strategies (3-Level Deep)</h4>
<div>
<div>Level 1: What is the difference between blue-green and canary deployments?</div>
<div>
  Blue-green runs two complete environments and switches all traffic atomically. Canary gradually shifts traffic percentage to new version while monitoring metrics. Blue-green is simpler but costs 2x resources; canary catches issues with smaller blast radius but requires sophisticated traffic routing and monitoring.
</div>
<div>Level 2: How do you handle database migrations in a blue-green deployment where both versions need different schemas?</div>
<div>
  Use the expand-contract (parallel change) pattern: (1) Expand: add new columns without removing old ones, make schema backward compatible. (2) Deploy new application version reading/writing both old and new schema. (3) Migrate: backfill new columns from old data. (4) Contract: after successful cutover, remove old columns. This allows both blue and green to work with the same database during transition.
</div>
<div>Level 3: During a canary deployment, you discover the new version has a subtle bug that only affects 0.1% of users with a specific data pattern. Your metrics show overall error rates are within threshold. How do you catch this?</div>
<div>
  Aggregate metrics miss long-tail issues. Solutions: (1) Segment metrics by customer cohorts, device types, data characteristics - monitor each segment separately. (2) Implement anomaly detection that flags unusual patterns even within thresholds. (3) Use log analysis for error clustering - new error signatures trigger alerts. (4) Shadow testing: run canary in parallel processing same requests as production and compare outputs. (5) Real user monitoring (RUM) with user feedback channels. (6) Staged canary targeting: first roll out to internal users, then beta users, then general population.
</div>
</div>
</div>
<hr />
<h2 id="common-anti-patterns-and-how-to-avoid-them">Common Anti-Patterns and How to Avoid Them</h2>
<div>
<h4>Microservices Anti-Patterns</h4>
<div>
<div>
<div>
<div>Distributed Monolith</div>
<div>Services are separated but still tightly coupled</div>
</div>
<div>
<strong>Symptoms:</strong> Can't deploy one service without deploying others. Services share database. Synchronous call chains of 5+ services. All services must be up for system to work.<br/>
<strong>Fix:</strong> Identify true boundaries, merge over-split services, introduce async communication, embrace eventual consistency.
</div>
</div>
<div>
<div>
<div>Shared Database</div>
<div>Multiple services accessing same database</div>
</div>
<div>
<strong>Symptoms:</strong> Schema changes require coordinating multiple teams. No clear data ownership. Performance issues affect all services. Can't choose optimal database per service.<br/>
<strong>Fix:</strong> Define data ownership, create service APIs for data access, replicate needed data via events.
</div>
</div>
<div>
<div>
<div>Chatty Services</div>
<div>Excessive inter-service communication</div>
</div>
<div>
<strong>Symptoms:</strong> High latency due to network round trips. N+1 query patterns across services. Single user action triggers dozens of service calls.<br/>
<strong>Fix:</strong> Batch APIs, data replication for read-heavy paths, coarser service boundaries, [[CQRS]](/microservices/patterns/cqrs) for queries.
</div>
</div>
<div>
<div>
<div>Missing Observability</div>
<div>Can't trace requests across services</div>
</div>
<div>
<strong>Symptoms:</strong> Debugging requires checking logs in multiple places. Can't understand call patterns. No visibility into cross-service latency breakdown.<br/>
<strong>Fix:</strong> Implement [[distributed tracing]](/observability/distributed-tracing) (Jaeger, Zipkin), structured logging with correlation IDs, centralized metrics.
</div>
</div>
</div>
</div>
<hr />
<h2 id="key-takeaways">Key Takeaways</h2>
<div>
<div>Essential Principles to Remember</div>
<div>
<div><strong>1.</strong> Microservices solve organizational scaling problems first, technical problems second</div>
<div><strong>2.</strong> Conway's Law is a tool - design team structure to get desired architecture</div>
<div><strong>3.</strong> Start monolith, extract services when you have proven domain boundaries</div>
<div><strong>4.</strong> Each service owns its data completely - no shared databases</div>
<div><strong>5.</strong> Design for failure from day one - circuit breakers, bulkheads, timeouts</div>
<div><strong>6.</strong> Deployment strategy depends on risk tolerance and infrastructure capability</div>
<div><strong>7.</strong> Observability is not optional - distributed tracing, centralized logging, metrics</div>
<div><strong>8.</strong> The goal is independent deployability - if you can't deploy independently, you don't have microservices</div>
</div>
</div>
<hr />
<h2 id="related-topics">Related Topics</h2>
<pre><code>        - [[Service Mesh]](/microservices/patterns/service-mesh) - Infrastructure layer for service-to-service communication
        - [[Saga Pattern]](/microservices/patterns/saga) - Managing distributed transactions
        - [[API Gateway]](/system-design/api-gateway) - Entry point and cross-cutting concerns
        - [[Event-Driven Architecture]](/microservices/patterns/event-driven) - Async communication patterns
        - [[CQRS]](/microservices/patterns/cqrs) - Command Query Responsibility Segregation
        - [[Distributed Tracing]](/observability/distributed-tracing) - Request flow visibility
        - [[Domain-Driven Design]](/architecture/ddd) - Strategic design for service boundaries
</code></pre>
