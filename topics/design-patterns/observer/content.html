<style>
/* Mobile-specific styles for iPhone 15 and similar devices */
@media screen and (max-width: 480px) {
    /* Force all grid layouts to single column */
    [style*="grid-template-columns"] {
        display: block !important;
    }
    [style*="grid-template-columns"] > div {
        margin-bottom: 16px !important;
    }
    /* Adjust padding for mobile */
    [style*="padding: 32px"],
    [style*="padding: 24px"] {
        padding: 16px !important;
    }
    /* Smaller headings */
    h4[style*="font-size: 18px"],
    h4[style*="font-size: 16px"] {
        font-size: 15px !important;
    }
    /* Readable font sizes */
    [style*="font-size: 13px"],
    [style*="font-size: 12px"],
    [style*="font-size: 11px"],
    [style*="font-size: 10px"] {
        font-size: 13px !important;
        line-height: 1.6 !important;
    }
    /* Flex containers stack vertically */
    [style*="display: flex"][style*="gap"] {
        flex-direction: column !important;
    }
    /* Better spacing for nested content */
    [style*="padding-left: 64px"],
    [style*="padding-left: 48px"],
    [style*="padding-left: 40px"] {
        padding-left: 16px !important;
    }
    /* Code blocks */
    pre {
        font-size: 12px !important;
        padding: 12px !important;
        overflow-x: auto !important;
    }
    pre code {
        font-size: 12px !important;
    }
    /* Tables */
    table {
        font-size: 12px !important;
        display: block !important;
        overflow-x: auto !important;
    }
    th, td {
        padding: 8px !important;
        font-size: 12px !important;
    }
}
</style>
<h1 id="observer-pattern">Observer Pattern</h1>
<h2 id="overview">Overview</h2>
<p>The Observer pattern establishes a one-to-many dependency where a subject maintains a list of dependents (observers) and notifies them automatically of state changes. While conceptually simple, production implementations reveal deep complexity around memory management, ordering guarantees, error propagation, and performance under scale.</p>
<p><strong>Difficulty:</strong> Intermediate to Advanced (Simple concept, treacherous at scale)<br />
<strong>Category:</strong> Behavioral Pattern<br />
<strong>Also Known As:</strong> Publish-Subscribe, Event-Subscriber, Listener, Dependents</p>
<hr />
<h2 id="core-mechanism-how-observer-actually-works">Core Mechanism: How Observer Actually Works</h2>
<div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #4ecdc4; margin-top: 0; text-align: center">Observer Pattern Internal Flow</h4>
<div style="display: flex; flex-direction: column; gap: 16px; align-items: center">
<div style="display: flex; gap: 20px; align-items: center; flex-wrap: wrap; justify-content: center">
<div style="background: #252540;border-radius: 8px; padding: 16px; min-width: 200px">
<div style="color: #569cd6; font-weight: bold; margin-bottom: 8px">Subject</div>
<div style="color: #ce9178; font-size: 13px">observers: List&lt;Observer&gt;</div>
<div style="color: #ce9178; font-size: 13px">state: T</div>
<div style="margin: 8px 0"></div>
<div style="color: #dcdcaa; font-size: 13px">attach(o) / detach(o)</div>
<div style="color: #dcdcaa; font-size: 13px">notify() / setState()</div>
</div>
<div style="color: #4ecdc4; font-size: 32px">&#8594;</div>
<div style="display: flex; flex-direction: column; gap: 8px">
<div style="background: #252540;border-radius: 8px; padding: 12px; min-width: 150px">
<div style="color: #4ecdc4; font-size: 13px">Observer A</div>
<div style="color: #888; font-size: 11px">update(state)</div>
</div>
<div style="background: #252540;border-radius: 8px; padding: 12px; min-width: 150px">
<div style="color: #4ecdc4; font-size: 13px">Observer B</div>
<div style="color: #888; font-size: 11px">update(state)</div>
</div>
<div style="background: #252540;border-radius: 8px; padding: 12px; min-width: 150px">
<div style="color: #4ecdc4; font-size: 13px">Observer N</div>
<div style="color: #888; font-size: 11px">update(state)</div>
</div>
</div>
</div>
<div style="background: #1e3a5f; border-radius: 8px; padding: 16px; width: 90%; margin-top: 16px">
<div style="color: #4ecdc4; font-weight: bold; margin-bottom: 8px">Notification Sequence</div>
<div style="display: flex; justify-content: space-between; flex-wrap: wrap; gap: 8px">
<div style="color: #ddd; font-size: 12px">1. State changes</div>
<div style="color: #888">&#8594;</div>
<div style="color: #ddd; font-size: 12px">2. notify() called</div>
<div style="color: #888">&#8594;</div>
<div style="color: #ddd; font-size: 12px">3. Iterate observers</div>
<div style="color: #888">&#8594;</div>
<div style="color: #ddd; font-size: 12px">4. Call update()</div>
</div>
</div>
</div>
</div>
<div style="background: #143d2e;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #28a745">Key Assumption:</strong> The Observer pattern assumes observers are independent and can be notified in any order. When this assumption breaks, you have hidden temporal coupling that leads to subtle bugs.
</div>
<h3 id="the-registration-mechanism">The Registration Mechanism</h3>
<p>When an observer registers with a subject, several things happen internally:</p>
<pre><code class="language-python">class Subject:
    def __init__(self):
        self._observers: List[Observer] = []
        self._state = None
        self._lock = threading.RLock()  # For thread safety

    def attach(self, observer: Observer) -&gt; None:
        &quot;&quot;&quot;
        Registration adds observer to internal collection.

        Critical decisions here:
        1. Duplicate check - allow same observer twice?
        2. Collection type - list (ordered) vs set (fast lookup)?
        3. Thread safety - lock during modification?
        4. Weak vs strong reference - who owns the observer lifecycle?
        &quot;&quot;&quot;
        with self._lock:
            if observer not in self._observers:  # O(n) check
                self._observers.append(observer)

    def detach(self, observer: Observer) -&gt; None:
        &quot;&quot;&quot;
        Deregistration - but what if we're mid-notification?
        &quot;&quot;&quot;
        with self._lock:
            try:
                self._observers.remove(observer)
            except ValueError:
                pass  # Already removed or never registered
</code></pre>
<div style="background: #143d2e;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #28a745">Trade-off - Collection Choice:</strong>
<ul style="margin: 8px 0 0 0; color: #ddd">
<li><strong>List:</strong> Preserves registration order, O(n) contains check, allows duplicates if unchecked</li>
<li><strong>Set:</strong> O(1) contains check, no duplicates, but loses ordering guarantees</li>
<li><strong>OrderedDict:</strong> O(1) lookup + ordering, but more memory overhead</li>
</ul>
</div>
<h3 id="interview-questions---core-mechanism">Interview Questions - Core Mechanism</h3>
<details>
<summary><strong>Level 1: What happens internally when notify() is called?</strong></summary>
<p>The subject iterates through its observer collection and calls each observer's update method, typically passing either the new state (push) or a reference to itself (pull).</p>
<pre><code class="language-python">def notify(self):
    for observer in self._observers:
        observer.update(self._state)
</code></pre>
<details>
<summary><strong>Level 2: What problems arise if an observer calls detach() during notify()?</strong></summary>
<p>This causes a concurrent modification problem. If we're iterating over <code>self._observers</code> and an observer removes itself during its <code>update()</code> call, the iterator becomes invalid. Solutions:</p>
<ol>
<li><strong>Copy the list before iteration:</strong> <code>for observer in list(self._observers):</code></li>
<li><strong>Defer removals:</strong> Mark for removal, process after iteration completes</li>
<li><strong>Use concurrent-safe collections:</strong> <code>CopyOnWriteArrayList</code> in Java</li>
</ol>
<pre><code class="language-python">def notify(self):
    # Safe: iterate over a snapshot
    observers_snapshot = list(self._observers)
    for observer in observers_snapshot:
        observer.update(self._state)
</code></pre>
<details>
<summary><strong>Level 3: How would you handle an observer that throws an exception during update()?</strong></summary>
<p>This is a critical design decision with multiple valid approaches:</p>
<p><strong>Option 1: Fail Fast (stop all notifications)</strong></p>
<pre><code class="language-python">def notify(self):
    for observer in list(self._observers):
        observer.update(self._state)  # Exception bubbles up
</code></pre>
<ul>
<li>Use when: All observers are critical, partial notification is worse than none</li>
<li>Risk: One bad observer blocks all others</li>
</ul>
<p><strong>Option 2: Fail Safe (continue with others)</strong></p>
<pre><code class="language-python">def notify(self):
    errors = []
    for observer in list(self._observers):
        try:
            observer.update(self._state)
        except Exception as e:
            errors.append((observer, e))
            logger.error(f&quot;Observer {observer} failed: {e}&quot;)
    if errors:
        raise ObserverNotificationError(errors)
</code></pre>
<ul>
<li>Use when: Observers are independent, partial notification is acceptable</li>
<li>Risk: Silent failures if not logged properly</li>
</ul>
<p><strong>Option 3: Circuit Breaker Pattern</strong></p>
<pre><code class="language-python">def notify(self):
    for observer in list(self._observers):
        if self._circuit_breaker.is_open(observer):
            continue  # Skip failing observer temporarily
        try:
            observer.update(self._state)
            self._circuit_breaker.record_success(observer)
        except Exception as e:
            self._circuit_breaker.record_failure(observer)
</code></pre>
<ul>
<li>Use when: You want automatic recovery from transient failures</li>
</ul>
</details>
</details>
</details>
<hr />
<h2 id="push-vs-pull-the-fundamental-design-decision">Push vs Pull: The Fundamental Design Decision</h2>
<p>The most critical architectural decision in Observer implementation is how data flows from subject to observer.</p>
<div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #4ecdc4; margin-top: 0; text-align: center">Push vs Pull Model Comparison</h4>
<div style="display: flex; gap: 24px; flex-wrap: wrap; justify-content: center">
<div style="flex: 1; min-width: 280px; background: #252540; border-radius: 8px; padding: 16px">
<h5 style="color: #569cd6; margin-top: 0">Push Model</h5>
<div style="color: #888; font-size: 12px; margin-bottom: 12px">Subject sends data to observers</div>
<div style="background: #1a1a2e; border-radius: 4px; padding: 12px; margin-bottom: 12px">
<code style="color: #dcdcaa; font-size: 12px">observer.update(changed_data)</code>
</div>
<div style="color: #ddd; font-size: 13px">
<div style="margin-bottom: 8px"><span style="color: #4ecdc4">+</span> Single call per observer</div>
<div style="margin-bottom: 8px"><span style="color: #4ecdc4">+</span> Observer gets data immediately</div>
<div style="margin-bottom: 8px"><span style="color: #4ecdc4">+</span> Lower latency</div>
<div style="margin-bottom: 8px"><span style="color: #f85149">-</span> Subject must know observer needs</div>
<div style="margin-bottom: 8px"><span style="color: #f85149">-</span> May send unnecessary data</div>
<div><span style="color: #f85149">-</span> Tight data coupling</div>
</div>
</div>
<div style="flex: 1; min-width: 280px; background: #252540; border-radius: 8px; padding: 16px">
<h5 style="color: #4ecdc4; margin-top: 0">Pull Model</h5>
<div style="color: #888; font-size: 12px; margin-bottom: 12px">Observer requests data from subject</div>
<div style="background: #1a1a2e; border-radius: 4px; padding: 12px; margin-bottom: 12px">
<code style="color: #dcdcaa; font-size: 12px">observer.update(subject_ref)</code>
</div>
<div style="color: #ddd; font-size: 13px">
<div style="margin-bottom: 8px"><span style="color: #4ecdc4">+</span> Observer controls what it fetches</div>
<div style="margin-bottom: 8px"><span style="color: #4ecdc4">+</span> Subject stays simple</div>
<div style="margin-bottom: 8px"><span style="color: #4ecdc4">+</span> Loose coupling</div>
<div style="margin-bottom: 8px"><span style="color: #f85149">-</span> Multiple calls to subject</div>
<div style="margin-bottom: 8px"><span style="color: #f85149">-</span> State may change between pulls</div>
<div><span style="color: #f85149">-</span> Higher latency</div>
</div>
</div>
</div>
</div>
<h3 id="push-model-implementation">Push Model Implementation</h3>
<pre><code class="language-python">class PushSubject:
    &quot;&quot;&quot;Subject pushes complete state change information to observers.&quot;&quot;&quot;

    def __init__(self):
        self._observers: List[Observer] = []
        self._temperature: float = 0.0
        self._humidity: float = 0.0
        self._pressure: float = 0.0

    def set_measurements(self, temp: float, humidity: float, pressure: float):
        self._temperature = temp
        self._humidity = humidity
        self._pressure = pressure
        self._notify_observers()

    def _notify_observers(self):
        # Push all data - observer has no choice
        measurement_data = {
            'temperature': self._temperature,
            'humidity': self._humidity,
            'pressure': self._pressure,
            'timestamp': datetime.now()
        }
        for observer in self._observers:
            observer.update(measurement_data)


class TemperatureDisplay:
    &quot;&quot;&quot;Observer that only cares about temperature.&quot;&quot;&quot;

    def update(self, data: dict):
        # Receives ALL data, uses only temperature
        # Wasteful if temperature didn't change
        temp = data['temperature']
        print(f&quot;Temperature: {temp}C&quot;)
</code></pre>
<h3 id="pull-model-implementation">Pull Model Implementation</h3>
<pre><code class="language-python">class PullSubject:
    &quot;&quot;&quot;Subject notifies, observer pulls what it needs.&quot;&quot;&quot;

    def __init__(self):
        self._observers: List[Observer] = []
        self._temperature: float = 0.0
        self._humidity: float = 0.0
        self._pressure: float = 0.0

    def set_measurements(self, temp: float, humidity: float, pressure: float):
        self._temperature = temp
        self._humidity = humidity
        self._pressure = pressure
        self._notify_observers()

    def _notify_observers(self):
        # Just signal that something changed
        for observer in self._observers:
            observer.update(self)  # Pass reference to self

    # Getters for observers to pull
    def get_temperature(self) -&gt; float:
        return self._temperature

    def get_humidity(self) -&gt; float:
        return self._humidity

    def get_pressure(self) -&gt; float:
        return self._pressure


class TemperatureDisplay:
    &quot;&quot;&quot;Observer pulls only what it needs.&quot;&quot;&quot;

    def update(self, subject: PullSubject):
        # Pull only temperature - efficient
        temp = subject.get_temperature()
        print(f&quot;Temperature: {temp}C&quot;)
</code></pre>
<div style="background: #143d2e;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #28a745">Critical Trade-off - State Consistency:</strong> In pull model, if observer A pulls temperature, then subject changes, then observer B pulls temperature, they see different values from the same notification. Push model guarantees all observers see the same snapshot.
</div>
<h3 id="hybrid-model-production-best-practice">Hybrid Model (Production Best Practice)</h3>
<pre><code class="language-python">class HybridSubject:
    &quot;&quot;&quot;
    Push a change summary, allow pull for details.
    Best of both worlds.
    &quot;&quot;&quot;

    def __init__(self):
        self._observers: Dict[str, List[Observer]] = defaultdict(list)
        self._state: Dict[str, Any] = {}

    def subscribe(self, event_type: str, observer: Observer):
        &quot;&quot;&quot;Subscribe to specific event types.&quot;&quot;&quot;
        self._observers[event_type].append(observer)

    def set_state(self, key: str, value: Any):
        old_value = self._state.get(key)
        self._state[key] = value

        # Push: Tell observers WHAT changed and the new value
        # Pull: Also pass self for additional data if needed
        change_event = ChangeEvent(
            key=key,
            old_value=old_value,
            new_value=value,
            timestamp=datetime.now(),
            subject=self  # For pull access
        )

        self._notify(key, change_event)

    def _notify(self, event_type: str, event: ChangeEvent):
        # Notify specific subscribers
        for observer in self._observers.get(event_type, []):
            observer.on_change(event)

        # Notify wildcard subscribers
        for observer in self._observers.get('*', []):
            observer.on_change(event)

    def get_state(self, key: str) -&gt; Any:
        &quot;&quot;&quot;Pull interface for observers needing more data.&quot;&quot;&quot;
        return self._state.get(key)


@dataclass
class ChangeEvent:
    key: str
    old_value: Any
    new_value: Any
    timestamp: datetime
    subject: 'HybridSubject'  # For pull access
</code></pre>
<h3 id="interview-questions---push-vs-pull">Interview Questions - Push vs Pull</h3>
<details>
<summary><strong>Level 1: When would you choose push over pull?</strong></summary>
<p>Choose <strong>push</strong> when:</p>
<ul>
<li>All observers need the same data</li>
<li>Data is small and changes infrequently</li>
<li>Latency is critical (real-time systems)</li>
<li>You want guaranteed consistent snapshots</li>
</ul>
<p>Choose <strong>pull</strong> when:</p>
<ul>
<li>Observers need different subsets of data</li>
<li>Data is large (video frames, large documents)</li>
<li>Observers may not need data for every notification</li>
<li>Subject shouldn't know observer requirements</li>
</ul>
<details>
<summary><strong>Level 2: How do you handle the pull model's consistency problem?</strong></summary>
<p>The consistency problem: Between notification and pull, state may change. Solutions:</p>
<p><strong>1. Version/Sequence Numbers:</strong></p>
<pre><code class="language-python">class VersionedSubject:
    def __init__(self):
        self._version = 0
        self._state = {}

    def update_state(self, key, value):
        self._version += 1
        self._state[key] = value
        self._notify(self._version)

    def get_state_at_version(self, version: int) -&gt; Optional[dict]:
        # Return state snapshot for that version
        return self._snapshots.get(version)
</code></pre>
<p><strong>2. Immutable State Snapshots:</strong></p>
<pre><code class="language-python">def notify(self):
    # Create immutable snapshot
    snapshot = frozendict(self._state)
    for observer in self._observers:
        observer.update(snapshot)
</code></pre>
<p><strong>3. Copy-on-Write:</strong></p>
<pre><code class="language-python">def set_state(self, key, value):
    # Create new state object, old one remains valid
    self._state = {**self._state, key: value}
    self._notify()
</code></pre>
<details>
<summary><strong>Level 3: In a distributed system with push model, how do you handle out-of-order delivery?</strong></summary>
<p>Out-of-order events in distributed systems break causality. Solutions:</p>
<p><strong>1. Vector Clocks:</strong></p>
<pre><code class="language-python">class DistributedEvent:
    def __init__(self, data, vector_clock: Dict[str, int]):
        self.data = data
        self.vector_clock = vector_clock  # {node_id: logical_time}

    def happened_before(self, other: 'DistributedEvent') -&gt; bool:
        &quot;&quot;&quot;Returns True if self causally precedes other.&quot;&quot;&quot;
        return all(
            self.vector_clock.get(k, 0) &lt;= other.vector_clock.get(k, 0)
            for k in set(self.vector_clock) | set(other.vector_clock)
        ) and self.vector_clock != other.vector_clock
</code></pre>
<p><strong>2. Sequence Numbers with Buffering:</strong></p>
<pre><code class="language-python">class OrderedEventConsumer:
    def __init__(self):
        self._expected_seq = 0
        self._buffer: Dict[int, Event] = {}

    def receive(self, event: Event):
        if event.sequence == self._expected_seq:
            self._process(event)
            self._expected_seq += 1
            self._flush_buffer()
        else:
            # Out of order - buffer it
            self._buffer[event.sequence] = event

    def _flush_buffer(self):
        while self._expected_seq in self._buffer:
            event = self._buffer.pop(self._expected_seq)
            self._process(event)
            self._expected_seq += 1
</code></pre>
<p><strong>3. Lamport Timestamps:</strong></p>
<pre><code class="language-python">class LamportClock:
    def __init__(self):
        self._time = 0

    def tick(self) -&gt; int:
        self._time += 1
        return self._time

    def update(self, received_time: int):
        self._time = max(self._time, received_time) + 1
</code></pre>
</details>
</details>
</details>
<hr />
<h2 id="memory-leaks-and-observer-lifecycle">Memory Leaks and Observer Lifecycle</h2>
<p>Memory leaks are the most common production issue with Observer pattern. They occur when observers subscribe but never unsubscribe, creating strong references that prevent garbage collection.</p>
<div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #f85149; margin-top: 0; text-align: center">Memory Leak Scenario</h4>
<div style="display: flex; flex-direction: column; gap: 16px">
<div style="display: flex; gap: 16px; align-items: center; justify-content: center; flex-wrap: wrap">
<div style="background: #252540;border-radius: 8px; padding: 16px; text-align: center">
<div style="color: #569cd6; font-weight: bold">Subject</div>
<div style="color: #888; font-size: 12px">Long-lived</div>
<div style="color: #888; font-size: 12px">(e.g., EventBus)</div>
</div>
<div style="display: flex; flex-direction: column; gap: 4px">
<div style="color: #f85149">&#8594; strong ref &#8594;</div>
<div style="color: #f85149">&#8594; strong ref &#8594;</div>
<div style="color: #f85149">&#8594; strong ref &#8594;</div>
</div>
<div style="display: flex; flex-direction: column; gap: 8px">
<div style="background: #3d2525;border-radius: 8px; padding: 8px; text-align: center">
<div style="color: #f85149; font-size: 13px">Observer (destroyed UI)</div>
</div>
<div style="background: #3d2525;border-radius: 8px; padding: 8px; text-align: center">
<div style="color: #f85149; font-size: 13px">Observer (closed tab)</div>
</div>
<div style="background: #3d2525;border-radius: 8px; padding: 8px; text-align: center">
<div style="color: #f85149; font-size: 13px">Observer (old request)</div>
</div>
</div>
</div>
<div style="background: #3d2525; border-radius: 8px; padding: 16px; text-align: center">
<div style="color: #f85149; font-weight: bold">Result: Observers cannot be garbage collected</div>
<div style="color: #888; font-size: 12px; margin-top: 8px">Memory grows linearly with each subscribe() without unsubscribe()</div>
</div>
</div>
</div>
<h3 id="the-leak-pattern">The Leak Pattern</h3>
<pre><code class="language-python"># DANGEROUS: Classic memory leak
class UserProfileComponent:
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        # Subscribe on creation - strong reference stored in event_bus
        self.event_bus.subscribe('user.updated', self.on_user_updated)

    def on_user_updated(self, event):
        self.render(event.data)

    # No cleanup! When component is &quot;destroyed&quot;, event_bus still holds reference
    # Component cannot be garbage collected


# SAFE: Explicit lifecycle management
class UserProfileComponent:
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self._subscription = None

    def mount(self):
        &quot;&quot;&quot;Called when component becomes active.&quot;&quot;&quot;
        self._subscription = self.event_bus.subscribe(
            'user.updated',
            self.on_user_updated
        )

    def unmount(self):
        &quot;&quot;&quot;Called when component is destroyed - MUST unsubscribe.&quot;&quot;&quot;
        if self._subscription:
            self._subscription.unsubscribe()
            self._subscription = None

    def on_user_updated(self, event):
        self.render(event.data)
</code></pre>
<h3 id="weak-references-automatic-cleanup">Weak References: Automatic Cleanup</h3>
<p>Weak references allow the garbage collector to reclaim observers even if the subject still holds a reference.</p>
<pre><code class="language-python">import weakref
from typing import Callable, Any, Optional


class WeakRefEventBus:
    &quot;&quot;&quot;
    Event bus using weak references to prevent memory leaks.
    Observers are automatically removed when garbage collected.
    &quot;&quot;&quot;

    def __init__(self):
        self._listeners: Dict[str, List[weakref.ref]] = defaultdict(list)

    def subscribe(self, event_type: str, callback: Callable) -&gt; None:
        &quot;&quot;&quot;
        Subscribe with weak reference.

        IMPORTANT: callback must be a bound method or stored elsewhere,
        not a lambda or local function (those get GC'd immediately).
        &quot;&quot;&quot;
        # Create weak reference with cleanup callback
        ref = weakref.ref(
            callback.__self__ if hasattr(callback, '__self__') else callback,
            lambda r: self._cleanup(event_type, r)
        )
        self._listeners[event_type].append((ref, callback.__name__))

    def _cleanup(self, event_type: str, dead_ref: weakref.ref):
        &quot;&quot;&quot;Called automatically when referenced object is garbage collected.&quot;&quot;&quot;
        self._listeners[event_type] = [
            (ref, name) for ref, name in self._listeners[event_type]
            if ref() is not None
        ]

    def emit(self, event_type: str, data: Any):
        &quot;&quot;&quot;Emit event, skipping dead references.&quot;&quot;&quot;
        live_listeners = []

        for ref, method_name in self._listeners.get(event_type, []):
            obj = ref()  # Dereference
            if obj is not None:
                live_listeners.append((ref, method_name))
                # Call the method on the object
                method = getattr(obj, method_name, None)
                if method:
                    method(data)

        # Update to only live listeners
        self._listeners[event_type] = live_listeners


# Python's WeakSet for simpler cases
class SimpleWeakSubject:
    def __init__(self):
        self._observers = weakref.WeakSet()

    def attach(self, observer):
        self._observers.add(observer)

    def notify(self, data):
        # Dead observers automatically excluded
        for observer in self._observers:
            observer.update(data)
</code></pre>
<div style="background: #143d2e;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #28a745">Weak Reference Gotcha:</strong> Lambdas and closures create temporary objects that get garbage collected immediately. Always use bound methods or explicitly stored callbacks with weak references.
<pre><code class="language-python"># BAD: Lambda is immediately garbage collected
bus.subscribe('event', lambda e: print(e))  # Callback disappears!

# GOOD: Method on a live object
class Handler:
    def handle(self, e): print(e)

handler = Handler()
bus.subscribe('event', handler.handle)  # Works as long as handler lives
</code></pre>
</div>
<h3 id="preventing-leaks-with-disposable-pattern">Preventing Leaks with Disposable Pattern</h3>
<pre><code class="language-python">from abc import ABC, abstractmethod
from contextlib import contextmanager


class Disposable(ABC):
    &quot;&quot;&quot;Base class for resources that need explicit cleanup.&quot;&quot;&quot;

    @abstractmethod
    def dispose(self) -&gt; None:
        pass


class Subscription(Disposable):
    &quot;&quot;&quot;Represents an active subscription that can be cancelled.&quot;&quot;&quot;

    def __init__(self, unsubscribe_fn: Callable[[], None]):
        self._unsubscribe = unsubscribe_fn
        self._disposed = False

    def dispose(self) -&gt; None:
        if not self._disposed:
            self._unsubscribe()
            self._disposed = True

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.dispose()


class CompositeDisposable(Disposable):
    &quot;&quot;&quot;Manages multiple subscriptions for batch cleanup.&quot;&quot;&quot;

    def __init__(self):
        self._disposables: List[Disposable] = []

    def add(self, disposable: Disposable) -&gt; None:
        self._disposables.append(disposable)

    def dispose(self) -&gt; None:
        for d in self._disposables:
            d.dispose()
        self._disposables.clear()


# Usage
class Dashboard:
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self._subscriptions = CompositeDisposable()

    def mount(self):
        self._subscriptions.add(
            self.event_bus.subscribe('metrics.updated', self.on_metrics)
        )
        self._subscriptions.add(
            self.event_bus.subscribe('alerts.new', self.on_alert)
        )

    def unmount(self):
        # Single call cleans up ALL subscriptions
        self._subscriptions.dispose()
</code></pre>
<h3 id="interview-questions---memory-leaks">Interview Questions - Memory Leaks</h3>
<details>
<summary><strong>Level 1: How do memory leaks occur in Observer pattern?</strong></summary>
<p>Memory leaks occur when:</p>
<ol>
<li>Observer subscribes to a long-lived subject</li>
<li>Observer goes out of scope or is &quot;destroyed&quot; logically</li>
<li>Observer never calls unsubscribe</li>
<li>Subject's strong reference prevents garbage collection</li>
</ol>
<p>The observer object remains in memory indefinitely, along with anything it references.</p>
<details>
<summary><strong>Level 2: What are the trade-offs between weak references and explicit unsubscription?</strong></summary>
<p><strong>Weak References:</strong></p>
<ul>
<li>Pros: Automatic cleanup, no explicit lifecycle management needed</li>
<li>Cons:
<ul>
<li>Non-deterministic cleanup timing (when GC runs)</li>
<li>Can't use with lambdas/closures</li>
<li>Harder to debug (observers disappear silently)</li>
<li>May still receive events after &quot;destruction&quot; but before GC</li>
</ul>
</li>
</ul>
<p><strong>Explicit Unsubscription:</strong></p>
<ul>
<li>Pros:
<ul>
<li>Deterministic timing</li>
<li>Works with any callback type</li>
<li>Clear ownership semantics</li>
<li>Easier to debug and trace</li>
</ul>
</li>
<li>Cons:
<ul>
<li>Must remember to call unsubscribe</li>
<li>Requires lifecycle management code</li>
<li>Easy to miss edge cases (error paths, early returns)</li>
</ul>
</li>
</ul>
<details>
<summary><strong>Level 3: How would you detect and diagnose observer memory leaks in production?</strong></summary>
<p><strong>Detection Strategies:</strong></p>
<ol>
<li><strong>Subscription Metrics:</strong></li>
</ol>
<pre><code class="language-python">class InstrumentedEventBus:
    def __init__(self):
        self._metrics = {
            'active_subscriptions': 0,
            'total_subscribes': 0,
            'total_unsubscribes': 0,
        }

    def subscribe(self, event_type, callback):
        self._metrics['active_subscriptions'] += 1
        self._metrics['total_subscribes'] += 1
        # ... subscription logic

    def unsubscribe(self, subscription):
        self._metrics['active_subscriptions'] -= 1
        self._metrics['total_unsubscribes'] += 1
        # ... unsubscription logic

    def get_metrics(self):
        leak_indicator = (
            self._metrics['total_subscribes'] -
            self._metrics['total_unsubscribes']
        )
        return {**self._metrics, 'potential_leaks': leak_indicator}
</code></pre>
<ol start="2">
<li><strong>Subscription Tracking with Stack Traces:</strong></li>
</ol>
<pre><code class="language-python">import traceback

class DiagnosticEventBus:
    def subscribe(self, event_type, callback):
        subscription_info = {
            'callback': callback,
            'created_at': datetime.now(),
            'stack_trace': traceback.format_stack(),  # Where was it created?
        }
        self._subscription_info[id(callback)] = subscription_info
</code></pre>
<ol start="3">
<li><strong>Memory Profiling:</strong></li>
</ol>
<pre><code class="language-python"># In production, use memory profiler to find growing collections
import objgraph

# Periodically check for leaked observers
def diagnose_leaks():
    # Find all Observer instances
    observers = objgraph.by_type('Observer')
    print(f&quot;Active observers: {len(observers)}&quot;)

    # Show reference chains for potential leaks
    objgraph.show_backrefs(observers[:5], filename='observer_refs.png')
</code></pre>
<ol start="4">
<li><strong>Canary Subscriptions:</strong></li>
</ol>
<pre><code class="language-python">class LeakDetector:
    &quot;&quot;&quot;Creates weak-referenced canary to detect leak conditions.&quot;&quot;&quot;

    def __init__(self, event_bus):
        self._canary = object()
        self._canary_ref = weakref.ref(self._canary)
        event_bus.subscribe('test.event', self._on_event)

    def _on_event(self, data):
        pass

    def check_for_leak(self) -&gt; bool:
        # If canary was collected but subscription still exists, there's a leak
        del self._canary
        gc.collect()
        return self._canary_ref() is not None
</code></pre>
</details>
</details>
</details>
<hr />
<h2 id="event-ordering-and-notification-guarantees">Event Ordering and Notification Guarantees</h2>
<p>Event ordering is a subtle but critical aspect of Observer implementations. Different systems provide different guarantees.</p>
<div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #4ecdc4; margin-top: 0; text-align: center">Ordering Guarantee Spectrum</h4>
<div style="display: flex; flex-direction: column; gap: 12px; margin-top: 16px">
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #1e3a5f; border-radius: 8px; padding: 12px; min-width: 180px; text-align: center">
<div style="color: #4ecdc4; font-weight: bold">FIFO per Observer</div>
</div>
<div style="color: #888; flex: 1; font-size: 13px">Each observer receives events in order they were emitted</div>
</div>
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #1e3a5f; border-radius: 8px; padding: 12px; min-width: 180px; text-align: center">
<div style="color: #f0ad4e; font-weight: bold">Total Order</div>
</div>
<div style="color: #888; flex: 1; font-size: 13px">All observers see same global event order</div>
</div>
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #1e3a5f; border-radius: 8px; padding: 12px; min-width: 180px; text-align: center">
<div style="color: #f85149; font-weight: bold">Causal Order</div>
</div>
<div style="color: #888; flex: 1; font-size: 13px">If A caused B, all observers see A before B</div>
</div>
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #1e3a5f; border-radius: 8px; padding: 12px; min-width: 180px; text-align: center">
<div style="color: #888; font-weight: bold">No Guarantee</div>
</div>
<div style="color: #888; flex: 1; font-size: 13px">Events may arrive in any order (async systems)</div>
</div>
</div>
</div>
<h3 id="priority-based-ordering">Priority-Based Ordering</h3>
<pre><code class="language-python">from enum import IntEnum
from dataclasses import dataclass, field
from typing import Callable, List, Any
import heapq


class Priority(IntEnum):
    CRITICAL = 0    # Runs first
    HIGH = 10
    NORMAL = 50
    LOW = 100       # Runs last


@dataclass(order=True)
class PrioritizedSubscription:
    priority: int
    callback: Callable = field(compare=False)
    subscription_id: int = field(compare=False)


class PriorityEventBus:
    &quot;&quot;&quot;Event bus with guaranteed observer execution order based on priority.&quot;&quot;&quot;

    def __init__(self):
        self._subscriptions: Dict[str, List[PrioritizedSubscription]] = defaultdict(list)
        self._next_id = 0

    def subscribe(
        self,
        event_type: str,
        callback: Callable,
        priority: Priority = Priority.NORMAL
    ) -&gt; int:
        &quot;&quot;&quot;Subscribe with priority. Lower priority number = runs first.&quot;&quot;&quot;
        sub_id = self._next_id
        self._next_id += 1

        sub = PrioritizedSubscription(
            priority=priority.value,
            callback=callback,
            subscription_id=sub_id
        )

        heapq.heappush(self._subscriptions[event_type], sub)
        return sub_id

    def emit(self, event_type: str, data: Any):
        &quot;&quot;&quot;Emit event to subscribers in priority order.&quot;&quot;&quot;
        # Get sorted copy (heap is not fully sorted, need to extract in order)
        subs = sorted(self._subscriptions.get(event_type, []))

        for sub in subs:
            sub.callback(data)


# Usage
bus = PriorityEventBus()

# Security validation runs first
bus.subscribe('request.received', validate_auth, Priority.CRITICAL)

# Logging runs last
bus.subscribe('request.received', log_request, Priority.LOW)

# Normal handlers in between
bus.subscribe('request.received', process_request, Priority.NORMAL)
</code></pre>
<h3 id="handling-observer-dependencies">Handling Observer Dependencies</h3>
<p>When observers have dependencies on each other, the pattern breaks down. Solutions:</p>
<pre><code class="language-python">class DependencyAwareEventBus:
    &quot;&quot;&quot;
    Event bus that respects inter-observer dependencies.

    WARNING: This complexity often indicates you should use a different pattern.
    Consider: Saga, Pipeline, or Chain of Responsibility.
    &quot;&quot;&quot;

    def __init__(self):
        self._subscriptions: Dict[str, Dict[str, Callable]] = defaultdict(dict)
        self._dependencies: Dict[str, Set[str]] = defaultdict(set)  # observer -&gt; {depends_on}

    def subscribe(
        self,
        event_type: str,
        observer_id: str,
        callback: Callable,
        depends_on: List[str] = None
    ):
        &quot;&quot;&quot;Subscribe with explicit dependencies on other observers.&quot;&quot;&quot;
        self._subscriptions[event_type][observer_id] = callback
        if depends_on:
            self._dependencies[observer_id] = set(depends_on)

    def emit(self, event_type: str, data: Any):
        &quot;&quot;&quot;Emit event, respecting topological order of dependencies.&quot;&quot;&quot;
        observers = self._subscriptions.get(event_type, {})
        execution_order = self._topological_sort(observers.keys())

        for observer_id in execution_order:
            callback = observers.get(observer_id)
            if callback:
                callback(data)

    def _topological_sort(self, observer_ids: Iterable[str]) -&gt; List[str]:
        &quot;&quot;&quot;Sort observers so dependencies run first.&quot;&quot;&quot;
        # Kahn's algorithm
        in_degree = {oid: 0 for oid in observer_ids}

        for oid in observer_ids:
            for dep in self._dependencies.get(oid, []):
                if dep in in_degree:
                    in_degree[oid] += 1

        queue = [oid for oid, deg in in_degree.items() if deg == 0]
        result = []

        while queue:
            current = queue.pop(0)
            result.append(current)

            for oid in observer_ids:
                if current in self._dependencies.get(oid, []):
                    in_degree[oid] -= 1
                    if in_degree[oid] == 0:
                        queue.append(oid)

        if len(result) != len(in_degree):
            raise CircularDependencyError(&quot;Cycle detected in observer dependencies&quot;)

        return result
</code></pre>
<div style="background: #143d2e;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #28a745">Design Choice:</strong> If you find yourself building dependency-aware observer systems, strongly consider whether the Observer pattern is the right choice. Dependencies between observers indicate they aren't truly independent, and you may benefit from [[Chain of Responsibility]](/topic/design-patterns/chain-of-responsibility) or [[Pipeline]](/topic/design-patterns/pipeline) patterns instead.
</div>
<h3 id="interview-questions---event-ordering">Interview Questions - Event Ordering</h3>
<details>
<summary><strong>Level 1: Why does observer execution order matter?</strong></summary>
<p>Order matters when:</p>
<ul>
<li>Security checks must run before business logic</li>
<li>Logging/audit must capture original state before modification</li>
<li>Cache invalidation must happen before database writes</li>
<li>UI updates must happen after data processing</li>
</ul>
<p>Example: If a validation observer runs after a persistence observer, invalid data gets saved.</p>
<details>
<summary><strong>Level 2: How do you handle the case where Observer A's action triggers an event that Observer B depends on?</strong></summary>
<p>This creates a notification cascade. Solutions:</p>
<p><strong>1. Deferred/Batched Notifications:</strong></p>
<pre><code class="language-python">class BatchingSubject:
    def __init__(self):
        self._notification_depth = 0
        self._pending_events: List[Event] = []

    def emit(self, event):
        self._pending_events.append(event)

        if self._notification_depth == 0:
            self._flush_notifications()

    def _flush_notifications(self):
        self._notification_depth += 1
        try:
            while self._pending_events:
                event = self._pending_events.pop(0)
                self._notify_observers(event)
        finally:
            self._notification_depth -= 1
</code></pre>
<p><strong>2. Event Sourcing with Replay:</strong></p>
<pre><code class="language-python">class EventSourcedSubject:
    def __init__(self):
        self._event_log: List[Event] = []

    def emit(self, event):
        self._event_log.append(event)
        # Observers can replay events in correct order
        self._notify_observers(event)

    def replay_from(self, sequence: int):
        for event in self._event_log[sequence:]:
            self._notify_observers(event)
</code></pre>
<details>
<summary><strong>Level 3: In a distributed system, how do you maintain causal ordering across services?</strong></summary>
<p>Causal ordering ensures that if event A caused event B, all observers see A before B. This is challenging in distributed systems.</p>
<p><strong>1. Lamport Timestamps:</strong></p>
<pre><code class="language-python">class CausalEventBus:
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.logical_clock = 0

    def emit(self, event_type: str, data: Any, caused_by: Event = None):
        # Increment clock
        self.logical_clock += 1

        if caused_by:
            # Ensure causal ordering
            self.logical_clock = max(
                self.logical_clock,
                caused_by.timestamp + 1
            )

        event = Event(
            type=event_type,
            data=data,
            timestamp=self.logical_clock,
            source=self.node_id,
            caused_by=caused_by.id if caused_by else None
        )

        self._publish(event)

    def receive(self, event: Event):
        # Update clock on receive
        self.logical_clock = max(self.logical_clock, event.timestamp) + 1
        self._deliver(event)
</code></pre>
<p><strong>2. Vector Clocks for Concurrent Events:</strong></p>
<pre><code class="language-python">class VectorClockEventBus:
    def __init__(self, node_id: str, all_nodes: List[str]):
        self.node_id = node_id
        self.vector_clock = {n: 0 for n in all_nodes}

    def emit(self, event_type: str, data: Any):
        self.vector_clock[self.node_id] += 1

        event = Event(
            type=event_type,
            data=data,
            vector_clock=dict(self.vector_clock),
        )

        self._publish(event)

    def receive(self, event: Event):
        # Merge clocks
        for node, time in event.vector_clock.items():
            self.vector_clock[node] = max(
                self.vector_clock.get(node, 0),
                time
            )
        self.vector_clock[self.node_id] += 1

        self._deliver_in_order(event)

    def _causally_ready(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;Check if all causal predecessors have been delivered.&quot;&quot;&quot;
        for node, time in event.vector_clock.items():
            if node == event.source:
                if self.delivered_clock.get(node, 0) != time - 1:
                    return False
            else:
                if self.delivered_clock.get(node, 0) &lt; time:
                    return False
        return True
</code></pre>
<p><strong>3. Kafka-Style Partitioning:</strong></p>
<pre><code class="language-python"># Partition by causal key - all related events go to same partition
# Partition provides total order within partition

def get_partition(event: Event) -&gt; int:
    # All events for same entity go to same partition
    causal_key = event.data.get('entity_id', event.type)
    return hash(causal_key) % NUM_PARTITIONS
</code></pre>
</details>
</details>
</details>
<hr />
<h2 id="backpressure-when-observers-cant-keep-up">Backpressure: When Observers Can't Keep Up</h2>
<p>Backpressure occurs when subjects produce events faster than observers can consume them. Without handling, this leads to memory exhaustion, increased latency, or dropped events.</p>
<div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #f85149; margin-top: 0; text-align: center">Backpressure Scenario</h4>
<div style="display: flex; align-items: center; justify-content: center; gap: 16px; flex-wrap: wrap; margin: 16px 0">
<div style="background: #252540;border-radius: 8px; padding: 16px; text-align: center">
<div style="color: #4ecdc4; font-weight: bold">Producer</div>
<div style="color: #4ecdc4; font-size: 24px">1000 evt/s</div>
</div>
<div style="display: flex; flex-direction: column; align-items: center">
<div style="color: #f0ad4e">&#8594;&#8594;&#8594;</div>
<div style="background: #3d3520;border-radius: 4px; padding: 8px; margin: 8px 0">
<div style="color: #f0ad4e; font-size: 12px">Queue: 50,000</div>
<div style="color: #f0ad4e; font-size: 12px">(growing!)</div>
</div>
<div style="color: #f0ad4e">&#8594;&#8594;&#8594;</div>
</div>
<div style="background: #252540;border-radius: 8px; padding: 16px; text-align: center">
<div style="color: #f85149; font-weight: bold">Consumer</div>
<div style="color: #f85149; font-size: 24px">100 evt/s</div>
</div>
</div>
<div style="background: #3d2525; border-radius: 8px; padding: 12px; text-align: center">
<div style="color: #f85149">Without backpressure: Queue grows 900 events/second until OOM</div>
</div>
</div>
<h3 id="backpressure-strategies">Backpressure Strategies</h3>
<pre><code class="language-python">from enum import Enum, auto
from collections import deque
from threading import Lock, Condition
import asyncio


class BackpressureStrategy(Enum):
    BLOCK = auto()      # Block producer until consumer catches up
    DROP_OLDEST = auto() # Drop oldest events when buffer full
    DROP_NEWEST = auto() # Drop new events when buffer full
    SAMPLE = auto()      # Keep every Nth event
    BUFFER = auto()      # Unbounded buffer (dangerous!)
    ERROR = auto()       # Raise exception when buffer full


class BackpressureEventBus:
    &quot;&quot;&quot;
    Event bus with configurable backpressure handling.
    &quot;&quot;&quot;

    def __init__(
        self,
        strategy: BackpressureStrategy = BackpressureStrategy.BLOCK,
        buffer_size: int = 1000,
        sample_rate: int = 10
    ):
        self._strategy = strategy
        self._buffer_size = buffer_size
        self._sample_rate = sample_rate
        self._event_count = 0

        self._buffer: deque = deque(maxlen=buffer_size if strategy == BackpressureStrategy.DROP_OLDEST else None)
        self._lock = Lock()
        self._not_full = Condition(self._lock)
        self._not_empty = Condition(self._lock)

        self._metrics = {
            'events_received': 0,
            'events_dropped': 0,
            'events_delivered': 0,
            'buffer_high_water': 0,
        }

    def emit(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;
        Emit event with backpressure handling.
        Returns True if event was accepted, False if dropped.
        &quot;&quot;&quot;
        self._metrics['events_received'] += 1
        self._event_count += 1

        with self._lock:
            # Update high water mark
            self._metrics['buffer_high_water'] = max(
                self._metrics['buffer_high_water'],
                len(self._buffer)
            )

            if self._strategy == BackpressureStrategy.BLOCK:
                return self._emit_blocking(event)
            elif self._strategy == BackpressureStrategy.DROP_OLDEST:
                return self._emit_drop_oldest(event)
            elif self._strategy == BackpressureStrategy.DROP_NEWEST:
                return self._emit_drop_newest(event)
            elif self._strategy == BackpressureStrategy.SAMPLE:
                return self._emit_sampled(event)
            elif self._strategy == BackpressureStrategy.ERROR:
                return self._emit_error(event)
            else:  # BUFFER
                self._buffer.append(event)
                self._not_empty.notify()
                return True

    def _emit_blocking(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;Block until space available.&quot;&quot;&quot;
        while len(self._buffer) &gt;= self._buffer_size:
            self._not_full.wait(timeout=1.0)

        self._buffer.append(event)
        self._not_empty.notify()
        return True

    def _emit_drop_oldest(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;Drop oldest events when buffer full (deque handles this with maxlen).&quot;&quot;&quot;
        if len(self._buffer) &gt;= self._buffer_size:
            self._metrics['events_dropped'] += 1
        self._buffer.append(event)
        self._not_empty.notify()
        return True

    def _emit_drop_newest(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;Reject new events when buffer full.&quot;&quot;&quot;
        if len(self._buffer) &gt;= self._buffer_size:
            self._metrics['events_dropped'] += 1
            return False

        self._buffer.append(event)
        self._not_empty.notify()
        return True

    def _emit_sampled(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;Keep only every Nth event.&quot;&quot;&quot;
        if self._event_count % self._sample_rate != 0:
            self._metrics['events_dropped'] += 1
            return False

        self._buffer.append(event)
        self._not_empty.notify()
        return True

    def _emit_error(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;Raise exception when buffer full.&quot;&quot;&quot;
        if len(self._buffer) &gt;= self._buffer_size:
            raise BufferFullError(f&quot;Event buffer full ({self._buffer_size} events)&quot;)

        self._buffer.append(event)
        self._not_empty.notify()
        return True

    def consume(self, timeout: float = None) -&gt; Optional[Event]:
        &quot;&quot;&quot;Consume next event from buffer.&quot;&quot;&quot;
        with self._lock:
            while len(self._buffer) == 0:
                if not self._not_empty.wait(timeout=timeout):
                    return None

            event = self._buffer.popleft()
            self._not_full.notify()
            self._metrics['events_delivered'] += 1
            return event
</code></pre>
<h3 id="reactive-streams-backpressure">Reactive Streams Backpressure</h3>
<p>The Reactive Streams specification provides a standard for backpressure handling:</p>
<pre><code class="language-python">from abc import ABC, abstractmethod


class Publisher(ABC):
    @abstractmethod
    def subscribe(self, subscriber: 'Subscriber') -&gt; None:
        pass


class Subscriber(ABC):
    @abstractmethod
    def on_subscribe(self, subscription: 'Subscription') -&gt; None:
        &quot;&quot;&quot;Called when subscription starts - receive Subscription to request data.&quot;&quot;&quot;
        pass

    @abstractmethod
    def on_next(self, item) -&gt; None:
        &quot;&quot;&quot;Called for each item - only called after request().&quot;&quot;&quot;
        pass

    @abstractmethod
    def on_error(self, error: Exception) -&gt; None:
        pass

    @abstractmethod
    def on_complete(self) -&gt; None:
        pass


class Subscription(ABC):
    @abstractmethod
    def request(self, n: int) -&gt; None:
        &quot;&quot;&quot;Request n more items - this is the backpressure signal.&quot;&quot;&quot;
        pass

    @abstractmethod
    def cancel(self) -&gt; None:
        pass


class ReactiveEventPublisher(Publisher):
    &quot;&quot;&quot;
    Publisher that respects subscriber demand.
    Only sends events when subscriber requests them.
    &quot;&quot;&quot;

    def __init__(self):
        self._subscribers: Dict[Subscriber, int] = {}  # subscriber -&gt; requested count
        self._pending_events: deque = deque()

    def subscribe(self, subscriber: Subscriber) -&gt; None:
        subscription = ReactiveSubscription(self, subscriber)
        self._subscribers[subscriber] = 0
        subscriber.on_subscribe(subscription)

    def emit(self, event) -&gt; None:
        self._pending_events.append(event)
        self._try_deliver()

    def _try_deliver(self):
        &quot;&quot;&quot;Deliver events only to subscribers who have requested them.&quot;&quot;&quot;
        for subscriber, requested in list(self._subscribers.items()):
            while requested &gt; 0 and self._pending_events:
                event = self._pending_events.popleft()
                subscriber.on_next(event)
                self._subscribers[subscriber] -= 1
                requested -= 1

    def _request(self, subscriber: Subscriber, n: int):
        &quot;&quot;&quot;Called by subscription when subscriber wants more items.&quot;&quot;&quot;
        self._subscribers[subscriber] = self._subscribers.get(subscriber, 0) + n
        self._try_deliver()


class ReactiveSubscription(Subscription):
    def __init__(self, publisher: ReactiveEventPublisher, subscriber: Subscriber):
        self._publisher = publisher
        self._subscriber = subscriber

    def request(self, n: int) -&gt; None:
        if n &lt;= 0:
            self._subscriber.on_error(ValueError(&quot;n must be positive&quot;))
            return
        self._publisher._request(self._subscriber, n)

    def cancel(self) -&gt; None:
        self._publisher._subscribers.pop(self._subscriber, None)


# Usage
class SlowConsumer(Subscriber):
    def __init__(self):
        self._subscription = None
        self._processed = 0

    def on_subscribe(self, subscription: Subscription):
        self._subscription = subscription
        # Request initial batch
        self._subscription.request(10)

    def on_next(self, item):
        # Process item (slow)
        time.sleep(0.1)
        self._processed += 1

        # Request more when ready
        if self._processed % 10 == 0:
            self._subscription.request(10)

    def on_error(self, error):
        print(f&quot;Error: {error}&quot;)

    def on_complete(self):
        print(&quot;Done&quot;)
</code></pre>
<div style="background: #143d2e;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #28a745">Trade-off - Backpressure Strategy Selection:</strong>
<ul style="margin: 8px 0 0 0; color: #ddd">
<li><strong>BLOCK:</strong> Use when every event must be processed, and you can afford producer slowdown</li>
<li><strong>DROP_OLDEST:</strong> Use when recent data is more valuable (real-time monitoring)</li>
<li><strong>DROP_NEWEST:</strong> Use when processing order matters and you want to finish current work</li>
<li><strong>SAMPLE:</strong> Use for high-frequency data where trends matter more than individual events</li>
<li><strong>ERROR:</strong> Use when dropping events is unacceptable and must be escalated</li>
</ul>
</div>
<h3 id="interview-questions---backpressure">Interview Questions - Backpressure</h3>
<details>
<summary><strong>Level 1: What is backpressure and why does it matter?</strong></summary>
<p>Backpressure occurs when a producer generates data faster than a consumer can process it. Without handling, this causes:</p>
<ul>
<li>Memory exhaustion (unbounded queues)</li>
<li>Increased latency (events wait in queue)</li>
<li>System instability (cascading failures)</li>
</ul>
<p>It matters because real-world systems have varying processing speeds, and assumptions about consumer capacity are often wrong.</p>
<details>
<summary><strong>Level 2: Compare blocking vs dropping strategies for backpressure. When would you use each?</strong></summary>
<p><strong>Blocking (Producer Slowdown):</strong></p>
<ul>
<li>Producer waits when buffer is full</li>
<li>Guarantees no data loss</li>
<li>Propagates slowness upstream</li>
<li>Use when: Every event is critical (financial transactions, audit logs)</li>
<li>Risk: Can cause cascading slowdowns through entire system</li>
</ul>
<p><strong>Dropping (Consumer Protection):</strong></p>
<ul>
<li>Discards events when overwhelmed</li>
<li>Protects consumer from overload</li>
<li>Loses data but maintains throughput</li>
<li>Use when: Recent data is more valuable, or data loss is acceptable (metrics, monitoring)</li>
<li>Risk: May lose critical events</li>
</ul>
<p><strong>Hybrid approaches:</strong></p>
<pre><code class="language-python">def emit_with_hybrid_backpressure(self, event):
    if event.priority == Priority.CRITICAL:
        # Block for critical events
        self._blocking_emit(event)
    else:
        # Drop low-priority events if buffer full
        self._drop_newest_emit(event)
</code></pre>
<details>
<summary><strong>Level 3: How would you implement end-to-end backpressure across microservices?</strong></summary>
<p>End-to-end backpressure requires coordination across service boundaries:</p>
<p><strong>1. Request-Based (Pull Model):</strong></p>
<pre><code class="language-python"># Consumer requests batches from producer
class BatchConsumer:
    async def consume_loop(self):
        while True:
            # Consumer controls rate by requesting specific batch size
            batch = await self.producer_client.request_batch(
                size=self.calculate_capacity(),
                timeout=5.0
            )
            await self.process_batch(batch)

    def calculate_capacity(self) -&gt; int:
        # Based on current processing rate and queue depth
        return max(1, 100 - self._local_queue.qsize())
</code></pre>
<p><strong>2. Credit-Based Flow Control:</strong></p>
<pre><code class="language-python">class CreditBasedProducer:
    def __init__(self):
        self._credits: Dict[str, int] = {}  # consumer_id -&gt; credits

    async def send(self, consumer_id: str, event: Event):
        while self._credits.get(consumer_id, 0) &lt;= 0:
            await self._wait_for_credits(consumer_id)

        self._credits[consumer_id] -= 1
        await self._network_send(consumer_id, event)

    def receive_credits(self, consumer_id: str, credits: int):
        &quot;&quot;&quot;Consumer sends credits when it has capacity.&quot;&quot;&quot;
        self._credits[consumer_id] = self._credits.get(consumer_id, 0) + credits


class CreditBasedConsumer:
    async def process_and_credit(self, event: Event):
        await self.process(event)
        # Send credit back to producer
        await self.producer.grant_credits(self.id, 1)
</code></pre>
<p><strong>3. HTTP/2 Flow Control:</strong></p>
<pre><code class="language-python"># HTTP/2 has built-in flow control via WINDOW_UPDATE frames
# gRPC streaming uses this automatically

async def stream_events(self, request, context):
    async for event in self.event_source:
        # gRPC automatically handles backpressure
        # Will block if client can't keep up
        yield event
</code></pre>
<p><strong>4. Message Queue with Consumer Groups:</strong></p>
<pre><code class="language-python"># Kafka-style: Partition-based parallelism with consumer groups
# Backpressure via consumer lag monitoring

class KafkaBackpressureMonitor:
    def check_lag(self, consumer_group: str) -&gt; int:
        lag = self.kafka_admin.get_consumer_lag(consumer_group)
        if lag &gt; self.threshold:
            # Alert, scale consumers, or slow producers
            self.alert(f&quot;Consumer lag critical: {lag}&quot;)
        return lag
</code></pre>
</details>
</details>
</details>
<hr />
<h2 id="reactive-patterns-and-modern-implementations">Reactive Patterns and Modern Implementations</h2>
<p>The Observer pattern evolved into Reactive Programming, which adds composability, error handling, and backpressure as first-class concepts.</p>
<div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #4ecdc4; margin-top: 0; text-align: center">Observer vs Reactive Streams</h4>
<div style="display: flex; gap: 24px; flex-wrap: wrap; justify-content: center; margin-top: 16px">
<div style="flex: 1; min-width: 280px; background: #252540; border-radius: 8px; padding: 16px">
<h5 style="color: #888; margin-top: 0">Classic Observer</h5>
<ul style="color: #ddd; font-size: 13px; padding-left: 20px; margin: 0">
<li>Push-only notification</li>
<li>No error channel</li>
<li>No completion signal</li>
<li>No backpressure</li>
<li>Imperative composition</li>
</ul>
</div>
<div style="flex: 1; min-width: 280px; background: #252540; border-radius: 8px; padding: 16px">
<h5 style="color: #4ecdc4; margin-top: 0">Reactive Streams</h5>
<ul style="color: #ddd; font-size: 13px; padding-left: 20px; margin: 0">
<li>on_next / on_error / on_complete</li>
<li>Built-in error propagation</li>
<li>Explicit completion</li>
<li>request(n) backpressure</li>
<li>Declarative operators</li>
</ul>
</div>
</div>
</div>
<h3 id="observable-pattern-rxpyrxjs-style">Observable Pattern (RxPy/RxJS Style)</h3>
<pre><code class="language-python">from typing import TypeVar, Generic, Callable, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

T = TypeVar('T')


@dataclass
class Notification(Generic[T]):
    &quot;&quot;&quot;Represents a stream notification.&quot;&quot;&quot;
    kind: str  # 'next', 'error', 'complete'
    value: Optional[T] = None
    error: Optional[Exception] = None


class Observable(Generic[T]):
    &quot;&quot;&quot;
    Observable represents a push-based collection.
    Implements the Observable pattern with operators.
    &quot;&quot;&quot;

    def __init__(self, subscribe_fn: Callable[['Observer[T]'], 'Disposable']):
        self._subscribe_fn = subscribe_fn

    def subscribe(
        self,
        on_next: Callable[[T], None] = None,
        on_error: Callable[[Exception], None] = None,
        on_complete: Callable[[], None] = None
    ) -&gt; 'Disposable':
        &quot;&quot;&quot;Subscribe to the observable.&quot;&quot;&quot;
        observer = Observer(
            on_next=on_next or (lambda x: None),
            on_error=on_error or (lambda e: None),
            on_complete=on_complete or (lambda: None)
        )
        return self._subscribe_fn(observer)

    # Operators
    def map(self, transform: Callable[[T], 'U']) -&gt; 'Observable[U]':
        &quot;&quot;&quot;Transform each element.&quot;&quot;&quot;
        def subscribe(observer: Observer):
            return self.subscribe(
                on_next=lambda x: observer.on_next(transform(x)),
                on_error=observer.on_error,
                on_complete=observer.on_complete
            )
        return Observable(subscribe)

    def filter(self, predicate: Callable[[T], bool]) -&gt; 'Observable[T]':
        &quot;&quot;&quot;Filter elements based on predicate.&quot;&quot;&quot;
        def subscribe(observer: Observer):
            return self.subscribe(
                on_next=lambda x: observer.on_next(x) if predicate(x) else None,
                on_error=observer.on_error,
                on_complete=observer.on_complete
            )
        return Observable(subscribe)

    def take(self, count: int) -&gt; 'Observable[T]':
        &quot;&quot;&quot;Take first n elements.&quot;&quot;&quot;
        def subscribe(observer: Observer):
            taken = [0]
            subscription = [None]

            def on_next(x):
                if taken[0] &lt; count:
                    observer.on_next(x)
                    taken[0] += 1
                    if taken[0] &gt;= count:
                        observer.on_complete()
                        if subscription[0]:
                            subscription[0].dispose()

            subscription[0] = self.subscribe(
                on_next=on_next,
                on_error=observer.on_error,
                on_complete=observer.on_complete
            )
            return subscription[0]
        return Observable(subscribe)

    def debounce(self, delay_seconds: float) -&gt; 'Observable[T]':
        &quot;&quot;&quot;Only emit if no new value for delay period.&quot;&quot;&quot;
        def subscribe(observer: Observer):
            timer = [None]

            def on_next(x):
                if timer[0]:
                    timer[0].cancel()
                timer[0] = threading.Timer(
                    delay_seconds,
                    lambda: observer.on_next(x)
                )
                timer[0].start()

            return self.subscribe(
                on_next=on_next,
                on_error=observer.on_error,
                on_complete=observer.on_complete
            )
        return Observable(subscribe)

    @staticmethod
    def from_iterable(items: Iterable[T]) -&gt; 'Observable[T]':
        &quot;&quot;&quot;Create observable from iterable.&quot;&quot;&quot;
        def subscribe(observer: Observer):
            try:
                for item in items:
                    observer.on_next(item)
                observer.on_complete()
            except Exception as e:
                observer.on_error(e)
            return Disposable(lambda: None)
        return Observable(subscribe)

    @staticmethod
    def interval(seconds: float) -&gt; 'Observable[int]':
        &quot;&quot;&quot;Emit incrementing integers at interval.&quot;&quot;&quot;
        def subscribe(observer: Observer):
            count = [0]
            running = [True]

            def emit():
                while running[0]:
                    observer.on_next(count[0])
                    count[0] += 1
                    time.sleep(seconds)

            thread = threading.Thread(target=emit, daemon=True)
            thread.start()

            return Disposable(lambda: running.__setitem__(0, False))
        return Observable(subscribe)


@dataclass
class Observer(Generic[T]):
    on_next: Callable[[T], None]
    on_error: Callable[[Exception], None]
    on_complete: Callable[[], None]


class Disposable:
    def __init__(self, dispose_fn: Callable[[], None]):
        self._dispose = dispose_fn
        self._disposed = False

    def dispose(self):
        if not self._disposed:
            self._dispose()
            self._disposed = True


# Usage example
prices = Observable.interval(0.1).pipe(
    ops.map(lambda _: random.uniform(100, 200)),  # Generate random prices
    ops.filter(lambda p: p &gt; 150),                 # Only high prices
    ops.debounce(0.5),                            # Debounce rapid changes
    ops.take(5)                                    # Stop after 5
)

prices.subscribe(
    on_next=lambda p: print(f&quot;Price alert: ${p:.2f}&quot;),
    on_error=lambda e: print(f&quot;Error: {e}&quot;),
    on_complete=lambda: print(&quot;Monitoring complete&quot;)
)
</code></pre>
<h3 id="subject-observer--observable-combined">Subject: Observer + Observable Combined</h3>
<pre><code class="language-python">class Subject(Generic[T], Observable[T]):
    &quot;&quot;&quot;
    Subject is both an Observable and an Observer.
    Acts as a bridge/proxy that can multicast to multiple observers.
    &quot;&quot;&quot;

    def __init__(self):
        self._observers: List[Observer[T]] = []
        self._completed = False
        self._error: Optional[Exception] = None

        super().__init__(self._subscribe)

    def _subscribe(self, observer: Observer[T]) -&gt; Disposable:
        if self._error:
            observer.on_error(self._error)
        elif self._completed:
            observer.on_complete()
        else:
            self._observers.append(observer)

        return Disposable(lambda: self._observers.remove(observer) if observer in self._observers else None)

    # Observer interface
    def on_next(self, value: T) -&gt; None:
        if not self._completed and not self._error:
            for observer in list(self._observers):
                observer.on_next(value)

    def on_error(self, error: Exception) -&gt; None:
        if not self._completed and not self._error:
            self._error = error
            for observer in list(self._observers):
                observer.on_error(error)
            self._observers.clear()

    def on_complete(self) -&gt; None:
        if not self._completed and not self._error:
            self._completed = True
            for observer in list(self._observers):
                observer.on_complete()
            self._observers.clear()


class BehaviorSubject(Subject[T]):
    &quot;&quot;&quot;
    Subject that replays the last value to new subscribers.
    Useful for state management.
    &quot;&quot;&quot;

    def __init__(self, initial_value: T):
        super().__init__()
        self._value = initial_value

    def _subscribe(self, observer: Observer[T]) -&gt; Disposable:
        # Immediately emit current value
        observer.on_next(self._value)
        return super()._subscribe(observer)

    def on_next(self, value: T) -&gt; None:
        self._value = value
        super().on_next(value)

    @property
    def value(self) -&gt; T:
        return self._value


class ReplaySubject(Subject[T]):
    &quot;&quot;&quot;
    Subject that replays N previous values to new subscribers.
    Useful for late subscribers who need history.
    &quot;&quot;&quot;

    def __init__(self, buffer_size: int = None):
        super().__init__()
        self._buffer: deque = deque(maxlen=buffer_size)

    def _subscribe(self, observer: Observer[T]) -&gt; Disposable:
        # Replay buffered values
        for value in self._buffer:
            observer.on_next(value)
        return super()._subscribe(observer)

    def on_next(self, value: T) -&gt; None:
        self._buffer.append(value)
        super().on_next(value)
</code></pre>
<div style="background: #143d2e;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #28a745">Design Choice - Subject Types:</strong>
<ul style="margin: 8px 0 0 0; color: #ddd">
<li><strong>Subject:</strong> Pure multicast, no replay - use for events where history doesn't matter</li>
<li><strong>BehaviorSubject:</strong> Always has current value - use for state (like Redux store)</li>
<li><strong>ReplaySubject:</strong> Replays history - use when late subscribers need past events</li>
<li><strong>AsyncSubject:</strong> Only emits last value on complete - use for async request/response</li>
</ul>
</div>
<h3 id="interview-questions---reactive-patterns">Interview Questions - Reactive Patterns</h3>
<details>
<summary><strong>Level 1: What problems does Reactive Streams solve that classic Observer doesn't?</strong></summary>
<p>Reactive Streams addresses four key gaps:</p>
<ol>
<li>
<p><strong>Error Handling:</strong> Classic Observer has no standard error channel. Reactive Streams has <code>on_error()</code>.</p>
</li>
<li>
<p><strong>Completion:</strong> No way to signal &quot;no more events&quot; in classic Observer. Reactive Streams has <code>on_complete()</code>.</p>
</li>
<li>
<p><strong>Backpressure:</strong> Classic Observer is push-only. Reactive Streams has <code>request(n)</code> for pull-based flow control.</p>
</li>
<li>
<p><strong>Composition:</strong> Classic Observer requires imperative code to combine streams. Reactive provides declarative operators (<code>map</code>, <code>filter</code>, <code>merge</code>, <code>flatMap</code>).</p>
</li>
</ol>
<details>
<summary><strong>Level 2: Explain the difference between hot and cold observables.</strong></summary>
<p><strong>Cold Observable:</strong></p>
<ul>
<li>Creates new producer for each subscriber</li>
<li>Each subscriber gets all values from the beginning</li>
<li>Like a video on-demand - starts from beginning for each viewer</li>
</ul>
<pre><code class="language-python"># Cold: Each subscriber triggers new HTTP request
cold = Observable.from_promise(fetch('/api/data'))

cold.subscribe(lambda x: print(&quot;Sub1:&quot;, x))  # HTTP request 1
cold.subscribe(lambda x: print(&quot;Sub2:&quot;, x))  # HTTP request 2
</code></pre>
<p><strong>Hot Observable:</strong></p>
<ul>
<li>Shares single producer among all subscribers</li>
<li>Subscribers only see events after they subscribe</li>
<li>Like live TV - you see what's broadcasting now</li>
</ul>
<pre><code class="language-python"># Hot: All subscribers share same WebSocket
websocket_messages = Subject()

# Later subscriber misses earlier messages
websocket_messages.subscribe(lambda x: print(&quot;Sub1:&quot;, x))
# ... time passes, messages emitted ...
websocket_messages.subscribe(lambda x: print(&quot;Sub2:&quot;, x))  # Misses earlier messages
</code></pre>
<p><strong>Converting between them:</strong></p>
<pre><code class="language-python"># Cold to Hot: Use share() or publish()
hot = cold.pipe(share())

# Hot to Cold: Use replay buffer
cold_replay = hot.pipe(replay_buffer(size=100))
</code></pre>
<details>
<summary><strong>Level 3: How would you implement a reactive state management system like Redux using observables?</strong></summary>
<pre><code class="language-python">from typing import TypeVar, Generic, Callable
from dataclasses import dataclass

State = TypeVar('State')
Action = TypeVar('Action')


@dataclass
class StoreAction:
    type: str
    payload: Any = None


class ReactiveStore(Generic[State]):
    &quot;&quot;&quot;
    Redux-like store implemented with reactive patterns.
    State changes are observable streams.
    &quot;&quot;&quot;

    def __init__(
        self,
        reducer: Callable[[State, StoreAction], State],
        initial_state: State,
        middleware: List[Callable] = None
    ):
        self._reducer = reducer
        self._state = initial_state
        self._middleware = middleware or []

        # BehaviorSubject for state - new subscribers get current state
        self._state_subject = BehaviorSubject(initial_state)

        # Subject for actions - for middleware/effects
        self._action_subject = Subject()

        # Set up action processing
        self._action_subject.subscribe(
            on_next=self._process_action
        )

    @property
    def state(self) -&gt; State:
        return self._state

    def select(self, selector: Callable[[State], T]) -&gt; Observable[T]:
        &quot;&quot;&quot;
        Select a slice of state as an observable.
        Only emits when selected value changes.
        &quot;&quot;&quot;
        return self._state_subject.pipe(
            ops.map(selector),
            ops.distinct_until_changed()
        )

    def dispatch(self, action: StoreAction) -&gt; None:
        &quot;&quot;&quot;Dispatch action through middleware chain.&quot;&quot;&quot;
        # Build middleware chain
        def dispatch_core(a):
            self._action_subject.on_next(a)

        chain = dispatch_core
        for middleware in reversed(self._middleware):
            chain = middleware(self)(chain)

        chain(action)

    def _process_action(self, action: StoreAction) -&gt; None:
        &quot;&quot;&quot;Process action through reducer and update state.&quot;&quot;&quot;
        new_state = self._reducer(self._state, action)

        if new_state is not self._state:
            self._state = new_state
            self._state_subject.on_next(new_state)

    def add_effect(
        self,
        action_type: str,
        effect: Callable[[StoreAction], Observable[StoreAction]]
    ) -&gt; Disposable:
        &quot;&quot;&quot;
        Add side effect that runs when action type is dispatched.
        Effect returns observable of new actions to dispatch.
        &quot;&quot;&quot;
        return self._action_subject.pipe(
            ops.filter(lambda a: a.type == action_type),
            ops.flat_map(effect)
        ).subscribe(
            on_next=self.dispatch
        )


# Usage
@dataclass
class AppState:
    users: List[dict]
    loading: bool
    error: Optional[str]


def app_reducer(state: AppState, action: StoreAction) -&gt; AppState:
    if action.type == 'FETCH_USERS_START':
        return AppState(users=state.users, loading=True, error=None)
    elif action.type == 'FETCH_USERS_SUCCESS':
        return AppState(users=action.payload, loading=False, error=None)
    elif action.type == 'FETCH_USERS_ERROR':
        return AppState(users=state.users, loading=False, error=action.payload)
    return state


# Create store
store = ReactiveStore(
    reducer=app_reducer,
    initial_state=AppState(users=[], loading=False, error=None)
)

# Add async effect
def fetch_users_effect(action: StoreAction) -&gt; Observable[StoreAction]:
    return Observable.from_promise(
        fetch('/api/users')
    ).pipe(
        ops.map(lambda users: StoreAction('FETCH_USERS_SUCCESS', users)),
        ops.catch(lambda e: Observable.of(StoreAction('FETCH_USERS_ERROR', str(e))))
    )

store.add_effect('FETCH_USERS_START', fetch_users_effect)

# Subscribe to state changes
store.select(lambda s: s.users).subscribe(
    on_next=lambda users: render_user_list(users)
)

store.select(lambda s: s.loading).subscribe(
    on_next=lambda loading: toggle_spinner(loading)
)

# Dispatch action
store.dispatch(StoreAction('FETCH_USERS_START'))
</code></pre>
</details>
</details>
</details>
<hr />
<h2 id="production-implementation-thread-safe-event-emitter">Production Implementation: Thread-Safe Event Emitter</h2>
<pre><code class="language-python">from typing import Callable, Dict, List, Any, Optional, Set, TypeVar
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from concurrent.futures import ThreadPoolExecutor, Future
from contextlib import contextmanager
import threading
import weakref
import logging
import traceback
import uuid

logger = logging.getLogger(__name__)

T = TypeVar('T')


class EventPriority(Enum):
    CRITICAL = 0   # Runs first, synchronously, blocks until complete
    HIGH = 10      # High priority async
    NORMAL = 50    # Default
    LOW = 100      # Background processing


@dataclass
class Event:
    &quot;&quot;&quot;Rich event with metadata for debugging and tracing.&quot;&quot;&quot;
    type: str
    data: Any
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    source: str = &quot;unknown&quot;
    timestamp: datetime = field(default_factory=datetime.utcnow)
    correlation_id: Optional[str] = None
    causation_id: Optional[str] = None  # ID of event that caused this one

    def caused_by(self, parent: 'Event') -&gt; 'Event':
        &quot;&quot;&quot;Create causal link to parent event.&quot;&quot;&quot;
        self.causation_id = parent.id
        self.correlation_id = parent.correlation_id or parent.id
        return self


@dataclass
class Subscription:
    &quot;&quot;&quot;Represents an active subscription.&quot;&quot;&quot;
    id: str
    event_type: str
    callback: Callable[[Event], None]
    priority: EventPriority = EventPriority.NORMAL
    filter_fn: Optional[Callable[[Event], bool]] = None
    error_handler: Optional[Callable[[Exception, Event], None]] = None
    max_calls: Optional[int] = None
    call_count: int = 0
    created_at: datetime = field(default_factory=datetime.utcnow)
    weak_ref: bool = False
    _callback_ref: Any = field(default=None, repr=False)

    def matches(self, event: Event) -&gt; bool:
        &quot;&quot;&quot;Check if subscription should receive this event.&quot;&quot;&quot;
        if self.max_calls and self.call_count &gt;= self.max_calls:
            return False
        if self.filter_fn and not self.filter_fn(event):
            return False
        return True

    def get_callback(self) -&gt; Optional[Callable]:
        &quot;&quot;&quot;Get callback, resolving weak reference if needed.&quot;&quot;&quot;
        if self.weak_ref and self._callback_ref:
            obj = self._callback_ref()
            if obj is None:
                return None  # Object was garbage collected
            return getattr(obj, self.callback.__name__)
        return self.callback


class EventEmitter:
    &quot;&quot;&quot;
    Production-grade event emitter with:
    - Thread-safe operations
    - Priority-based execution
    - Weak reference support
    - Error isolation
    - Metrics and observability
    - Backpressure handling
    &quot;&quot;&quot;

    def __init__(
        self,
        max_workers: int = 4,
        max_queue_size: int = 10000,
        default_error_handler: Callable[[Exception, Event, Subscription], None] = None
    ):
        self._subscriptions: Dict[str, List[Subscription]] = {}
        self._lock = threading.RLock()
        self._executor = ThreadPoolExecutor(max_workers=max_workers)
        self._default_error_handler = default_error_handler or self._log_error
        self._paused_events: Set[str] = set()
        self._max_queue_size = max_queue_size
        self._pending_count = 0

        self._metrics = {
            'events_emitted': 0,
            'events_delivered': 0,
            'events_dropped': 0,
            'errors': 0,
            'subscriptions_created': 0,
            'subscriptions_removed': 0,
        }

    def on(
        self,
        event_type: str,
        callback: Callable[[Event], None],
        priority: EventPriority = EventPriority.NORMAL,
        filter_fn: Callable[[Event], bool] = None,
        error_handler: Callable[[Exception, Event], None] = None,
        max_calls: int = None,
        weak: bool = False
    ) -&gt; Subscription:
        &quot;&quot;&quot;
        Subscribe to an event type.

        Args:
            event_type: Event type to subscribe to. Use &quot;*&quot; for all events.
            callback: Function called when event occurs.
            priority: Execution priority (CRITICAL runs first, synchronously).
            filter_fn: Optional predicate to filter events.
            error_handler: Custom error handler for this subscription.
            max_calls: Auto-unsubscribe after N calls.
            weak: Use weak reference (auto-cleanup when callback owner is GC'd).

        Returns:
            Subscription object for later unsubscription.
        &quot;&quot;&quot;
        sub_id = str(uuid.uuid4())

        subscription = Subscription(
            id=sub_id,
            event_type=event_type,
            callback=callback,
            priority=priority,
            filter_fn=filter_fn,
            error_handler=error_handler,
            max_calls=max_calls,
            weak_ref=weak,
        )

        # Set up weak reference if requested
        if weak and hasattr(callback, '__self__'):
            subscription._callback_ref = weakref.ref(
                callback.__self__,
                lambda ref: self._cleanup_dead_subscription(event_type, sub_id)
            )

        with self._lock:
            if event_type not in self._subscriptions:
                self._subscriptions[event_type] = []

            self._subscriptions[event_type].append(subscription)
            self._subscriptions[event_type].sort(key=lambda s: s.priority.value)
            self._metrics['subscriptions_created'] += 1

        return subscription

    def once(
        self,
        event_type: str,
        callback: Callable[[Event], None],
        **kwargs
    ) -&gt; Subscription:
        &quot;&quot;&quot;Subscribe for exactly one event.&quot;&quot;&quot;
        return self.on(event_type, callback, max_calls=1, **kwargs)

    def off(self, subscription: Subscription) -&gt; bool:
        &quot;&quot;&quot;Unsubscribe from an event.&quot;&quot;&quot;
        with self._lock:
            subs = self._subscriptions.get(subscription.event_type, [])
            for i, sub in enumerate(subs):
                if sub.id == subscription.id:
                    subs.pop(i)
                    self._metrics['subscriptions_removed'] += 1
                    return True
        return False

    def emit(
        self,
        event_type: str,
        data: Any = None,
        source: str = None,
        correlation_id: str = None,
        caused_by: Event = None,
        wait: bool = False
    ) -&gt; Optional[List[Future]]:
        &quot;&quot;&quot;
        Emit an event to all matching subscribers.

        Args:
            event_type: Type of event.
            data: Event payload.
            source: Source identifier.
            correlation_id: For tracing related events.
            caused_by: Parent event for causal tracking.
            wait: If True, wait for all callbacks to complete.

        Returns:
            List of Futures if wait=False, None otherwise.
        &quot;&quot;&quot;
        if event_type in self._paused_events:
            logger.debug(f&quot;Event {event_type} is paused&quot;)
            return None

        # Backpressure check
        if self._pending_count &gt;= self._max_queue_size:
            self._metrics['events_dropped'] += 1
            logger.warning(f&quot;Event dropped due to backpressure: {event_type}&quot;)
            return None

        event = Event(
            type=event_type,
            data=data,
            source=source or &quot;emit&quot;,
            correlation_id=correlation_id,
        )

        if caused_by:
            event.caused_by(caused_by)

        self._metrics['events_emitted'] += 1

        # Collect matching subscriptions
        with self._lock:
            subscriptions = list(self._subscriptions.get(event_type, []))
            subscriptions.extend(self._subscriptions.get(&quot;*&quot;, []))

        futures = []
        expired = []

        for sub in subscriptions:
            # Check if callback is still valid (weak refs)
            callback = sub.get_callback()
            if callback is None:
                expired.append(sub)
                continue

            # Check filters
            if not sub.matches(event):
                continue

            sub.call_count += 1

            # Execute based on priority
            if sub.priority == EventPriority.CRITICAL:
                # Synchronous execution for critical handlers
                self._execute_callback(sub, callback, event)
            else:
                # Async execution for others
                self._pending_count += 1
                future = self._executor.submit(
                    self._execute_callback_with_tracking,
                    sub, callback, event
                )
                futures.append(future)

        # Clean up expired weak references
        for sub in expired:
            self.off(sub)

        # Wait if requested
        if wait and futures:
            for future in futures:
                future.result()
            return None

        return futures if futures else None

    def _execute_callback(
        self,
        sub: Subscription,
        callback: Callable,
        event: Event
    ) -&gt; None:
        &quot;&quot;&quot;Execute callback with error handling.&quot;&quot;&quot;
        try:
            callback(event)
            self._metrics['events_delivered'] += 1
        except Exception as e:
            self._metrics['errors'] += 1
            error_handler = sub.error_handler or self._default_error_handler
            error_handler(e, event, sub)

    def _execute_callback_with_tracking(
        self,
        sub: Subscription,
        callback: Callable,
        event: Event
    ) -&gt; None:
        &quot;&quot;&quot;Execute callback with pending count tracking.&quot;&quot;&quot;
        try:
            self._execute_callback(sub, callback, event)
        finally:
            self._pending_count -= 1

    def _cleanup_dead_subscription(self, event_type: str, sub_id: str):
        &quot;&quot;&quot;Called when a weak-referenced object is garbage collected.&quot;&quot;&quot;
        with self._lock:
            subs = self._subscriptions.get(event_type, [])
            self._subscriptions[event_type] = [
                s for s in subs if s.id != sub_id
            ]
            self._metrics['subscriptions_removed'] += 1

    def _log_error(
        self,
        error: Exception,
        event: Event,
        subscription: Subscription
    ) -&gt; None:
        &quot;&quot;&quot;Default error handler.&quot;&quot;&quot;
        logger.error(
            f&quot;Error in event handler:\n&quot;
            f&quot;  Event: {event.type} (id={event.id})\n&quot;
            f&quot;  Subscription: {subscription.id}\n&quot;
            f&quot;  Error: {error}\n&quot;
            f&quot;  Traceback: {traceback.format_exc()}&quot;
        )

    @contextmanager
    def pause(self, *event_types: str):
        &quot;&quot;&quot;Temporarily pause specific event types.&quot;&quot;&quot;
        try:
            for et in event_types:
                self._paused_events.add(et)
            yield
        finally:
            for et in event_types:
                self._paused_events.discard(et)

    def get_metrics(self) -&gt; dict:
        &quot;&quot;&quot;Return current metrics.&quot;&quot;&quot;
        with self._lock:
            return {
                **self._metrics,
                'pending_events': self._pending_count,
                'active_subscriptions': sum(
                    len(subs) for subs in self._subscriptions.values()
                ),
            }

    def clear(self, event_type: str = None) -&gt; None:
        &quot;&quot;&quot;Clear subscriptions.&quot;&quot;&quot;
        with self._lock:
            if event_type:
                removed = len(self._subscriptions.pop(event_type, []))
            else:
                removed = sum(len(s) for s in self._subscriptions.values())
                self._subscriptions.clear()
            self._metrics['subscriptions_removed'] += removed

    def shutdown(self, wait: bool = True) -&gt; None:
        &quot;&quot;&quot;Shutdown the executor.&quot;&quot;&quot;
        self._executor.shutdown(wait=wait)
</code></pre>
<hr />
<h2 id="common-pitfalls-and-anti-patterns">Common Pitfalls and Anti-Patterns</h2>
<div style="background: #3d2525;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #f85149">Anti-Pattern 1: The God Subject</strong>
<p style="color: #ddd; margin: 8px 0">A single subject that everything observes, creating a tight coupling bottleneck.</p>
<pre><code class="language-python"># BAD: Everything watches one global event bus
class Application:
    event_bus = GlobalEventBus()  # Singleton!

# All components coupled through single point
user_service.events = Application.event_bus
order_service.events = Application.event_bus
inventory_service.events = Application.event_bus
# Any change to event_bus affects everything
</code></pre>
<p style="color: #4ecdc4; margin-top: 12px"><strong>Fix:</strong> Domain-specific event buses with clear boundaries.</p>
</div>
<div style="background: #3d2525;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #f85149">Anti-Pattern 2: Observer Cascade</strong>
<p style="color: #ddd; margin: 8px 0">Observer A triggers Observer B which triggers Observer A.</p>
<pre><code class="language-python"># BAD: Infinite loop
@event_bus.on('user.updated')
def sync_profile(event):
    update_profile(event.data)
    event_bus.emit('profile.updated', event.data)

@event_bus.on('profile.updated')
def sync_user(event):
    update_user(event.data)
    event_bus.emit('user.updated', event.data)  # Loop!
</code></pre>
<p style="color: #4ecdc4; margin-top: 12px"><strong>Fix:</strong> Use correlation IDs or event source tracking to detect cycles.</p>
</div>
<div style="background: #3d2525;padding: 16px; margin: 20px 0; border-radius: 0 8px 8px 0">
<strong style="color: #f85149">Anti-Pattern 3: Synchronous Blocking</strong>
<p style="color: #ddd; margin: 8px 0">Slow observer blocks all other observers.</p>
<pre><code class="language-python"># BAD: 5 second database write blocks email
@event_bus.on('order.created')
def audit_log(event):
    database.insert_slow(event.data)  # 5 seconds!

@event_bus.on('order.created')
def send_email(event):
    # Waits 5 seconds because audit_log runs first
    email.send(event.data)
</code></pre>
<p style="color: #4ecdc4; margin-top: 12px"><strong>Fix:</strong> Use async execution with priorities and timeouts.</p>
</div>
<hr />
<div class="concept-section type-deep-learning">
<h2 id="deep-learning-qa">Deep Learning Q&A</h2>
<p style="color: #64748b; margin-bottom: 24px;">Challenge yourself with these open-ended questions. Each answer leads to deeper exploration.</p>

<!-- Question 1: Real-Time Notification System -->
<div style="background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #92400e; margin: 0 0 16px 0;">Q1: You're building a real-time notification system where users subscribe to topics (sports scores, stock prices, breaking news). How would you implement the Observer pattern to handle millions of subscribers with varying delivery requirements?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Use a <strong>hierarchical observer architecture</strong>: Instead of one subject notifying millions of observers directly, create a tree structure. The root subject notifies regional aggregators, which notify local dispatchers, which notify end users. This distributes the notification load and allows for regional optimizations.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">Implement <strong>topic-based partitioning</strong>: Partition subscribers by topic (sports, stocks, news) and further by sub-topic (NBA, NFL, MLB). Each partition runs independently, so a spike in sports traffic doesn't affect stock alerts. Use consistent hashing to distribute topics across notification servers.</p>

<!-- Nested Q1.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.1: Some users need instant push notifications (stock traders) while others are fine with batched updates (casual sports fans). How do you handle different delivery priorities?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Create <strong>priority queues per subscription tier</strong>: Premium subscribers get dedicated notification channels with direct push. Standard subscribers are batched every 30 seconds. Implement a <code>DeliveryPolicy</code> interface that each subscription carries, specifying latency tolerance, batching window, and retry behavior. The dispatcher checks the policy before choosing the delivery path.</p>

<!-- Nested Q1.1.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.1: A premium user's device is offline during a critical stock alert. How do you ensure they eventually receive it without duplicating notifications?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>persistent notification queues with acknowledgment</strong>: Store pending notifications in a durable queue (Redis Streams, Kafka) keyed by user_id. Mark notifications as "pending" until the client acknowledges receipt. On reconnect, the client requests all unacknowledged notifications. Include a unique notification_id to allow client-side deduplication if retries occur.</p>
</div>
</details>
</div>

<!-- Nested Q1.1.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.2: How do you prevent a flood of notifications when a user comes back online after being offline for hours?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>notification coalescing and summarization</strong>: Group similar notifications (e.g., "15 NBA score updates") into summaries when count exceeds threshold. Implement TTL on notifications - stock alerts older than 15 minutes are stale and should be marked as "historical" rather than pushed. Let users configure their offline catchup preferences: "Show summary only" vs "Show last 10" vs "Show all".</p>
</div>
</details>
</div>

<!-- Nested Q1.1.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.3: Premium users pay more but still overwhelm the system during market volatility. How do you handle fair resource allocation?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>token bucket rate limiting per user tier</strong>: Premium users get 100 notifications/minute, standard gets 20. During spikes, excess notifications queue with priority ordering. Add <strong>circuit breakers per topic</strong>: If a topic (e.g., volatile stock) generates more than 1000 events/second, switch to "digest mode" that sends summaries every 5 seconds instead of individual updates. This protects the system while maintaining value for users.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q1.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.2: A breaking news event causes millions of simultaneous notifications. How do you prevent the notification system from collapsing?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Implement <strong>backpressure with graceful degradation</strong>: When queue depth exceeds threshold, switch from push to pull model temporarily. Notify clients "High traffic - poll for updates." Use <strong>fan-out limiting</strong>: Process notifications in waves (first 100K, then next 100K) with small delays between waves. This smooths the spike while ensuring everyone eventually receives the notification.</p>

<!-- Nested Q1.2.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.1: The waves approach means some users get news 5 minutes later than others. How do you decide who goes first?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>weighted priority scoring</strong>: Score = (subscription_tier * 10) + (engagement_level * 5) + (random_factor). Premium users score higher but the random factor ensures some standard users get early access too, preventing perception of unfairness. For truly critical news (safety alerts), bypass the queue entirely and use broadcast channels (push notification services have "high priority" modes for this).</p>
</div>
</details>
</div>

<!-- Nested Q1.2.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.2: What if the database storing subscriber lists also gets overwhelmed during the spike?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Pre-materialize subscriber lists</strong>: Don't query "who subscribes to breaking news" during an event. Maintain pre-computed lists in Redis for hot topics. Update these lists asynchronously when subscriptions change. During high load, work from these cached lists even if slightly stale (a user who subscribed 5 minutes ago might miss this notification but will get the next one).</p>
</div>
</details>
</div>

<!-- Nested Q1.2.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.3: How do you test that your system actually handles these spikes before they happen in production?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Run <strong>chaos engineering exercises</strong>: Simulate "Super Bowl ending" or "Market crash" events in staging with realistic subscriber counts. Use shadow traffic: replay production subscription patterns against test infrastructure. Implement <strong>load shedding drills</strong>: Intentionally trigger degradation modes monthly to ensure they work. Track metrics like "time to full delivery" and "notification loss rate" to establish baselines and SLOs.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q1.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.3: Users want to subscribe to complex conditions like "Notify me when AAPL drops 5% AND VIX rises above 30." How do you extend the Observer pattern for composite subscriptions?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Implement a <strong>Complex Event Processing (CEP) layer</strong>: Create intermediate "virtual subjects" that observe multiple real subjects and emit events only when conditions match. Use a rule engine (like Drools or custom DSL) to define composite conditions. The user's subscription attaches to the virtual subject, not the raw data streams. This separates condition evaluation from notification delivery.</p>

<!-- Nested Q1.3.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.1: Millions of users have unique composite conditions. How do you evaluate them efficiently?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Index conditions by their constituent parts</strong>: Build an inverted index from "data point" to "rules that reference it." When AAPL price updates, find all rules mentioning AAPL, evaluate only those. Further optimize with <strong>partial evaluation caching</strong>: If a rule has 3 conditions and only 1 data point changed, re-evaluate only that condition and combine with cached results of others.</p>
</div>
</details>
</div>

<!-- Nested Q1.3.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.2: A user creates a rule that fires constantly (e.g., "notify when price changes"). How do you prevent abuse?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Validate rules at creation time with <strong>static analysis</strong>: Reject rules that would fire more than N times per hour based on historical data patterns. For edge cases that slip through, implement <strong>per-rule rate limiting</strong>: Max 10 notifications per hour per rule. Auto-disable rules that consistently hit limits and notify the user. Charge premium users for high-frequency rules to align incentives.</p>
</div>
</details>
</div>

<!-- Nested Q1.3.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.3: The rule engine becomes a single point of failure. How do you make it resilient?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Partition rules across multiple rule engine instances</strong>: Use consistent hashing based on user_id or rule_id. Each instance handles a subset of rules independently. Replicate state across instances for failover. If an instance dies, its rules are redistributed to surviving instances. Keep rule state simple enough to rebuild from durable storage (the rules themselves, plus recent data point values).</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Question 2: Memory Leaks -->
<div style="background: linear-gradient(135deg, #dbeafe 0%, #bfdbfe 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #1e40af; margin: 0 0 16px 0;">Q2: Your React-like UI framework uses Observer for component state management. Users report that long-running single-page applications become sluggish over time. You suspect observer memory leaks. How do you diagnose and fix this?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Start with <strong>subscription lifecycle auditing</strong>: Add instrumentation to track every subscribe/unsubscribe call with timestamps and stack traces. Compare "active subscriptions" count over time - it should correlate with visible component count. A growing delta indicates leaks. Common culprits: components that subscribe in constructor but forget to unsubscribe in destructor, especially during error conditions or early returns.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">Implement <strong>automatic cleanup hooks</strong>: Tie subscription lifecycle to component lifecycle automatically. When a component unmounts, all its subscriptions are cancelled without explicit unsubscribe calls. This is how React's useEffect cleanup and Vue's onUnmounted work.</p>

<!-- Nested Q2.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.1: Developers are creating subscriptions inside loops or callbacks, making it hard to track ownership. How do you enforce proper subscription hygiene?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Introduce a <strong>SubscriptionScope pattern</strong>: Require all subscriptions to be created within a scope that tracks them. When the scope closes, all its subscriptions are automatically disposed. Provide a lint rule that flags subscribe() calls outside of a scope. This forces developers to think about subscription ownership at creation time rather than hoping they remember to clean up later.</p>

<!-- Nested Q2.1.1 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.1: The lint rule has too many false positives in legacy code. How do you adopt it incrementally?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>granular rule enablement</strong>: Enable the lint rule only for new files or specific directories first. Maintain an allowlist of legacy files that are exempt. Track "lint debt" metrics and allocate time each sprint to fix legacy violations. Provide an automated codemod that wraps existing subscribe() calls in scopes with TODO comments, making the migration mechanical.</p>
</div>
</details>
</div>

<!-- Nested Q2.1.2 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.2: Some subscriptions legitimately need to outlive their creating component (global state observers). How do you handle those?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Create an explicit <strong>GlobalSubscriptionRegistry</strong>: Subscriptions that need longer lifetimes must be registered here with a reason annotation. The registry is visible in dev tools for debugging. Provide an API like <code>globalScope.subscribe(reason: "Auth state sync")</code> that documents intent. Audit the registry periodically - if it grows unbounded, something is wrong.</p>
</div>
</details>
</div>

<!-- Nested Q2.1.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.3: How do you detect leaks that only manifest after hours of user interaction?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>automated soak tests</strong>: Run scripted user journeys (navigate, interact, repeat) for hours in CI. Monitor subscription counts, memory usage, and event throughput over time. Flag any metric that shows linear growth. Also add <strong>production telemetry</strong>: Sample 1% of users and report subscription metrics every 5 minutes. Correlate with session duration to find "the longer they use it, the worse it gets" patterns.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q2.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.2: You've added weak references to auto-cleanup observers. Now users complain that their callbacks randomly stop working. What went wrong?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Weak references don't work well with <strong>inline functions or closures</strong>: When users write <code>store.subscribe(() => this.update())</code>, the lambda has no strong reference elsewhere and gets garbage collected immediately. The callback "disappears" unpredictably. Solution: Require callbacks to be methods on objects that are strongly referenced, or provide a different API that makes ownership explicit.</p>

<!-- Nested Q2.2.1 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.1: Forcing users to avoid lambdas hurts developer experience. Is there a better approach?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>explicit subscription tokens instead of weak refs</strong>: <code>const sub = store.subscribe(() => ...); onUnmount(() => sub.dispose());</code> The subscription holds a strong reference to the callback, and the token gives users explicit control. This is the pattern React, RxJS, and most modern libraries use. Weak refs are rarely the right default - explicit is better than implicit for resource management.</p>
</div>
</details>
</div>

<!-- Nested Q2.2.2 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.2: What if users forget to call dispose() on the subscription token?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Add <strong>development-mode leak warnings</strong>: Track subscription creation location and duration. If a subscription lives longer than expected (e.g., component unmounted 30 seconds ago but subscription still active), log a warning with the creation stack trace. In strict mode, throw an error. This catches bugs during development without affecting production performance.</p>
</div>
</details>
</div>

<!-- Nested Q2.2.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.3: How do popular frameworks like React and Vue actually handle this internally?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">React uses <strong>effect cleanup functions</strong>: useEffect returns a cleanup function that's called on unmount. Vue uses <strong>scope-based tracking</strong>: effectScope() creates a container that auto-disposes all effects when stopped. Both approaches tie subscription lifetime to component lifetime automatically. The key insight is making cleanup the default path, not an afterthought.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q2.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.3: The memory leak fix worked, but now users report that observers are being cleaned up too aggressively - callbacks fire fewer times than expected. How do you debug this?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">This is the <strong>premature disposal problem</strong>: The component thinks it's done, but the user's mental model expects the subscription to still be active. Add <strong>subscription state visualization</strong> in dev tools: Show active subscriptions per component, their creation time, and disposal reason. This helps users understand "why did my callback stop" without guessing.</p>

<!-- Nested Q2.3.1 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.1: The subscription was disposed because of a re-render, but the user expected it to survive re-renders. How do you handle this?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Distinguish between <strong>unmount disposal</strong> and <strong>re-render recreation</strong>: Subscriptions should persist across re-renders unless their dependencies change. Implement dependency tracking: <code>subscribe(callback, [dep1, dep2])</code> - only recreate subscription when dependencies change. This is exactly how React's useEffect dependency array works. Without deps, recreate every render; with empty deps, never recreate.</p>
</div>
</details>
</div>

<!-- Nested Q2.3.2 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.2: A callback references stale data from a previous render because it wasn't recreated. How do you avoid stale closures?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Two approaches: (1) <strong>Refs for mutable values</strong>: Store the latest value in a ref that the callback reads, so it always gets fresh data. (2) <strong>Include values in dependency array</strong>: The callback is recreated with new closure when values change. Trade-off: Refs are more performant but harder to reason about; deps are cleaner but cause more subscription churn.</p>
</div>
</details>
</div>

<!-- Nested Q2.3.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.3: How do you write tests that catch these subtle subscription lifecycle bugs?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Create <strong>lifecycle assertion helpers</strong>: <code>expectSubscriptionActive()</code>, <code>expectSubscriptionDisposed()</code>, <code>expectCallbackCalledTimes(n)</code>. Write tests that explicitly exercise the edge cases: mount-unmount-remount, rapid re-renders, error during render, conditional rendering. Use fake timers to control when garbage collection would run (in languages that support it) to test weak reference behavior deterministically.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Question 3: Push vs Pull -->
<div style="background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #166534; margin: 0 0 16px 0;">Q3: You're designing an analytics dashboard that displays real-time metrics from 50 different data sources. Each source updates at different frequencies (some every second, some every hour). Should you use push or pull observer model, and how do you optimize for this heterogeneous update pattern?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Use a <strong>hybrid approach based on update frequency</strong>: High-frequency sources (>1 update/second) use push model - the source notifies the dashboard immediately. Low-frequency sources (<1 update/minute) use pull model - the dashboard polls on a schedule. Medium-frequency sources use push with batching - collect updates for 5 seconds, then push the batch. This minimizes both latency for fast sources and overhead for slow sources.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">Implement <strong>adaptive switching</strong>: Monitor actual update rates and automatically migrate sources between push/pull as their behavior changes. A source that was quiet but suddenly becomes active should switch from pull to push dynamically.</p>

<!-- Nested Q3.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.1: With push model for fast sources, the dashboard can't keep up with rendering all updates. How do you prevent the UI from becoming unresponsive?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Implement <strong>render throttling with latest-value semantics</strong>: Buffer incoming updates and render at a fixed frame rate (60fps = every 16ms). When rendering, use only the latest value for each metric, discarding intermediate values. The observer still receives all updates (for logging/persistence), but the render observer only sees sampled snapshots. This decouples data ingestion from display.</p>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.1: Some metrics need to show every value (like trade executions) not just the latest. How do you handle that?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Support <strong>multiple delivery semantics per subscription</strong>: <code>subscribe(metric, { mode: 'latest' })</code> vs <code>subscribe(metric, { mode: 'all' })</code>. The "all" mode buffers updates and delivers them in order during the next render cycle, even if there are hundreds. For extreme volumes, virtualize the display: only render visible rows, keep the rest in memory. Let users toggle between "streaming" (all values) and "snapshot" (latest only) views.</p>
</div>
</details>
</div>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.2: The buffering adds latency. How do you minimize time-to-glass for critical metrics?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Add a <strong>priority lane for critical metrics</strong>: Mark certain subscriptions as "immediate" which bypass the buffer and trigger synchronous render. Use sparingly - only for alerts or user-initiated actions. Combine with <code>requestAnimationFrame</code> scheduling: immediate updates wait for the next frame but skip the batching delay. This gives sub-frame latency (~10ms) for critical data while still protecting the render loop.</p>
</div>
</details>
</div>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.3: Different users care about different metrics. How do you prioritize rendering for the user's focus?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>viewport-aware prioritization</strong>: Metrics visible on screen get highest render priority. Metrics in collapsed panels or off-screen get lower priority (update less frequently or skip frames). Track user focus: if they're hovering over a chart or have a panel expanded, boost that metric's priority. This is similar to how browsers prioritize rendering visible content.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q3.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.2: With pull model for slow sources, you waste resources polling sources that haven't changed. How do you optimize polling?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Use <strong>conditional polling with ETags/timestamps</strong>: Each poll request includes "If-Modified-Since" or ETag. Source responds with 304 Not Modified if nothing changed (minimal bandwidth). Implement <strong>exponential backoff</strong>: If a source returns unchanged multiple times, increase polling interval (1min -> 2min -> 5min). Reset to base interval on first change detected.</p>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.2.1: Some sources don't support conditional requests. How do you avoid unnecessary data transfer?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>client-side change detection</strong>: Hash the response and compare with previous hash. Only propagate to observers if hash differs. For structured data, use deep equality comparison on specific fields that matter. Cache responses with their hashes. This turns "always changed" sources into "changed only when actually different" at the cost of local computation.</p>
</div>
</details>
</div>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.2.2: You have 50 sources to poll. How do you schedule polling without creating request bursts?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>staggered scheduling with jitter</strong>: Instead of polling all 50 sources at :00, spread them across the interval. If base interval is 60 seconds, poll source 1 at :00, source 2 at :01.2, source 3 at :02.4, etc. Add random jitter (+-10%) to prevent synchronization after restarts. Implement a <strong>polling scheduler</strong> that maintains a priority queue sorted by next-poll-time and processes entries sequentially.</p>
</div>
</details>
</div>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.2.3: A polled source suddenly starts updating rapidly. How do you detect this and switch to push?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Track <strong>change frequency per source</strong>: If a source changes on >80% of polls for 5 consecutive polls, it's become "hot." Check if the source supports push (WebSocket, SSE) and switch automatically. If push isn't available, decrease polling interval to minimum and alert operators that this source needs push support. Conversely, if a push source goes quiet for 10 minutes, consider switching to pull to reduce connection overhead.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q3.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.3: The dashboard runs in a browser. With 50 data sources, you'll hit browser connection limits and battery drain on mobile. How do you optimize the transport layer?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Implement a <strong>backend aggregation layer</strong>: Instead of 50 browser-to-source connections, have the browser connect to one backend service that aggregates all sources. The backend maintains persistent connections to sources and multiplexes updates to browsers over a single WebSocket. This respects browser connection limits (6-8 per domain), reduces mobile battery usage, and allows server-side optimizations.</p>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.3.1: The aggregation layer adds latency. How do you minimize the overhead?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Deploy aggregation servers <strong>close to data sources</strong> (same region/datacenter). Use <strong>streaming protocols</strong> (WebSocket, gRPC streaming) end-to-end to avoid request/response overhead. Implement <strong>delta compression</strong>: Only send changed fields, not entire objects. For low-latency requirements, run aggregators as edge functions (Cloudflare Workers, Lambda@Edge) to minimize hops.</p>
</div>
</details>
</div>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.3.2: Users only care about 5 of the 50 metrics. How do you avoid wasting bandwidth on unused data?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>subscription-based filtering</strong>: The browser tells the aggregator which metrics it wants. Aggregator only forwards subscribed metrics. Use GraphQL subscriptions or a custom subscription protocol. Lazy-load metric data: Only subscribe when a widget becomes visible, unsubscribe when hidden. Track subscription counts server-side to optimize which sources to poll/connect to.</p>
</div>
</details>
</div>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.3.3: The WebSocket connection drops frequently on poor networks. How do you maintain update continuity?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>resumable subscriptions with sequence numbers</strong>: Each update has a sequence number. On reconnect, client sends "last seen sequence X." Server replays all updates since X. If gap is too large, send full snapshot instead. Use <strong>offline buffering</strong>: Store updates locally (IndexedDB) during disconnect, reconcile on reconnect. Add visual indicators showing "Last updated 30s ago" so users know data might be stale.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>
</div>

<!-- Pros and Cons Section -->
<hr />
<div class="concept-section type-analysis">
<h2 id="pros-cons-analysis">Observer Pattern: Pros & Cons Analysis</h2>

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 24px; margin: 24px 0;">

<!-- Pros -->
<div style="background: linear-gradient(135deg, #ecfdf5 0%, #d1fae5 100%); border-radius: 16px; padding: 24px;">
<h3 style="color: #065f46; margin: 0 0 20px 0; display: flex; align-items: center; gap: 8px;">
<span style="font-size: 24px;">+</span> Pros
</h3>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Loose Coupling Between Components</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Subjects don't need to know the concrete types of their observers. New observers can be added without modifying the subject code.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Too many observers can create implicit coupling through shared event types</li>
<li>Document your event contracts as carefully as you would API contracts</li>
<li>Use TypeScript/typed events to catch breaking changes at compile time</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Supports Broadcast Communication</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">One state change can notify any number of interested parties automatically, without the subject tracking who they are.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Broadcast to thousands of observers can block the notifying thread</li>
<li>Consider async notification for large observer counts (>100)</li>
<li>Monitor notification latency percentiles, not just averages</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Enables Reactive Programming Patterns</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Forms the foundation for reactive frameworks (RxJS, Vue reactivity, MobX) that enable declarative, data-driven UIs.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Reactive chains can become hard to debug - invest in devtools</li>
<li>Glitches (temporary inconsistent states) can occur during multi-value updates</li>
<li>Learn your framework's specific batching and scheduling behavior</li>
</ul>
</div>
</div>
</div>

<!-- Cons -->
<div style="background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%); border-radius: 16px; padding: 24px;">
<h3 style="color: #991b1b; margin: 0 0 20px 0; display: flex; align-items: center; gap: 8px;">
<span style="font-size: 24px;">-</span> Cons
</h3>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Memory Leaks from Forgotten Subscriptions</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Observers that subscribe but never unsubscribe create memory leaks, especially in long-running applications or SPAs.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Tie subscription lifecycle to component lifecycle automatically</li>
<li>Use subscription tokens that must be explicitly disposed</li>
<li>Add development-mode warnings for leaked subscriptions</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Unpredictable Notification Order</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Standard Observer provides no guarantees about which observer is notified first. Dependencies between observers cause subtle bugs.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Design observers to be truly independent with no order assumptions</li>
<li>If order matters, use priority queues or explicit dependency declaration</li>
<li>Document any ordering requirements prominently</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Cascade Effects and Debugging Difficulty</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">One event triggers observers that trigger more events, creating hard-to-trace chains. Stack traces become meaningless.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Add correlation IDs to events for distributed tracing</li>
<li>Implement cycle detection to catch infinite notification loops</li>
<li>Build event flow visualization tools for debugging</li>
</ul>
</div>
</div>
</div>
</div>
</div>

<hr />
<h2 id="related-patterns">Related Patterns</h2>
<ul>
<li><a href="/topic/design-patterns/mediator">[Mediator]</a> - Centralizes communication instead of direct observer relationships</li>
<li><a href="/topic/system-design/message-queues">[Pub/Sub]</a> - Distributed observer pattern with message broker</li>
<li><a href="/topic/system-design/event-sourcing">[Event Sourcing]</a> - Store events as the source of truth</li>
<li><a href="/topic/system-design/cqrs">[CQRS]</a> - Separate read/write models, often event-driven</li>
<li><a href="/topic/design-patterns/chain-of-responsibility">[Chain of Responsibility]</a> - When observer order matters</li>
<li><a href="/topic/design-patterns/state">[State]</a> - Often combined with Observer for state machines</li>
</ul>
<hr />
<h2 id="summary-key-takeaways-for-interviews">Summary: Key Takeaways for Interviews</h2>
<ol>
<li>
<p><strong>Push vs Pull:</strong> Push is simpler but couples subject to observer needs. Pull is more flexible but has consistency challenges. Hybrid approaches work best in practice.</p>
</li>
<li>
<p><strong>Memory Leaks:</strong> Always pair subscribe with unsubscribe. Consider weak references for automatic cleanup, but understand their limitations.</p>
</li>
<li>
<p><strong>Event Ordering:</strong> Classic Observer provides no ordering guarantees. If order matters, use priorities, dependencies, or consider a different pattern.</p>
</li>
<li>
<p><strong>Backpressure:</strong> Without backpressure handling, fast producers overwhelm slow consumers. Choose strategy based on data criticality.</p>
</li>
<li>
<p><strong>Error Handling:</strong> Decide early: fail fast (one failure stops all) or fail safe (isolate failures). Most production systems use fail safe with error logging.</p>
</li>
<li>
<p><strong>Reactive Streams:</strong> Modern evolution of Observer that adds error channels, completion signals, backpressure, and composable operators.</p>
</li>
<li>
<p><strong>Distributed Systems:</strong> Observer across services requires handling out-of-order delivery, at-least-once semantics, and idempotency.</p>
</li>
</ol>
