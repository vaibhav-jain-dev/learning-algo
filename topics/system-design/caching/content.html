<style>
/* Mobile-specific styles for iPhone 15 and similar devices */
@media screen and (max-width: 480px) {
    /* Force all grid layouts to single column */
    [style*="grid-template-columns"] {
        display: block !important;
    }
    [style*="grid-template-columns"] > div {
        margin-bottom: 16px !important;
    }
    /* Adjust padding for mobile */
    [style*="padding: 32px"],
    [style*="padding: 24px"] {
        padding: 16px !important;
    }
    /* Smaller headings */
    h4[style*="font-size: 18px"],
    h4[style*="font-size: 16px"] {
        font-size: 15px !important;
    }
    /* Readable font sizes */
    [style*="font-size: 13px"],
    [style*="font-size: 12px"],
    [style*="font-size: 11px"],
    [style*="font-size: 10px"] {
        font-size: 13px !important;
        line-height: 1.6 !important;
    }
    /* Flex containers stack vertically */
    [style*="display: flex"][style*="gap"] {
        flex-direction: column !important;
    }
    /* Better spacing for nested content */
    [style*="padding-left: 64px"],
    [style*="padding-left: 48px"],
    [style*="padding-left: 40px"] {
        padding-left: 16px !important;
    }
    /* Code blocks */
    pre {
        font-size: 12px !important;
        padding: 12px !important;
        overflow-x: auto !important;
    }
    pre code {
        font-size: 12px !important;
    }
    /* Tables */
    table {
        font-size: 12px !important;
        display: block !important;
        overflow-x: auto !important;
    }
    th, td {
        padding: 8px !important;
        font-size: 12px !important;
    }
}
</style>
<h1 id="caching">Caching</h1>
<div class="tldr-box">
    <div class="tldr-header">TL;DR</div>
    <ul class="tldr-list">
        <li>Caching stores frequently accessed data in fast memory (100-1000x faster than disk/network)</li>
        <li>Common strategies: Cache-Aside (lazy load), Write-Through (sync), Write-Behind (async)</li>
        <li>Eviction policies: LRU (most popular), LFU, FIFO, TTL-based</li>
        <li>Prevent stampede: use jittered TTLs, locking, or stale-while-revalidate</li>
        <li>Best for read-heavy workloads (10:1 read/write ratio) with acceptable staleness</li>
    </ul>
</div>
<div class="concept-section type-definition">
<h2 id="overview">Overview</h2>
<p>Caching is a technique that stores copies of frequently accessed data in a faster storage layer (like memory) to reduce latency and decrease load on the primary data source. Think of it as keeping your most-used tools on your desk instead of walking to the storage room every time you need them.</p>
</div>
<hr />
<div class="concept-section type-important">
<h2 id="why-this-matters">Why This Matters</h2>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; margin: 0 0 16px 0; font-size: 16px">Real Company Examples</h4>
<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 16px">
<div style="background: #ffffff;border-radius: 8px; padding: 16px">
<div style="color: #0f172a; font-weight: 600; margin-bottom: 8px">Netflix</div>
<div style="color: #475569; font-size: 14px">Caches movie metadata and thumbnails at edge servers. Reduced origin requests by 95% and serves 200+ million users globally.</div>
</div>
<div style="background: #ffffff;border-radius: 8px; padding: 16px">
<div style="color: #0f172a; font-weight: 600; margin-bottom: 8px">Facebook</div>
<div style="color: #475569; font-size: 14px">Uses Memcached clusters caching 75% of all reads. Handles billions of requests per second with sub-millisecond latency.</div>
</div>
<div style="background: #ffffff;border-radius: 8px; padding: 16px">
<div style="color: #0f172a; font-weight: 600; margin-bottom: 8px">Amazon</div>
<div style="color: #475569; font-size: 14px">Every 100ms of latency costs 1% in sales. Caching product pages and recommendations saves millions in revenue.</div>
</div>
</div>
</div>
<p><strong>Why caching is essential:</strong></p>
<ul>
<li><strong>Speed</strong>: Memory access is ~100x faster than disk, ~1000x faster than network</li>
<li><strong>Cost Reduction</strong>: Serve more requests with fewer database servers</li>
<li><strong>Scalability</strong>: Handle traffic spikes without scaling expensive backend resources</li>
<li><strong>User Experience</strong>: Users abandon sites that take more than 3 seconds to load</li>
</ul>
</div>
<hr />
<div class="concept-section type-definition">
<h2 id="core-concepts">Core Concepts</h2>
<h3 id="the-library-analogy">The Library Analogy</h3>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<div style="color: #1e293b; font-size: 15px; line-height: 1.7">
<p>Imagine a <strong>university library</strong>:</p>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 16px">
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #dc2626; font-weight: 600; margin-bottom: 8px">Without Caching</div>
<ul style="color: #475569; margin: 0; padding-left: 20px; font-size: 14px">
<li>Every student walks to the archive basement</li>
<li>Finds the book in the catalog</li>
<li>Retrieves it from storage</li>
<li>Walks back to their desk</li>
<li><strong>Time: 10 minutes per book</strong></li>
</ul>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #16a34a; font-weight: 600; margin-bottom: 8px">With Caching</div>
<ul style="color: #475569; margin: 0; padding-left: 20px; font-size: 14px">
<li>Popular books kept on a "reserve shelf" near entrance</li>
<li>Students check reserve shelf first</li>
<li>If found (cache hit): grab and go</li>
<li>If not found (cache miss): go to archive</li>
<li><strong>Time: 30 seconds (hit) or 10 min (miss)</strong></li>
</ul>
</div>
</div>
</div>
</div>
<h3 id="cache-terminology">Cache Terminology</h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Library Analogy</th>
<th>Technical Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cache Hit</strong></td>
<td>Book found on reserve shelf</td>
<td>Data found in cache</td>
</tr>
<tr>
<td><strong>Cache Miss</strong></td>
<td>Book not on shelf, go to archive</td>
<td>Data not in cache, fetch from source</td>
</tr>
<tr>
<td><strong>TTL</strong></td>
<td>Books returned to archive after 7 days</td>
<td>Time before cached data expires</td>
</tr>
<tr>
<td><strong>Eviction</strong></td>
<td>Remove least-used books when shelf is full</td>
<td>Remove data when cache is full</td>
</tr>
<tr>
<td><strong>Invalidation</strong></td>
<td>Remove outdated edition when new one arrives</td>
<td>Remove stale data after update</td>
</tr>
</tbody>
</table>
</div>
<hr />
<div class="concept-section type-definition">
<h2 id="how-it-works">How It Works</h2>
<h3 id="cache-hierarchy">Cache Hierarchy</h3>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 20px 0; font-size: 16px">THE CACHING PYRAMID</h4>
<div style="display: flex; flex-direction: column; align-items: center; gap: 8px">
<div style="background: linear-gradient(135deg, #22c55e 0%, #16a34a 100%); color: white; padding: 12px 24px; border-radius: 8px; text-align: center; width: 120px">
<div style="font-weight: 600; font-size: 13px">Browser</div>
<div style="font-size: 11px; opacity: 0.9">~0ms</div>
</div>
<div style="color: #64748b">|</div>
<div style="background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%); color: white; padding: 12px 24px; border-radius: 8px; text-align: center; width: 160px">
<div style="font-weight: 600; font-size: 13px">CDN Edge</div>
<div style="font-size: 11px; opacity: 0.9">~20ms</div>
</div>
<div style="color: #64748b">|</div>
<div style="background: linear-gradient(135deg, #8b5cf6 0%, #7c3aed 100%); color: white; padding: 12px 24px; border-radius: 8px; text-align: center; width: 200px">
<div style="font-weight: 600; font-size: 13px">Application Cache (Redis)</div>
<div style="font-size: 11px; opacity: 0.9">~1ms</div>
</div>
<div style="color: #64748b">|</div>
<div style="background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; padding: 12px 24px; border-radius: 8px; text-align: center; width: 240px">
<div style="font-weight: 600; font-size: 13px">Database Query Cache</div>
<div style="font-size: 11px; opacity: 0.9">~10ms</div>
</div>
<div style="color: #64748b">|</div>
<div style="background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%); color: white; padding: 12px 24px; border-radius: 8px; text-align: center; width: 280px">
<div style="font-weight: 600; font-size: 13px">Database (Disk)</div>
<div style="font-size: 11px; opacity: 0.9">~50-100ms</div>
</div>
</div>
<div style="text-align: center; margin-top: 16px; color: #64748b; font-size: 13px">
    Faster at top, more capacity at bottom
</div>
</div>
<h3 id="caching-strategies">Caching Strategies</h3>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 20px 0; font-size: 16px">CACHE-ASIDE (LAZY LOADING)</h4>
<div style="display: flex; align-items: center; justify-content: center; gap: 16px; flex-wrap: wrap">
<div style="background: #ffffff;border-radius: 8px; padding: 16px 24px; text-align: center">
<div style="color: #1e293b; font-weight: 600">Application</div>
</div>
<div style="display: flex; flex-direction: column; align-items: center; gap: 4px">
<div style="color: #1e293b; font-size: 12px">1. Check</div>
<div style="color: #3b82f6; font-size: 18px">--></div>
</div>
<div style="background: #ffffff;border-radius: 8px; padding: 16px 24px; text-align: center">
<div style="color: #1e293b; font-weight: 600">Cache</div>
<div style="color: #64748b; font-size: 12px; margin-top: 4px">Hit? Return!</div>
</div>
<div style="display: flex; flex-direction: column; align-items: center; gap: 4px">
<div style="color: #1e293b; font-size: 12px">2. Miss?</div>
<div style="color: #ef4444; font-size: 18px">--></div>
</div>
<div style="background: #ffffff;border-radius: 8px; padding: 16px 24px; text-align: center">
<div style="color: #1e293b; font-weight: 600">Database</div>
</div>
</div>
<div style="text-align: center; margin-top: 16px; color: #475569; font-size: 13px">
    3. Store result in cache for next time
</div>
</div>
<h3 id="strategy-comparison">Strategy Comparison</h3>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<div style="overflow-x: auto">
<table style="width: 100%; border-collapse: collapse; color: #1e293b; font-size: 14px">
  <thead>
<tr style="background: #e2e8f0">
<th style="padding: 12px; text-align: left">Strategy</th>
<th style="padding: 12px; text-align: left">Read Path</th>
<th style="padding: 12px; text-align: left">Write Path</th>
<th style="padding: 12px; text-align: left">Best For</th>
</tr>
  </thead>
  <tbody>
<tr style="background: #ffffff">
<td style="padding: 12px;font-weight: 600">Cache-Aside</td>
<td style="padding: 12px">App checks cache, then DB</td>
<td style="padding: 12px">Update DB, invalidate cache</td>
<td style="padding: 12px">General purpose</td>
</tr>
<tr style="background: #f8fafc">
<td style="padding: 12px;font-weight: 600">Write-Through</td>
<td style="padding: 12px">Read from cache</td>
<td style="padding: 12px">Write to cache AND DB together</td>
<td style="padding: 12px">Strong consistency needed</td>
</tr>
<tr style="background: #ffffff">
<td style="padding: 12px;font-weight: 600">Write-Behind</td>
<td style="padding: 12px">Read from cache</td>
<td style="padding: 12px">Write to cache, async DB write</td>
<td style="padding: 12px">Write-heavy workloads</td>
</tr>
<tr style="background: #f8fafc">
<td style="padding: 12px; font-weight: 600">Read-Through</td>
<td style="padding: 12px">Cache fetches from DB on miss</td>
<td style="padding: 12px">N/A</td>
<td style="padding: 12px">Simplified read logic</td>
</tr>
  </tbody>
</table>
</div>
</div>
<h3 id="cache-eviction-policies">Cache Eviction Policies</h3>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 20px 0; font-size: 16px">WHEN THE CACHE IS FULL, WHO GETS EVICTED?</h4>
<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 16px">
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">LRU (Least Recently Used)</div>
<div style="color: #475569; font-size: 13px">Evict item not accessed longest. Most popular choice.</div>
<div style="color: #64748b; font-size: 12px; margin-top: 8px; font-style: italic">"Haven't used this in ages? Out!"</div>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">LFU (Least Frequently Used)</div>
<div style="color: #475569; font-size: 13px">Evict item accessed fewest times overall.</div>
<div style="color: #64748b; font-size: 12px; margin-top: 8px; font-style: italic">"Only used twice ever? Goodbye!"</div>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">FIFO (First In First Out)</div>
<div style="color: #475569; font-size: 13px">Evict oldest item regardless of usage.</div>
<div style="color: #64748b; font-size: 12px; margin-top: 8px; font-style: italic">"You were here first, now leave first."</div>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">TTL (Time To Live)</div>
<div style="color: #475569; font-size: 13px">Items expire after set time period.</div>
<div style="color: #64748b; font-size: 12px; margin-top: 8px; font-style: italic">"Your time is up!"</div>
</div>
</div>
</div>
</div>
<hr />
<div class="concept-section type-warning">
<h2 id="real-life-failure-story">Real-Life Failure Story</h2>
<div style="background: linear-gradient(135deg, #fef2f2 0%, #fee2e2 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #991b1b; margin: 0 0 16px 0; font-size: 16px">The Facebook Cache Stampede (2010)</h4>
<div style="color: #1e293b; font-size: 14px; line-height: 1.7">
<p><strong>What Happened:</strong> Facebook experienced a major outage when a bug caused their entire Memcached cluster to invalidate simultaneously. When cache entries expired at the same time:</p>
<ol style="color: #475569; margin: 12px 0">
<li>Millions of requests found empty caches (cache miss)</li>
<li>All requests hit the database simultaneously</li>
<li>Database servers were overwhelmed and crashed</li>
<li>Even after restart, the stampede repeated</li>
</ol>
<p><strong>The Fix:</strong></p>
<ul style="color: #475569; margin: 12px 0">
<li><strong>Jittered TTLs:</strong> Added random variation to expiration times (e.g., 3600s +/- 300s)</li>
<li><strong>Locking:</strong> Only one request regenerates cache, others wait</li>
<li><strong>Stale-while-revalidate:</strong> Serve stale data while refreshing in background</li>
</ul>
<p><strong>Lesson:</strong> Never let cache entries expire at the same time. Add randomization to everything in distributed systems.</p>
</div>
</div>
</div>
<hr />
<div class="concept-section type-warning">
<h2 id="what-to-watch-out-for">What to Watch Out For</h2>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; margin: 0 0 16px 0; font-size: 16px">Common Pitfalls</h4>
<div style="display: grid; gap: 12px">
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600">Cache Stampede</div>
<div style="color: #475569; font-size: 13px">Many requests hit database when cache expires. Use locking or jittered TTLs.</div>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600">Stale Data</div>
<div style="color: #475569; font-size: 13px">Cache shows outdated information. Implement proper invalidation or use short TTLs.</div>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600">Cache Penetration</div>
<div style="color: #475569; font-size: 13px">Queries for non-existent data always miss cache. Cache negative results too.</div>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600">Hot Key Problem</div>
<div style="color: #475569; font-size: 13px">One popular key overwhelms a single cache node. Replicate hot keys or use local caching.</div>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600">Memory Pressure</div>
<div style="color: #475569; font-size: 13px">Cache grows unbounded. Set memory limits and monitor eviction rates.</div>
</div>
</div>
</div>
</div>
<hr />
<div class="concept-section type-important">
<h2 id="interview-deep-dive">Interview Deep Dive</h2>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; margin: 0 0 16px 0; font-size: 16px">Common Interview Questions</h4>
<div style="margin-bottom: 20px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">Q: How do you handle cache invalidation in a distributed system?</div>
<div style="color: #475569; font-size: 14px; background: #ffffff; padding: 12px; border-radius: 6px">
<strong>A:</strong> Multiple approaches: (1) <strong>TTL-based</strong> - set expiration, accept some staleness. (2) <strong>Event-driven</strong> - publish invalidation events via Kafka/Redis Pub-Sub when data changes. (3) <strong>Version-based</strong> - include version in cache key, increment on updates. For strong consistency, use write-through with distributed locks.
</div>
</div>
<div style="margin-bottom: 20px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">Q: Redis vs Memcached - when would you choose each?</div>
<div style="color: #475569; font-size: 14px; background: #ffffff; padding: 12px; border-radius: 6px">
<strong>A:</strong> <strong>Redis</strong> when you need: data structures (lists, sets, sorted sets), persistence, pub/sub, Lua scripting, replication. <strong>Memcached</strong> when you need: simple key-value, multi-threaded performance, less memory overhead per key, or already have it in your stack. Redis is more versatile; Memcached is simpler and slightly faster for basic operations.
</div>
</div>
<div style="margin-bottom: 20px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">Q: How do you prevent cache stampede?</div>
<div style="color: #475569; font-size: 14px; background: #ffffff; padding: 12px; border-radius: 6px">
<strong>A:</strong> (1) <strong>Locking</strong> - only one request regenerates, others wait or return stale. (2) <strong>Probabilistic early expiration</strong> - randomly refresh before TTL. (3) <strong>Background refresh</strong> - async job refreshes popular keys. (4) <strong>Jittered TTLs</strong> - add randomness to prevent synchronized expiry.
</div>
</div>
<div>
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px">Q: When should you NOT use caching?</div>
<div style="color: #475569; font-size: 14px; background: #ffffff; padding: 12px; border-radius: 6px">
<strong>A:</strong> (1) <strong>Highly dynamic data</strong> that changes every request. (2) <strong>Strong consistency requirements</strong> where stale reads are unacceptable (financial transactions). (3) <strong>Low-traffic endpoints</strong> where cache hit rate would be low. (4) <strong>Large, unique datasets</strong> that don't fit in memory. (5) <strong>Security-sensitive data</strong> that shouldn't persist outside the database.
</div>
</div>
</div>
</div>
<hr />
<div class="concept-section type-example">
<h2 id="code-implementation">Code Implementation</h2>
<h3 id="python---production-cache-with-stampede-prevention">Python - Production Cache with Stampede Prevention</h3>
<pre><code class="language-python">import time
import threading
import hashlib
import random
from typing import Optional, Callable, Any
from dataclasses import dataclass

@dataclass
class CacheEntry:
    value: Any
    expires_at: float
    created_at: float

class ProductionCache:
    &quot;&quot;&quot;
    Production-ready cache with:
    - TTL with jitter (prevents stampede)
    - Locking for cache regeneration
    - Stale-while-revalidate
    - Cache statistics
    &quot;&quot;&quot;

    def __init__(self, max_size: int = 10000, default_ttl: int = 3600):
        self.cache: dict[str, CacheEntry] = {}
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.locks: dict[str, threading.Lock] = {}
        self.lock_mutex = threading.Lock()

        # Statistics
        self.hits = 0
        self.misses = 0

    def _get_lock(self, key: str) -&gt; threading.Lock:
        &quot;&quot;&quot;Get or create a lock for a specific key.&quot;&quot;&quot;
        with self.lock_mutex:
            if key not in self.locks:
                self.locks[key] = threading.Lock()
            return self.locks[key]

    def _add_jitter(self, ttl: int) -&gt; float:
        &quot;&quot;&quot;Add 10% random jitter to TTL.&quot;&quot;&quot;
        jitter = ttl * 0.1 * random.random()
        return ttl + jitter

    def get(self, key: str) -&gt; Optional[Any]:
        &quot;&quot;&quot;Get value from cache.&quot;&quot;&quot;
        entry = self.cache.get(key)

        if entry is None:
            self.misses += 1
            return None

        if time.time() &gt; entry.expires_at:
            self.misses += 1
            return None

        self.hits += 1
        return entry.value

    def set(self, key: str, value: Any, ttl: Optional[int] = None) -&gt; None:
        &quot;&quot;&quot;Set value in cache with jittered TTL.&quot;&quot;&quot;
        ttl = ttl or self.default_ttl
        jittered_ttl = self._add_jitter(ttl)

        # Evict if at capacity (simple LRU would be better)
        if len(self.cache) &gt;= self.max_size:
            oldest_key = min(self.cache, key=lambda k: self.cache[k].created_at)
            del self.cache[oldest_key]

        self.cache[key] = CacheEntry(
            value=value,
            expires_at=time.time() + jittered_ttl,
            created_at=time.time()
        )

    def get_or_set(
        self,
        key: str,
        loader: Callable[[], Any],
        ttl: Optional[int] = None,
        stale_ttl: int = 60
    ) -&gt; Any:
        &quot;&quot;&quot;
        Get from cache or load with stampede prevention.

        Uses locking to ensure only one request loads data.
        Others wait or return stale data.
        &quot;&quot;&quot;
        entry = self.cache.get(key)
        now = time.time()

        # Fresh cache hit
        if entry and now &lt; entry.expires_at:
            self.hits += 1
            return entry.value

        # Stale data available?
        stale_value = entry.value if entry else None
        stale_available = entry and now &lt; entry.expires_at + stale_ttl

        # Try to acquire lock
        lock = self._get_lock(key)
        acquired = lock.acquire(blocking=not stale_available)

        if not acquired:
            # Couldn't get lock, return stale if available
            self.hits += 1  # Serving stale
            return stale_value

        try:
            # Double-check after acquiring lock
            entry = self.cache.get(key)
            if entry and time.time() &lt; entry.expires_at:
                return entry.value

            # Load fresh data
            self.misses += 1
            value = loader()
            self.set(key, value, ttl)
            return value
        finally:
            lock.release()

    def invalidate(self, key: str) -&gt; bool:
        &quot;&quot;&quot;Remove key from cache.&quot;&quot;&quot;
        if key in self.cache:
            del self.cache[key]
            return True
        return False

    def invalidate_pattern(self, pattern: str) -&gt; int:
        &quot;&quot;&quot;Invalidate all keys matching pattern (simple prefix match).&quot;&quot;&quot;
        keys_to_delete = [k for k in self.cache if k.startswith(pattern)]
        for key in keys_to_delete:
            del self.cache[key]
        return len(keys_to_delete)

    def stats(self) -&gt; dict:
        &quot;&quot;&quot;Get cache statistics.&quot;&quot;&quot;
        total = self.hits + self.misses
        return {
            &quot;hits&quot;: self.hits,
            &quot;misses&quot;: self.misses,
            &quot;hit_rate&quot;: self.hits / total if total &gt; 0 else 0,
            &quot;size&quot;: len(self.cache),
            &quot;max_size&quot;: self.max_size
        }


# Usage Example
cache = ProductionCache(max_size=10000, default_ttl=3600)

def get_user(user_id: int) -&gt; dict:
    &quot;&quot;&quot;Get user with caching.&quot;&quot;&quot;
    cache_key = f&quot;user:{user_id}&quot;

    def load_from_db():
        # Simulate database query
        return {&quot;id&quot;: user_id, &quot;name&quot;: f&quot;User {user_id}&quot;}

    return cache.get_or_set(cache_key, load_from_db, ttl=300)

# First call - cache miss, loads from DB
user = get_user(123)

# Second call - cache hit
user = get_user(123)

# Check stats
print(cache.stats())
# {'hits': 1, 'misses': 1, 'hit_rate': 0.5, 'size': 1, 'max_size': 10000}
</code></pre>
<h3 id="python---distributed-cache-with-redis">Python - Distributed Cache with Redis</h3>
<pre><code class="language-python">import redis
import json
import time
from typing import Optional, Any, Callable

class RedisCache:
    &quot;&quot;&quot;Redis-backed distributed cache.&quot;&quot;&quot;

    def __init__(self, host: str = 'localhost', port: int = 6379, db: int = 0):
        self.client = redis.Redis(host=host, port=port, db=db, decode_responses=True)
        self.default_ttl = 3600

    def get(self, key: str) -&gt; Optional[Any]:
        &quot;&quot;&quot;Get value from Redis.&quot;&quot;&quot;
        value = self.client.get(key)
        if value:
            return json.loads(value)
        return None

    def set(self, key: str, value: Any, ttl: Optional[int] = None) -&gt; None:
        &quot;&quot;&quot;Set value in Redis with TTL.&quot;&quot;&quot;
        ttl = ttl or self.default_ttl
        self.client.setex(key, ttl, json.dumps(value))

    def get_or_set(
        self,
        key: str,
        loader: Callable[[], Any],
        ttl: Optional[int] = None
    ) -&gt; Any:
        &quot;&quot;&quot;Get from cache or load with distributed locking.&quot;&quot;&quot;
        # Try cache first
        value = self.get(key)
        if value is not None:
            return value

        # Distributed lock using SETNX
        lock_key = f&quot;lock:{key}&quot;
        lock_acquired = self.client.setnx(lock_key, &quot;1&quot;)

        if lock_acquired:
            self.client.expire(lock_key, 30)  # Lock timeout
            try:
                value = loader()
                self.set(key, value, ttl)
                return value
            finally:
                self.client.delete(lock_key)
        else:
            # Wait and retry
            time.sleep(0.1)
            return self.get(key) or loader()

    def invalidate(self, key: str) -&gt; bool:
        &quot;&quot;&quot;Delete key from Redis.&quot;&quot;&quot;
        return self.client.delete(key) &gt; 0

    def invalidate_pattern(self, pattern: str) -&gt; int:
        &quot;&quot;&quot;Delete keys matching pattern.&quot;&quot;&quot;
        keys = self.client.keys(pattern)
        if keys:
            return self.client.delete(*keys)
        return 0
</code></pre>
</div>
<hr />
<h2 id="quick-reference-card">Quick Reference Card</h2>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 20px 0; font-size: 16px">CACHING CHEAT SHEET</h4>
<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 16px">
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px;padding-bottom: 8px">When to Cache</div>
<ul style="color: #475569; font-size: 13px; margin: 0; padding-left: 16px">
<li>Read-heavy workloads (read:write > 10:1)</li>
<li>Expensive computations</li>
<li>Slow external API calls</li>
<li>Database query results</li>
<li>Session data</li>
</ul>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px;padding-bottom: 8px">When NOT to Cache</div>
<ul style="color: #475569; font-size: 13px; margin: 0; padding-left: 16px">
<li>Rapidly changing data</li>
<li>Write-heavy workloads</li>
<li>Unique queries (low hit rate)</li>
<li>Sensitive financial data</li>
<li>Real-time requirements</li>
</ul>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px;padding-bottom: 8px">TTL Guidelines</div>
<ul style="color: #475569; font-size: 13px; margin: 0; padding-left: 16px">
<li>Static assets: 1 year</li>
<li>User profiles: 1 hour</li>
<li>API responses: 5-15 minutes</li>
<li>Search results: 1-5 minutes</li>
<li>Real-time data: 10-30 seconds</li>
</ul>
</div>
<div style="background: #ffffff; border-radius: 8px; padding: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 8px;padding-bottom: 8px">Key Metrics</div>
<ul style="color: #475569; font-size: 13px; margin: 0; padding-left: 16px">
<li>Hit rate > 90% (for hot data)</li>
<li>Latency p99 < 10ms</li>
<li>Memory usage < 80%</li>
<li>Eviction rate (should be low)</li>
<li>Connection count</li>
</ul>
</div>
</div>
<div style="margin-top: 16px; padding: 12px; background: #ffffff; border-radius: 8px; text-align: center">
<code style="color: #1e293b; font-size: 13px">Cache Rule: "Cache data that is read often, written rarely, and can tolerate some staleness"</code>
</div>
</div>
<hr />
<div class="concept-section type-deep-learning">
<h2 id="deep-learning-qa">Deep Learning Q&A</h2>
<p style="color: #64748b; margin-bottom: 24px;">Challenge yourself with these open-ended questions. Each answer leads to deeper exploration.</p>

<!-- Question 1: Cache Invalidation -->
<div style="background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #92400e; margin: 0 0 16px 0;">Q1: You're building a social media feed. A user updates their profile picture. How do you ensure all their posts show the new picture without rebuilding the entire cache?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Use a <strong>reference-based caching strategy</strong>: Instead of embedding the profile picture URL in every post cache, store only the user_id. When rendering, fetch the current profile picture from a separate user cache with short TTL (5 min). This way, updating the user cache automatically reflects in all posts without mass invalidation.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">Alternatively, use <strong>cache versioning</strong>: Include a version number in cache keys (e.g., <code>user:123:v5</code>). On profile update, increment the version. Old cached posts still work but fetch the new user data on next access.</p>

<!-- Nested Q1.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.1: What if the user has 10 million followers and they all see stale pictures for 5 minutes?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">For high-profile users, implement <strong>push-based invalidation</strong>: Publish an event to a message queue (Kafka) when they update. Subscriber services actively purge relevant caches. Combined with CDN purge APIs, you can reduce staleness to seconds. Trade-off: More infrastructure complexity, but necessary for celebrity/brand accounts.</p>

<!-- Nested Q1.1.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.1: How do you prioritize which users get push-based invalidation vs TTL-based?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Create a <strong>tiered invalidation system</strong>: Tier 1 (>1M followers): Push-based + CDN purge, Tier 2 (100K-1M): Push-based only, Tier 3 (<100K): TTL-based with 5-min window. Store follower counts in a fast lookup (Redis sorted set). On update, check tier and route to appropriate invalidation path.</p>
</div>
</details>
</div>

<!-- Nested Q1.1.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.2: What if the push-based system itself becomes a bottleneck during viral moments?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>rate limiting on invalidation</strong>: Queue invalidation requests and process with backpressure. Use exponential backoff for retries. For extreme virality, fall back to "eventual consistency mode" - accept that some users see stale data for up to 15 minutes. The 99.9% case matters more than the 0.1% edge case.</p>
</div>
</details>
</div>

<!-- Nested Q1.1.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.3: How do you measure if your invalidation strategy is actually working?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Track <strong>staleness metrics</strong>: (1) Time-to-consistency: measure p50/p95/p99 of how long after an update users see new data. (2) Stale-read-rate: sample requests and compare cache vs DB. (3) Invalidation success rate: track push failures. Set SLOs like "95% of users see updates within 30 seconds" and alert on breaches.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q1.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.2: The reference-based approach adds an extra cache lookup per post. How do you prevent this from killing performance?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Use <strong>batch fetching with pipelining</strong>: When loading a feed of 20 posts, collect all unique user_ids, then fetch all user data in a single Redis MGET. This turns 20 round trips into 1. Also implement <strong>local in-memory cache</strong> (like Caffeine in JVM) with 1-minute TTL for the hottest user profiles - reduces Redis calls by 80%+ for popular users.</p>

<!-- Nested Q1.2.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.1: With local cache + Redis + DB, how do you debug when a user complains about seeing wrong data?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Add <strong>cache metadata headers</strong>: Return X-Cache-Hit, X-Cache-Layer (local/redis/db), X-Cache-Age with every response. Log these for sampled requests. Build a debug endpoint that shows all cache layers for a given key. For user complaints, correlate their request timestamps with cache ages to identify which layer served stale data.</p>
</div>
</details>
</div>

<!-- Nested Q1.2.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.2: Local cache means each server has different data. How do you handle this inconsistency?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Accept it as a feature, not a bug. Document that users may see inconsistent data for up to 1 minute when switching between servers (load balancer). For critical flows (checkout, settings), bypass local cache entirely with a "no-cache" flag. Use sticky sessions for user-facing pages if absolute consistency matters more than load distribution.</p>
</div>
</details>
</div>

<!-- Nested Q1.2.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.3: How do you decide the right TTL for the local cache?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Start with business requirements: "How stale is acceptable?" Then measure: (1) Redis p99 latency - if <1ms, local cache adds little value. (2) Request rate per server - high rate = more savings. (3) Update frequency - daily updates = longer TTL okay. Formula: TTL = min(acceptable_staleness, update_interval / 10). Monitor hit rates; if below 50%, the TTL is too short.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q1.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.3: What if the user changes their profile picture AND their username at the same time? Do you need distributed transactions?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">No distributed transactions needed. The user object is cached as a single unit. Update the database atomically (single row update), then invalidate/update the user cache. Both fields update together. The only inconsistency window is between DB commit and cache invalidation (milliseconds). If cache update fails, the short TTL ensures self-healing.</p>

<!-- Nested Q1.3.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.1: What if cache invalidation fails right after DB commit?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>outbox pattern</strong>: Write invalidation intent to a DB table in the same transaction as the update. A background worker reads the outbox and processes invalidations with retries. Even if the initial invalidation fails, the worker will eventually succeed. The cache TTL is the maximum staleness window.</p>
</div>
</details>
</div>

<!-- Nested Q1.3.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.2: Should you use cache-aside or write-through for user profiles?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Cache-aside for reads, write-through for writes</strong>: Reads use lazy loading (check cache, miss = load from DB). Writes use write-through (update cache immediately after DB). This gives fast reads with guaranteed freshness after writes. The write path adds latency but profile updates are rare compared to views.</p>
</div>
</details>
</div>

<!-- Nested Q1.3.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.3: How do you handle the user viewing their own profile right after updating?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>read-your-writes consistency</strong>: After a write, set a short-lived flag in the user's session (or a cookie). On subsequent reads, if the flag exists, bypass cache and read from DB directly. The flag expires after 10 seconds - long enough for cache to update, short enough to not hurt performance. Alternatively, return the updated data directly in the write response and use it client-side.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Question 2: Cache Warming -->
<div style="background: linear-gradient(135deg, #dbeafe 0%, #bfdbfe 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #1e40af; margin: 0 0 16px 0;">Q2: Your e-commerce site has a flash sale starting at midnight. How do you ensure the cache is ready and doesn't collapse under the traffic spike?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Implement <strong>cache warming</strong> before the sale: (1) Identify sale items from the promotion database. (2) Pre-populate cache with product details, prices, inventory counts 30 minutes before. (3) Set TTLs to extend past the sale peak (e.g., 2 hours). (4) Use jittered TTLs to prevent synchronized expiration.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">Additionally, enable <strong>request coalescing</strong>: If 1000 requests hit the same cache miss simultaneously, only one fetches from DB; others wait for that result. This prevents database stampede.</p>

<!-- Nested Q2.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.1: The inventory is changing rapidly during the sale. How do you balance cache freshness with performance?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Separate <strong>static and dynamic data</strong>: Product name, description, images = cache for hours. Inventory count = don't cache at all OR use very short TTL (5 seconds). For the checkout flow, always read inventory from database to prevent overselling. Display "Low stock!" when inventory < threshold without showing exact count.</p>

<!-- Nested Q2.1.1, Q2.1.2, Q2.1.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.1: What if "always read from DB" overwhelms the database during peak?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>read replicas with lag tolerance</strong>: Route inventory reads to replicas, accepting up to 1-second lag. This is fine because the actual decrement happens on the primary with optimistic locking. If the replica shows "5 left" but primary has "3", the checkout will still succeed for 3 customers and gracefully reject the rest.</p>
</div>
</details>
</div>
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.2: How do you handle the "add to cart but out of stock at checkout" problem?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>soft reservation</strong>: When added to cart, decrement a "soft inventory" counter in Redis (with TTL of 15 minutes). If user doesn't checkout, the reservation expires automatically. Checkout confirms against hard DB inventory. This reduces disappointment while preventing indefinite holds.</p>
</div>
</details>
</div>
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.3: How do you prevent bots from gaming the soft reservation system?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Add <strong>reservation limits per user</strong>: Max 2 units per SKU per user (by user_id or IP). Use <strong>CAPTCHA before reservation</strong> for high-demand items. Implement <strong>queue-based access</strong>: Users enter a virtual queue and get a time-limited purchase token. Bots can queue but can't mass-reserve. Monitor for suspicious patterns (many reservations, few checkouts).</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q2.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.2: The cache warming job takes 20 minutes but the sale items are finalized only 10 minutes before midnight. What do you do?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;"><strong>Incremental warming with priorities</strong>: (1) Pre-warm common infrastructure caches (user sessions, common products). (2) When sale items are finalized, warm only those items - a subset is faster. (3) Use parallel workers (10 workers can warm 100K items in 2 minutes). (4) As a fallback, enable aggressive request coalescing so even cold caches don't kill the DB.</p>

<!-- Nested Q2.2.1, Q2.2.2, Q2.2.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.1: How do you know which items to prioritize warming?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>historical data + promotion placement</strong>: Items on the homepage banner = highest priority. Items from last year's similar sale = high priority. Everything else = medium. Track wishlist additions and browsing patterns leading up to the sale to predict demand. Warm the top 1000 items first, then fill in the rest.</p>
</div>
</details>
</div>
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.2: What if the warming job itself fails at 11:58 PM?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Graceful degradation</strong>: Have circuit breakers on DB connections. If cache is cold, throttle requests at the load balancer (queue users with a "Please wait" page). Better to serve 1000 users/second reliably than crash trying to serve 10000. Alert the on-call team immediately. Document this as an incident and add monitoring for warming job completion.</p>
</div>
</details>
</div>
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.3: How do you test cache warming works before the actual sale?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Chaos testing in staging</strong>: Run load tests simulating sale traffic against a staging environment with intentionally cold caches. Measure DB load, response times, error rates. Do this weekly leading up to major sales. Also run the warming job against production caches with a "dry run" flag that doesn't actually write - just verifies all data sources are accessible.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q2.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.3: Post-sale, you have a huge cache filled with sale items nobody will access again. How do you clean up efficiently?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;"><strong>Natural TTL expiration</strong> is usually sufficient - items expire within hours. If memory pressure is urgent: (1) Tag sale items with a prefix (<code>sale:2024:item:123</code>). (2) After sale, run <code>SCAN</code> with pattern matching to find and delete. (3) Alternatively, use a separate Redis instance for sale-specific caches that you can simply flush. Avoid blocking operations - Redis KEYS/DEL on millions of items blocks the server.</p>

<!-- Nested Q2.3.1, Q2.3.2, Q2.3.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.1: SCAN is slow. Is there a faster way?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>Redis namespaces via separate databases</strong> (0-15) or separate Redis instances. Put all sale data in DB 1, regular data in DB 0. After sale, <code>FLUSHDB</code> on DB 1 is instant. Or use <strong>key expiration</strong>: Set all sale items with TTL of (sale_duration + 2_hours). They self-delete without manual cleanup.</p>
</div>
</details>
</div>
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.2: What about cache entries that reference sale items?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Design for <strong>graceful missing references</strong>: When a cached page references a deleted sale item, handle the cache miss gracefully - show "Item no longer available" instead of erroring. Use lazy cleanup: when accessed, check if the item exists; if not, remove the reference and continue. This avoids complex dependency tracking.</p>
</div>
</details>
</div>
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.3: How do you prevent the cleanup process from affecting post-sale traffic?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Schedule cleanup during low-traffic hours</strong> (typically 3-5 AM). Use <code>UNLINK</code> instead of <code>DEL</code> for async deletion. Rate-limit deletions to ~1000 keys/second. Monitor Redis CPU and pause cleanup if it spikes. Better yet, rely on TTL expiration and skip explicit cleanup entirely.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Question 3: Multi-Region Caching -->
<div style="background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #166534; margin: 0 0 16px 0;">Q3: Your service is deployed in US, EU, and Asia. A user in Tokyo updates data. How do you ensure users in New York see the update without unacceptable latency?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Use <strong>local read, global write</strong> pattern: Each region has its own cache cluster. Reads always hit the local cache (low latency). Writes go to the primary database in one region, then replicate to others. Cache invalidation is broadcast globally via a message bus (Kafka, Redis Pub/Sub across regions).</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">Accept that cross-region propagation takes 100-300ms. For most use cases, this is fine. For critical updates (password changes, payment confirmations), use <strong>read-after-write routing</strong>: temporarily route that user's reads to the primary region.</p>

<!-- Nested Q3.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.1: The message bus itself has latency. What if the New York cache serves stale data during that window?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Two strategies: (1) <strong>Versioned cache keys</strong>: Include a version/timestamp in the data. Client-side logic can detect stale versions and request fresh data. (2) <strong>Write timestamp propagation</strong>: Include "last_updated_at" with every cache entry. On read, if age > threshold (e.g., 500ms), check primary region before returning.</p>

<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.1: How do you handle conflicting writes from different regions?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>single-leader replication</strong>: All writes go to one primary region, then replicate. This eliminates conflicts but adds write latency for remote users. Alternatively, use <strong>conflict-free replicated data types (CRDTs)</strong> for data that can merge (counters, sets). For complex data, use <strong>last-writer-wins</strong> with synchronized clocks (NTP + hybrid logical clocks).</p>
</div>
</details>
</div>
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.2: What if the message bus goes down between regions?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Fall back to TTL-based expiration</strong>: If invalidation messages don't arrive, entries naturally expire. Set TTLs shorter than the acceptable staleness SLA. Additionally, implement <strong>periodic full reconciliation</strong>: every 5 minutes, compare cache checksums across regions and invalidate mismatches. Queue undelivered messages and replay when connectivity resumes.</p>
</div>
</details>
</div>
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.3: How do you debug cross-region cache issues?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Build a <strong>cache observatory dashboard</strong>: For a given key, show its value in all regions with timestamps. Track invalidation message flow: "Message sent from Tokyo at T1, received in NY at T2, processed at T3". Add <strong>request tracing</strong> (OpenTelemetry) that includes cache interactions. Alert on anomalies like "NY cache is 5 minutes behind Tokyo".</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q3.2, Q3.3 abbreviated for space -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.2: Running cache clusters in 3 regions triples your infrastructure cost. How do you optimize?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;"><strong>Tiered caching by access pattern</strong>: Hot data (top 10K keys) = replicated everywhere. Warm data = replicated to 2 regions. Cold data = single region with remote fetch on miss. Use analytics to categorize keys. Also consider <strong>cache compression</strong>: gzip can reduce memory by 60-80% for text data, trading CPU for memory savings.</p>
</div>
</details>
</div>

<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.3: How do you handle a regional cache failure without affecting global users?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;"><strong>Automatic failover to nearby region</strong>: If Asia cache dies, route Asian users to US-West (lowest latency alternative). Use DNS-based or load-balancer-based routing. Accept degraded performance (200ms vs 20ms latency) over total failure. Pre-configure failover rules and test quarterly with chaos engineering.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>

<!-- Pros and Cons Section -->
<hr />
<div class="concept-section type-analysis">
<h2 id="pros-cons-analysis">Caching: Pros & Cons Analysis</h2>

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 24px; margin: 24px 0;">

<!-- Pros -->
<div style="background: linear-gradient(135deg, #ecfdf5 0%, #d1fae5 100%); border-radius: 16px; padding: 24px;">
<h3 style="color: #065f46; margin: 0 0 20px 0; display: flex; align-items: center; gap: 8px;">
<span style="font-size: 24px;">+</span> Pros
</h3>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Dramatically Reduces Latency</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Memory access is 100-1000x faster than disk/network. Sub-millisecond responses become possible.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Monitor p99 latency, not just averages - cache misses skew results</li>
<li>Set up alerts for cache hit rate drops below 90%</li>
<li>Track latency by cache layer to identify bottlenecks</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Reduces Database Load</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Cache handles repetitive queries, freeing DB for complex operations and writes.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Don't cache everything - focus on read-heavy, stable data</li>
<li>Monitor DB connection pool even with caching (misses still hit DB)</li>
<li>Test failure scenarios: what happens when cache is completely cold?</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Enables Horizontal Scaling</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Add more app servers without proportionally scaling database. Cache absorbs the read load.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Plan cache cluster scaling before app scaling (cache becomes the bottleneck)</li>
<li>Consider local caches on app servers to reduce cache cluster load</li>
<li>Monitor cache cluster CPU and memory headroom</li>
</ul>
</div>
</div>
</div>

<!-- Cons -->
<div style="background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%); border-radius: 16px; padding: 24px;">
<h3 style="color: #991b1b; margin: 0 0 20px 0; display: flex; align-items: center; gap: 8px;">
<span style="font-size: 24px;">-</span> Cons
</h3>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Cache Invalidation Complexity</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">"There are only two hard things in CS: cache invalidation and naming things."</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Start with TTL-based expiration - simplest and often sufficient</li>
<li>Add event-driven invalidation only where TTL staleness is unacceptable</li>
<li>Document your invalidation strategy and test it explicitly</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Data Inconsistency Risk</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Cache can serve stale data, leading to user confusion or business logic errors.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Define acceptable staleness per data type (5 sec for inventory, 1 hour for profiles)</li>
<li>Show "last updated" timestamps where staleness matters to users</li>
<li>Never cache financial or security-critical data without immediate invalidation</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Additional Infrastructure Complexity</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Cache clusters need monitoring, failover, backups, and operational expertise.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Start with managed services (ElastiCache, Cloud Memorystore) to reduce ops burden</li>
<li>Build graceful degradation: app should work (slowly) without cache</li>
<li>Set up comprehensive monitoring before you need it</li>
</ul>
</div>
</div>
</div>
</div>
</div>

<hr />
<h2 id="related-topics">Related Topics</h2>
<ul>
<li><a href="/topic/system-design/cdn">CDN</a> - Edge caching for static content</li>
<li><a href="/topic/system-design/database-replication">Database Replication</a> - Data redundancy</li>
<li><a href="/topic/system-design/load-balancing">Load Balancing</a> - Request distribution</li>
<li><a href="/topic/system-design/redis">Redis</a> - Popular caching solution</li>
</ul>
