<style>
/* Mobile-specific styles for iPhone 15 and similar devices */
@media screen and (max-width: 480px) {
    /* Force all grid layouts to single column */
    [style*="grid-template-columns"] {
        display: block !important;
    }
    [style*="grid-template-columns"] > div {
        margin-bottom: 16px !important;
    }
    /* Adjust padding for mobile */
    [style*="padding: 32px"],
    [style*="padding: 24px"] {
        padding: 16px !important;
    }
    /* Smaller headings */
    h4[style*="font-size: 18px"],
    h4[style*="font-size: 16px"] {
        font-size: 15px !important;
    }
    /* Readable font sizes */
    [style*="font-size: 13px"],
    [style*="font-size: 12px"],
    [style*="font-size: 11px"],
    [style*="font-size: 10px"] {
        font-size: 13px !important;
        line-height: 1.6 !important;
    }
    /* Flex containers stack vertically */
    [style*="display: flex"][style*="gap"] {
        flex-direction: column !important;
    }
    /* Better spacing for nested content */
    [style*="padding-left: 64px"],
    [style*="padding-left: 48px"],
    [style*="padding-left: 40px"] {
        padding-left: 16px !important;
    }
    /* Code blocks */
    pre {
        font-size: 12px !important;
        padding: 12px !important;
        overflow-x: auto !important;
    }
    pre code {
        font-size: 12px !important;
    }
    /* Tables */
    table {
        font-size: 12px !important;
        display: block !important;
        overflow-x: auto !important;
    }
    th, td {
        padding: 8px !important;
        font-size: 12px !important;
    }
}

.collapsible-code {
    margin: 16px 0;
    border: 1px solid #e2e8f0;
    border-radius: 6px;
    overflow: hidden;
}

.code-header {
    background-color: #f8fafc;
    padding: 12px 16px;
    cursor: pointer;
    display: flex;
    justify-content: space-between;
    align-items: center;
    border-bottom: 1px solid #e2e8f0;
    user-select: none;
    font-weight: 500;
    color: #334155;
}

.code-header:hover {
    background-color: #f1f5f9;
}

.code-toggle-icon {
    display: inline-block;
    width: 20px;
    height: 20px;
    transition: transform 0.2s ease;
    font-size: 14px;
    line-height: 20px;
}

.collapsible-code.collapsed .code-toggle-icon {
    transform: rotate(-90deg);
}

.code-content {
    max-height: 1000px;
    overflow: hidden;
    transition: max-height 0.3s ease, visibility 0.3s ease;
    visibility: visible;
}

.collapsible-code.collapsed .code-content {
    max-height: 0;
    visibility: hidden;
}

.code-content pre {
    margin: 0;
    border-radius: 0;
}

.code-content pre code {
    display: block;
    overflow-x: auto;
}

</style>
<h1 id="load-balancing">Load Balancing</h1>
<div class="tldr-box">
    <div class="tldr-header">TL;DR</div>
    <ul class="tldr-list">
        <li>Load balancers distribute traffic across servers for high availability and scalability</li>
        <li>Layer 4 (TCP/UDP) is fast but basic; Layer 7 (HTTP) enables smart routing</li>
        <li>Algorithms: Round Robin (simple), Least Connections (smart), Consistent Hashing (session affinity)</li>
        <li>Health checks prevent routing to failed servers (active probes + passive monitoring)</li>
        <li>Use hardware for highest throughput, software for flexibility, cloud for ease</li>
    </ul>
</div>
<div class="concept-section type-definition">
<h2 id="overview">Overview</h2>
<p>Load balancing is the process of distributing incoming network traffic across multiple servers to ensure no single server becomes overwhelmed. Think of it like a traffic officer directing cars at a busy intersection - without proper direction, all cars would pile up in one lane while others remain empty.</p>
<p>At its core, a load balancer sits between clients and servers, acting as a reverse proxy that decides which server should handle each incoming request. This simple concept enables some of the most critical capabilities in modern systems: high availability, horizontal scaling, and fault tolerance.</p>
<div style="background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-radius: 16px; padding: 28px; margin: 24px 0">
<h4 style="margin-top: 0; color: #1e40af; font-size: 18px">Core Equation</h4>
<div style="font-family: 'Courier New', monospace; font-size: 16px; background: #eff6ff; padding: 16px; border-radius: 8px; text-align: center; color: #1e293b">
    Load Balancer = Traffic Distribution + Health Monitoring + Session Management + Failover Automation
</div>
</div>
<p><span style="color: #166534; font-weight: 600"><strong>Critical Assumption:</strong></span> Load balancing assumes backend servers are interchangeable for the same request type. If servers have different capabilities or data, you need content-aware routing or session affinity, which complicates the balancing strategy.</p>
<p><span style="color: #166534; font-weight: 600"><strong>Key Trade-off:</strong></span> Simplicity vs Intelligence. Simple algorithms (round-robin) are fast but may route to overloaded servers. Intelligent algorithms (least connections, adaptive) make better decisions but add latency and complexity.</p>
</div>
<hr />
<div class="concept-section type-important">
<h2 id="why-load-balancing-matters">Why Load Balancing Matters</h2>
<div style="background: #f0fdf4; border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #166534; margin-top: 0">Real-World Impact</h4>
<div style="color: #1e293b">
<div class="collapsible-code collapsed">
    <div class="code-header">
        <span>Code</span>
        <span class="code-toggle-icon">▶</span>
    </div>
    <div class="code-content">
        <pre><code>**Netflix** handles over 400 million streaming hours daily using load balancers to distribute requests across thousands of servers globally. Without load balancing, a single popular show release could crash their entire service.

**Amazon** reported that every 100ms of latency costs them 1% in sales. Load balancing helps maintain sub-100ms response times by routing requests to the fastest available server.

**GitHub** uses load balancing to handle millions of git operations daily. During peak hours, their load balancers distribute traffic across multiple data centers to maintain availability.
</code></pre>
    </div>
</div>
</div>
</div>
<h3 id="key-benefits">Key Benefits</h3>
<div style="background: #f8fafc; border-radius: 12px; padding: 24px; margin: 20px 0">
<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px">
<div style="background: #eff6ff; padding: 16px; border-radius: 8px">
<h5 style="color: #1e40af; margin: 0 0 8px 0">High Availability</h5>
<p style="color: #1e293b; margin: 0; font-size: 14px">If one server fails, traffic automatically routes to healthy servers. Users never notice the failure.</p>
</div>
<div style="background: #f0fdf4; padding: 16px; border-radius: 8px">
<h5 style="color: #166534; margin: 0 0 8px 0">Horizontal Scaling</h5>
<p style="color: #1e293b; margin: 0; font-size: 14px">Add more servers to handle increased load. Scale out is often cheaper than scale up.</p>
</div>
<div style="background: #fefce8; padding: 16px; border-radius: 8px">
<h5 style="color: #854d0e; margin: 0 0 8px 0">Performance</h5>
<p style="color: #1e293b; margin: 0; font-size: 14px">Distribute load evenly to prevent any single server from becoming a bottleneck.</p>
</div>
<div style="background: #fdf4ff; padding: 16px; border-radius: 8px">
<h5 style="color: #86198f; margin: 0 0 8px 0">Flexibility</h5>
<p style="color: #1e293b; margin: 0; font-size: 14px">Perform maintenance on servers without downtime by draining connections gracefully.</p>
</div>
</div>
</div>
</div>
<hr />
<div class="concept-section type-definition">
<h2 id="section-1-layer-4-vs-layer-7-load-balancing">Section 1: Layer 4 vs Layer 7 Load Balancing</h2>
<h3 id="deep-mechanics">Deep Mechanics</h3>
<p>The OSI model distinction between Layer 4 (Transport) and Layer 7 (Application) load balancing fundamentally changes what information is available for routing decisions and the performance characteristics of the load balancer.</p>
<div style="background: #f8fafc;border-radius: 16px; padding: 32px; margin: 24px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 24px 0">Layer 4 vs Layer 7 Architecture</h4>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 24px">
<div style="background: #eff6ff;border-radius: 12px; padding: 20px">
<h5 style="color: #1e40af; margin: 0 0 16px 0">Layer 4 (Transport Layer)</h5>
<div style="background: white; border-radius: 8px; padding: 16px; margin-bottom: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 12px; font-size: 13px">Operates On:</div>
<div style="display: flex; flex-direction: column; gap: 8px">
<div style="background: #dbeafe; padding: 8px 12px; border-radius: 6px; font-size: 13px">
<span style="color: #1e40af; font-weight: 600">TCP/UDP Headers</span>
</div>
<div style="background: #dbeafe; padding: 8px 12px; border-radius: 6px; font-size: 13px">
<span style="color: #1e40af">Source/Destination IP</span>
</div>
<div style="background: #dbeafe; padding: 8px 12px; border-radius: 6px; font-size: 13px">
<span style="color: #1e40af">Source/Destination Port</span>
</div>
</div>
</div>
<div style="background: #f8fafc; border-radius: 8px; padding: 12px; margin-bottom: 16px">
<div style="color: #64748b; font-size: 12px; margin-bottom: 8px">What L4 Sees:</div>
<div style="font-family: monospace; font-size: 11px">
<div style="background: #dcfce7;padding: 6px 10px; border-radius: 4px; margin-bottom: 4px">
<span style="color: #166534">SRC: 192.168.1.100:54321</span>
</div>
<div style="background: #dcfce7;padding: 6px 10px; border-radius: 4px; margin-bottom: 4px">
<span style="color: #166534">DST: 10.0.0.1:443</span>
</div>
<div style="background: #fee2e2;padding: 6px 10px; border-radius: 4px">
<span style="color: #991b1b">Payload: [encrypted blob]</span>
</div>
</div>
</div>
<div style="font-size: 13px">
<div style="color: #166534; margin-bottom: 4px">+ Very fast (no payload parsing)</div>
<div style="color: #166534; margin-bottom: 4px">+ Protocol agnostic</div>
<div style="color: #166534; margin-bottom: 4px">+ Lower resource usage</div>
<div style="color: #991b1b; margin-bottom: 4px">- No content-based routing</div>
<div style="color: #991b1b">- Cannot modify requests</div>
</div>
<div style="margin-top: 16px; padding-top: 16px">
<div style="color: #64748b; font-size: 12px">Examples:</div>
<div style="color: #1e40af; font-size: 13px">AWS NLB, HAProxy TCP mode, F5 BIG-IP LTM</div>
</div>
</div>
<div style="background: #f3e8ff;border-radius: 12px; padding: 20px">
<h5 style="color: #7c3aed; margin: 0 0 16px 0">Layer 7 (Application Layer)</h5>
<div style="background: white; border-radius: 8px; padding: 16px; margin-bottom: 16px">
<div style="color: #1e293b; font-weight: 600; margin-bottom: 12px; font-size: 13px">Operates On:</div>
<div style="display: flex; flex-direction: column; gap: 8px">
<div style="background: #e9d5ff; padding: 8px 12px; border-radius: 6px; font-size: 13px">
<span style="color: #7c3aed; font-weight: 600">HTTP Headers & Body</span>
</div>
<div style="background: #e9d5ff; padding: 8px 12px; border-radius: 6px; font-size: 13px">
<span style="color: #7c3aed">URL Path & Query Params</span>
</div>
<div style="background: #e9d5ff; padding: 8px 12px; border-radius: 6px; font-size: 13px">
<span style="color: #7c3aed">Cookies & Sessions</span>
</div>
</div>
</div>
<div style="background: #f8fafc; border-radius: 8px; padding: 12px; margin-bottom: 16px; font-family: monospace; font-size: 11px">
<div style="color: #166534">GET /api/users/123 HTTP/1.1</div>
<div style="color: #1e40af">Host: api.example.com</div>
<div style="color: #ea580c">Cookie: session=abc123</div>
<div style="color: #7c3aed">X-Tenant-ID: acme-corp</div>
<div style="color: #64748b">Authorization: Bearer eyJ...</div>
</div>
<div style="font-size: 13px">
<div style="color: #166534; margin-bottom: 4px">+ Content-aware routing</div>
<div style="color: #166534; margin-bottom: 4px">+ Can modify/transform requests</div>
<div style="color: #166534; margin-bottom: 4px">+ SSL termination capabilities</div>
<div style="color: #991b1b; margin-bottom: 4px">- Higher latency</div>
<div style="color: #991b1b">- More resource intensive</div>
</div>
<div style="margin-top: 16px; padding-top: 16px">
<div style="color: #64748b; font-size: 12px">Examples:</div>
<div style="color: #7c3aed; font-size: 13px">AWS ALB, Nginx, HAProxy HTTP, Envoy</div>
</div>
</div>
</div>
</div>
<h3 id="layer-7-routing-capabilities">Layer 7 Routing Capabilities</h3>
<div style="background: #f0fdf4;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #166534; margin-top: 0">Content-Based Routing Examples</h4>
<div style="display: grid; gap: 12px">
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #166534">Path-Based Routing</strong>
<pre style="margin: 8px 0 0 0; color: #166534; font-size: 14px; background: #dcfce7; padding: 12px; border-radius: 6px">/api/*     --> API Servers (high CPU, low memory)
  /static/*  --> CDN/Static Servers (high bandwidth)
  /admin/*   --> Admin Servers (restricted network)
/ws/*      --> WebSocket Servers (persistent connections)</pre>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #166534">Header-Based Routing</strong>
<pre style="margin: 8px 0 0 0; color: #166534; font-size: 14px; background: #dcfce7; padding: 12px; border-radius: 6px">X-API-Version: v2  --> V2 API Servers
  Accept: application/grpc --> gRPC Servers
X-Tenant-ID: premium --> Premium Tier Servers</pre>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #166534">Cookie-Based Routing (A/B Testing)</strong>
<pre style="margin: 8px 0 0 0; color: #166534; font-size: 14px; background: #dcfce7; padding: 12px; border-radius: 6px">experiment=control  --> Production Servers (90%)
experiment=variant  --> Experiment Servers (10%)</pre>
</div>
</div>
</div>
<h3 id="when-to-choose-l4-vs-l7">When to Choose L4 vs L7</h3>
<div style="background: #fef3c7;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #92400e; margin-top: 0">Decision Framework</h4>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px">
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #1e40af">Choose Layer 4 When:</strong>
<ul style="color: #475569; margin: 8px 0 0 0; padding-left: 20px; font-size: 14px">
<li>Maximum throughput is critical (millions of connections)</li>
<li>Protocol is not HTTP (database connections, game servers)</li>
<li>End-to-end encryption required (TLS passthrough)</li>
<li>Simple round-robin or IP-hash is sufficient</li>
<li>Backend servers are homogeneous</li>
</ul>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #7c3aed">Choose Layer 7 When:</strong>
<ul style="color: #475569; margin: 8px 0 0 0; padding-left: 20px; font-size: 14px">
<li>Content-based routing needed (path, headers)</li>
<li>SSL termination at load balancer</li>
<li>Request/response transformation needed</li>
<li>Advanced health checks (HTTP status codes)</li>
<li>WebSocket protocol upgrade handling</li>
<li>[[API Gateway]](/topic/system-design/api-gateway) functionality</li>
</ul>
</div>
</div>
<div style="background: #fef9c3; padding: 16px; border-radius: 8px; margin-top: 16px">
<span style="color: #166534; font-weight: 600">**Trade-off:**</span> Many architectures use both - L4 at the edge for high-throughput TCP distribution, then L7 internally for intelligent HTTP routing. This is called "two-tier load balancing."
</div>
</div>
<h3 id="l4-vs-l7-interview-questions-3-levels-deep">L4 vs L7 Interview Questions (3 Levels Deep)</h3>
<div style="background: #eff6ff;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e40af; margin-top: 0">Level 1: What is the difference between Layer 4 and Layer 7 load balancing?</h4>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> Layer 4 load balancing operates at the transport layer, making routing decisions based on IP addresses and TCP/UDP ports without inspecting packet contents. Layer 7 operates at the application layer, inspecting HTTP headers, URLs, cookies, and request bodies to make intelligent routing decisions. L4 is faster but less flexible; L7 is more capable but adds latency.</p>
<div style="background: white; border-radius: 8px; padding: 20px; margin-top: 16px">
<h5 style="color: #1e40af; margin-top: 0">Level 2: How does SSL/TLS handling differ between L4 and L7 load balancers?</h5>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> L4 load balancers can either pass through encrypted traffic (TLS passthrough) or terminate TLS. With passthrough, the load balancer cannot inspect content but maintains end-to-end encryption. L7 load balancers must terminate TLS to inspect HTTP content, then optionally re-encrypt for backend communication (TLS re-encryption). <span style="color: #166534; font-weight: 600">**Trade-off:**</span> TLS termination at L7 enables content inspection and caching but means traffic between LB and backend may be unencrypted unless re-encrypted. For compliance requirements (PCI-DSS), you may need TLS passthrough or re-encryption. See [[network-protocols]](/topic/system-design/network-protocols) for TLS details.</p>
<div style="background: #f8fafc; border-radius: 8px; padding: 16px; margin-top: 12px">
<h6 style="color: #1e40af; margin-top: 0">Level 3: You're designing a system that needs to handle 10 million concurrent WebSocket connections. How do you architect the load balancing layer?</h6>
<p style="color: #1e293b; line-height: 1.7; font-size: 14px"><strong>Answer:</strong> This requires a hybrid approach. (1) <strong>Edge layer (L4):</strong> Use L4 load balancers (AWS NLB or dedicated hardware) to distribute TCP connections across multiple L7 instances. L4 handles millions of connections with minimal overhead. (2) <strong>Protocol layer (L7):</strong> L7 load balancers handle the WebSocket upgrade (HTTP -> WS) and route based on path/headers. Use consistent hashing by client ID so reconnections go to the same backend. (3) <strong>Backend awareness:</strong> WebSockets are stateful, so backends must handle connection state. Options: sticky sessions via consistent hashing, or externalize state to [[Redis]](/topic/system-design/caching) so any backend can handle any message. (4) <strong>Health checking:</strong> L4 uses TCP health checks; L7 can send WebSocket ping frames. (5) <strong>Connection draining:</strong> On backend shutdown, send WebSocket close frame with reconnect hint before TCP termination. <span style="color: #166534; font-weight: 600">**Assumption:**</span> This assumes backends can horizontally scale. If backends have per-connection state, you need either sticky sessions or a pub/sub layer ([[message-queues]](/topic/system-design/message-queues)) to route messages to the correct backend.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-2-load-balancing-algorithms">Section 2: Load Balancing Algorithms</h2>
<h3 id="algorithm-deep-dive">Algorithm Deep Dive</h3>
<p>The choice of load balancing algorithm fundamentally affects how traffic is distributed and how the system behaves under various conditions.</p>
<div style="background: #f8fafc;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; margin-top: 0">Algorithm Comparison Matrix</h4>
<div style="overflow-x: auto">
<table style="width: 100%; border-collapse: collapse; font-size: 14px">
<tr style="background: #f1f5f9">
<th style="padding: 12px; text-align: left; color: #1e293b">Algorithm</th>
<th style="padding: 12px; text-align: left; color: #1e293b">How It Works</th>
<th style="padding: 12px; text-align: left; color: #1e293b">Time Complexity</th>
<th style="padding: 12px; text-align: left; color: #1e293b">Best For</th>
<th style="padding: 12px; text-align: left; color: #1e293b">Drawback</th>
</tr>
<tr>
<td style="padding: 12px; color: #1e293b"><strong><a href="algorithms/round-robin.html" style="color: #2563eb; text-decoration: none">Round Robin</a></strong></td>
<td style="padding: 12px; color: #475569">Sequential rotation through servers</td>
<td style="padding: 12px; color: #475569">O(1)</td>
<td style="padding: 12px; color: #475569">Homogeneous servers, short requests</td>
<td style="padding: 12px; color: #dc2626">Ignores server load completely</td>
</tr>
<tr>
<td style="padding: 12px; color: #1e293b"><strong><a href="algorithms/weighted-round-robin.html" style="color: #2563eb; text-decoration: none">Weighted Round Robin</a></strong></td>
<td style="padding: 12px; color: #475569">RR with capacity-based weights</td>
<td style="padding: 12px; color: #475569">O(1)</td>
<td style="padding: 12px; color: #475569">Heterogeneous server capacities</td>
<td style="padding: 12px; color: #dc2626">Static weights don't adapt</td>
</tr>
<tr>
<td style="padding: 12px; color: #1e293b"><strong><a href="algorithms/least-connections.html" style="color: #2563eb; text-decoration: none">Least Connections</a></strong></td>
<td style="padding: 12px; color: #475569">Route to server with fewest active connections</td>
<td style="padding: 12px; color: #475569">O(n) or O(log n) with heap</td>
<td style="padding: 12px; color: #475569">Long-lived connections (WebSocket, DB)</td>
<td style="padding: 12px; color: #dc2626">Doesn't account for request complexity</td>
</tr>
<tr>
<td style="padding: 12px; color: #1e293b"><strong><a href="algorithms/least-response-time.html" style="color: #2563eb; text-decoration: none">Least Response Time</a></strong></td>
<td style="padding: 12px; color: #475569">Combine connections + response latency</td>
<td style="padding: 12px; color: #475569">O(n)</td>
<td style="padding: 12px; color: #475569">Latency-sensitive applications</td>
<td style="padding: 12px; color: #dc2626">Requires latency tracking</td>
</tr>
<tr>
<td style="padding: 12px; color: #1e293b"><strong><a href="algorithms/ip-hash.html" style="color: #2563eb; text-decoration: none">IP Hash</a></strong></td>
<td style="padding: 12px; color: #475569">Hash client IP to determine server</td>
<td style="padding: 12px; color: #475569">O(1)</td>
<td style="padding: 12px; color: #475569">Basic session persistence</td>
<td style="padding: 12px; color: #dc2626">Uneven if IPs cluster (NAT)</td>
</tr>
<tr>
<td style="padding: 12px; color: #1e293b"><strong><a href="algorithms/consistent-hashing.html" style="color: #2563eb; text-decoration: none">Consistent Hashing</a></strong></td>
<td style="padding: 12px; color: #475569">Minimal key redistribution on changes</td>
<td style="padding: 12px; color: #475569">O(log n)</td>
<td style="padding: 12px; color: #475569">Distributed caches, stateful services</td>
<td style="padding: 12px; color: #dc2626">Complex implementation, requires virtual nodes</td>
</tr>
</table>
</div>
</div>
<div style="background: #f0fdf4; border-radius: 12px; padding: 24px; margin: 20px 0">
<p style="color: #1e293b; line-height: 1.7">Each algorithm has been documented in detail on its own dedicated page with diagrams and Python implementations. Click on any algorithm name in the table above to learn more.</p>
</div>
<h3 id="algorithm-selection-interview-questions-3-levels-deep">Algorithm Selection Interview Questions (3 Levels Deep)</h3>
<div style="background: #eff6ff;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e40af; margin-top: 0">Level 1: When would you choose Least Connections over Round Robin?</h4>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> Choose Least Connections when requests have highly variable processing times. Round robin assumes all requests complete quickly and evenly, but if some requests take 100ms and others take 10 seconds, round robin can overload servers with slow requests. Least connections naturally routes new requests to servers that have finished previous work, adapting to actual server load.</p>
<div style="background: white; border-radius: 8px; padding: 20px; margin-top: 16px">
<h5 style="color: #1e40af; margin-top: 0">Level 2: What's the problem with basic IP hashing for session persistence, and how does consistent hashing solve it?</h5>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> Basic IP hashing uses `hash(IP) % N` to select a server. When servers are added/removed (N changes), almost all keys remap to different servers, invalidating caches and breaking sessions. Consistent hashing places servers on a ring; when a server is removed, only keys between it and its predecessor move to the next server clockwise - roughly 1/N keys instead of all keys. <span style="color: #166534; font-weight: 600">**Trade-off:**</span> Consistent hashing requires more memory (ring structure) and has O(log N) lookup vs O(1) for modular hashing. For small, stable server pools, simple hashing may be sufficient. See [[database-sharding]](/topic/system-design/database-sharding) for similar concepts.</p>
<div style="background: #f8fafc; border-radius: 8px; padding: 16px; margin-top: 12px">
<h6 style="color: #1e40af; margin-top: 0">Level 3: You're building a distributed cache where cache effectiveness depends on request locality (same user hitting same cache server). How do you handle the cold-start problem when adding new cache servers?</h6>
<p style="color: #1e293b; line-height: 1.7; font-size: 14px"><strong>Answer:</strong> Adding a server to a consistent hash ring causes ~1/N keys to remap, but those keys will initially have cache misses (cold cache). Solutions: (1) <strong>Warm-up period:</strong> Add new server with zero weight, gradually increase weight over minutes as cache populates from backend fetches. (2) <strong>Cache copying:</strong> Before enabling new server, have it subscribe to writes going to servers whose key ranges it will absorb. Pre-populate hot keys using access logs. (3) <strong>Two-tier hashing:</strong> Hash to a logical partition first, then hash partitions to servers. Adding a server moves whole partitions, allowing batch pre-warming. (4) <strong>Bounded load consistent hashing:</strong> Google's algorithm caps maximum load per server; when a server is "full," keys overflow to next server, naturally spreading hot keys across multiple servers. <span style="color: #166534; font-weight: 600">**Assumption:**</span> This assumes cache misses going to backend is acceptable during transition. For truly zero-downtime, you need cache replication, which adds complexity and memory cost. See [[caching]](/topic/system-design/caching) for cache warming strategies.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-3-health-checks">Section 3: Health Checks</h2>
<h3 id="deep-mechanics-1">Deep Mechanics</h3>
<p>Health checks are the nervous system of load balancing - they detect failed or degraded servers and automatically route traffic away before users experience errors.</p>
<div style="background: #f8fafc;border-radius: 16px; padding: 32px; margin: 24px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 24px 0">Health Check Architecture</h4>
<div style="display: flex; flex-direction: column; gap: 24px">
<div style="display: flex; align-items: center; justify-content: center; gap: 32px">
<div style="background: linear-gradient(135deg, #3b82f6 0%, #1d4ed8 100%); padding: 20px 32px; border-radius: 12px; text-align: center; color: white">
<div style="font-weight: 700; font-size: 16px">Load Balancer</div>
<div style="font-size: 12px; opacity: 0.9; margin-top: 4px">Health Check Engine</div>
</div>
<div style="display: flex; flex-direction: column; gap: 8px; align-items: center">
<div style="color: #22c55e; font-size: 16px">---> TCP SYN</div>
<div style="color: #22c55e; font-size: 16px"><--- TCP ACK</div>
<div style="color: #3b82f6; font-size: 12px">Every 5 seconds</div>
</div>
<div style="display: flex; flex-direction: column; gap: 12px">
<div style="background: #dcfce7; padding: 12px 20px; border-radius: 8px">
<div style="color: #166534; font-weight: 600">Server 1</div>
<div style="color: #16a34a; font-size: 11px">Healthy</div>
</div>
<div style="background: #dcfce7; padding: 12px 20px; border-radius: 8px">
<div style="color: #166534; font-weight: 600">Server 2</div>
<div style="color: #16a34a; font-size: 11px">Healthy</div>
</div>
<div style="background: #fee2e2; padding: 12px 20px; border-radius: 8px">
<div style="color: #991b1b; font-weight: 600">Server 3</div>
<div style="color: #dc2626; font-size: 11px">Unhealthy (3 failures)</div>
</div>
</div>
</div>
</div>
</div>
<h3 id="health-check-types">Health Check Types</h3>
<div style="background: #f8fafc;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e293b; margin-top: 0">Health Check Comparison</h4>
<div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px">
<div style="background: #f0fdf4;border-radius: 12px; padding: 20px">
<h5 style="color: #166534; margin: 0 0 12px 0">TCP Health Check</h5>
<div style="color: #475569; font-size: 13px; margin-bottom: 12px">
  Attempts TCP connection to port. Success = server is listening.
</div>
<div style="background: white; padding: 12px; border-radius: 6px; font-family: monospace; font-size: 12px">
<div style="color: #166534">SYN --></div>
<div style="color: #166534"><-- SYN-ACK</div>
<div style="color: #166534">ACK --></div>
<div style="color: #64748b; margin-top: 4px">(3-way handshake)</div>
</div>
<div style="margin-top: 12px; font-size: 12px">
<div style="color: #166534">+ Very fast (~1ms)</div>
<div style="color: #166534">+ Works with any TCP service</div>
<div style="color: #991b1b">- Can't detect app-level issues</div>
</div>
</div>
<div style="background: #eff6ff;border-radius: 12px; padding: 20px">
<h5 style="color: #1e40af; margin: 0 0 12px 0">HTTP Health Check</h5>
<div style="color: #475569; font-size: 13px; margin-bottom: 12px">
  Sends HTTP request, validates response status code.
</div>
<div style="background: white; padding: 12px; border-radius: 6px; font-family: monospace; font-size: 12px">
<div style="color: #1e40af">GET /health HTTP/1.1</div>
<div style="color: #64748b">Host: backend:8080</div>
<div style="color: #166534; margin-top: 8px">HTTP/1.1 200 OK</div>
<div style="color: #166534">{"status": "healthy"}</div>
</div>
<div style="margin-top: 12px; font-size: 12px">
<div style="color: #166534">+ Can check app health</div>
<div style="color: #166534">+ Validates HTTP stack</div>
<div style="color: #991b1b">- Slower than TCP</div>
</div>
</div>
<div style="background: #f3e8ff;border-radius: 12px; padding: 20px">
<h5 style="color: #7c3aed; margin: 0 0 12px 0">Deep Health Check</h5>
<div style="color: #475569; font-size: 13px; margin-bottom: 12px">
  Application checks dependencies (DB, cache, external APIs).
</div>
<div style="background: white; padding: 12px; border-radius: 6px; font-family: monospace; font-size: 11px">
<div style="color: #7c3aed">GET /health/deep</div>
<div style="color: #166534; margin-top: 8px">{"status": "healthy",</div>
<div style="color: #166534"> "db": "connected",</div>
<div style="color: #166534"> "redis": "connected",</div>
<div style="color: #166534"> "latency_ms": 12}</div>
</div>
<div style="margin-top: 12px; font-size: 12px">
<div style="color: #166534">+ Detects dependency failures</div>
<div style="color: #166534">+ Can include latency metrics</div>
<div style="color: #991b1b">- Expensive to run frequently</div>
</div>
</div>
</div>
</div>
<h3 id="health-check-configuration">Health Check Configuration</h3>
<div style="background: #fff7ed;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #92400e; margin-top: 0">Critical Configuration Parameters</h4>
<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px">
<div style="background: white; padding: 16px; border-radius: 8px">
<div style="display: flex; align-items: center; gap: 12px; margin-bottom: 12px">
<span style="background: #3b82f6; color: white; padding: 6px 12px; border-radius: 6px; font-size: 13px; font-weight: 600">interval</span>
<span style="color: #1e293b; font-weight: 600">= 5s</span>
</div>
<div style="color: #475569; font-size: 13px">
  Time between health checks. Too short = overhead. Too long = slow detection.
<div style="margin-top: 8px; padding: 8px; background: #f0fdf4; border-radius: 4px">
<span style="color: #166534; font-weight: 600">**Trade-off:**</span> 5s interval means up to 5s of traffic to failing server before detection.
</div>
</div>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<div style="display: flex; align-items: center; gap: 12px; margin-bottom: 12px">
<span style="background: #ef4444; color: white; padding: 6px 12px; border-radius: 6px; font-size: 13px; font-weight: 600">unhealthy_threshold</span>
<span style="color: #1e293b; font-weight: 600">= 3</span>
</div>
<div style="color: #475569; font-size: 13px">
  Consecutive failures before marking unhealthy. Prevents flapping from transient failures.
<div style="margin-top: 8px; padding: 8px; background: #fef2f2; border-radius: 4px">
<span style="color: #991b1b">Detection time = interval × threshold = 15s</span>
</div>
</div>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<div style="display: flex; align-items: center; gap: 12px; margin-bottom: 12px">
<span style="background: #22c55e; color: white; padding: 6px 12px; border-radius: 6px; font-size: 13px; font-weight: 600">healthy_threshold</span>
<span style="color: #1e293b; font-weight: 600">= 2</span>
</div>
<div style="color: #475569; font-size: 13px">
  Consecutive successes before marking healthy again. Prevents thundering herd on recovery.
<div style="margin-top: 8px; padding: 8px; background: #f0fdf4; border-radius: 4px">
<span style="color: #166534">Recovery time = interval × threshold = 10s</span>
</div>
</div>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<div style="display: flex; align-items: center; gap: 12px; margin-bottom: 12px">
<span style="background: #f59e0b; color: white; padding: 6px 12px; border-radius: 6px; font-size: 13px; font-weight: 600">timeout</span>
<span style="color: #1e293b; font-weight: 600">= 2s</span>
</div>
<div style="color: #475569; font-size: 13px">
  Max time to wait for health check response. Must be less than interval.
<div style="margin-top: 8px; padding: 8px; background: #fef3c7; border-radius: 4px">
<span style="color: #92400e">Timeout counts as failure toward threshold.</span>
</div>
</div>
</div>
</div>
</div>
<h3 id="health-check-edge-cases">Health Check Edge Cases</h3>
<div style="background: #fef2f2;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #991b1b; margin-top: 0">Critical Health Check Failures</h4>
<div style="display: grid; gap: 16px">
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Flapping Servers</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">Server oscillates between healthy/unhealthy, causing traffic shifts. <strong>Solution:</strong> Increase thresholds, add exponential backoff before re-adding, investigate root cause (memory pressure, GC pauses).</p>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Health Check Passing But App Failing</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">Basic `/health` returns 200 but app is returning 500s for real requests. <strong>Solution:</strong> Deep health checks that test actual functionality. Include database queries, cache reads, external API calls in health endpoint. Related: [[circuit-breaker]](/topic/system-design/circuit-breaker) for detecting runtime failures.</p>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Cascading Health Check Failures</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">Database goes down, all servers fail deep health checks simultaneously. <strong>Solution:</strong> Separate liveness (is process running?) from readiness (can handle traffic?). Don't kill pods for dependency failures. Use [[circuit-breaker]](/topic/system-design/circuit-breaker) to degrade gracefully.</p>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Health Check Endpoint Crashes App</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">Expensive health check under load causes server to become unresponsive. <strong>Solution:</strong> Keep health endpoint cheap. Cache dependency check results. Use separate lightweight liveness endpoint.</p>
</div>
</div>
</div>
<h3 id="health-check-interview-questions-3-levels-deep">Health Check Interview Questions (3 Levels Deep)</h3>
<div style="background: #eff6ff;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e40af; margin-top: 0">Level 1: What types of health checks should a load balancer perform?</h4>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> Load balancers typically perform three types of health checks: (1) <strong>TCP checks</strong> - verify the port is accepting connections, (2) <strong>HTTP checks</strong> - verify the application returns expected status code (usually 200), and (3) <strong>Deep/Custom checks</strong> - verify the application can perform its function (database connectivity, cache access). TCP is fastest but least informative; deep checks are most thorough but expensive.</p>
<div style="background: white; border-radius: 8px; padding: 20px; margin-top: 16px">
<h5 style="color: #1e40af; margin-top: 0">Level 2: How do you balance between fast failure detection and avoiding false positives?</h5>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> This is tuned through the interval and threshold parameters. Shorter intervals detect failures faster but increase load and network traffic. Higher failure thresholds prevent marking servers unhealthy due to transient issues (network hiccup, GC pause) but slow detection of real failures. <span style="color: #166534; font-weight: 600">**Trade-off:**</span> A common configuration is 5s interval with 3 failure threshold (15s detection) and 2 success threshold (10s recovery). For critical low-latency systems, consider 2s interval with 2 failure threshold (4s detection) but monitor for flapping. Also implement passive health checking - if real requests are failing, mark unhealthy immediately without waiting for active checks.</p>
<div style="background: #f8fafc; border-radius: 8px; padding: 16px; margin-top: 12px">
<h6 style="color: #1e40af; margin-top: 0">Level 3: Your system has 1000 servers and health checks are causing network congestion. How do you scale health checking?</h6>
<p style="color: #1e293b; line-height: 1.7; font-size: 14px"><strong>Answer:</strong> Several strategies: (1) <strong>Hierarchical health checking:</strong> Instead of central LB checking all servers, use regional health aggregators that report to the LB. Each aggregator checks 50-100 servers. (2) <strong>Push-based health:</strong> Servers push their health status to a central registry (Consul, etcd). LB watches registry instead of polling all servers. (3) <strong>Sampling:</strong> For homogeneous server pools, check a random sample (10-20%) and assume others in same state. If sample shows failures, expand checking. (4) <strong>Staggered intervals:</strong> Randomize check timing to avoid synchronous health check storms. (5) <strong>Passive health:</strong> Track success/failure of real requests; use active checks only for servers not receiving traffic. (6) <strong>Connection reuse:</strong> Keep persistent connections to servers for health checks instead of new TCP handshake each time. <span style="color: #166534; font-weight: 600">**Assumption:**</span> This assumes servers are relatively homogeneous. If servers have different criticality, implement tiered checking - critical servers get frequent checks, others get infrequent. Related: [[microservices]](/topic/system-design/microservices) service discovery patterns.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-4-session-persistence-sticky-sessions">Section 4: Session Persistence (Sticky Sessions)</h2>
<h3 id="deep-mechanics-2">Deep Mechanics</h3>
<p>Session persistence ensures that requests from the same client are routed to the same backend server. This is necessary when servers maintain client state that isn't shared across the cluster.</p>
<div style="background: #f8fafc;border-radius: 16px; padding: 32px; margin: 24px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 24px 0">Sticky Session Mechanisms</h4>
<div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px">
<div style="background: #eff6ff;border-radius: 12px; padding: 20px">
<h5 style="color: #1e40af; margin: 0 0 12px 0">Cookie-Based</h5>
<div style="background: white; border-radius: 8px; padding: 12px; font-family: monospace; font-size: 11px; margin-bottom: 12px">
<div style="color: #64748b">Response Header:</div>
<div style="color: #1e40af">Set-Cookie: SERVERID=srv1;</div>
<div style="color: #1e40af">  Path=/; HttpOnly</div>
<div style="color: #64748b; margin-top: 8px">Subsequent Request:</div>
<div style="color: #166534">Cookie: SERVERID=srv1</div>
</div>
<div style="font-size: 12px">
<div style="color: #166534">+ Most reliable</div>
<div style="color: #166534">+ Survives IP changes</div>
<div style="color: #991b1b">- Requires cookie support</div>
<div style="color: #991b1b">- Cookie size limits</div>
</div>
</div>
<div style="background: #f0fdf4;border-radius: 12px; padding: 20px">
<h5 style="color: #166534; margin: 0 0 12px 0">IP-Based (Source Hash)</h5>
<div style="background: white; border-radius: 8px; padding: 12px; font-family: monospace; font-size: 11px; margin-bottom: 12px">
<div style="color: #64748b">Algorithm:</div>
<div style="color: #166534">hash(client_ip) % num_servers</div>
<div style="color: #64748b; margin-top: 8px">Example:</div>
<div style="color: #166534">192.168.1.100 --> Server 2</div>
<div style="color: #166534">192.168.1.100 --> Server 2</div>
</div>
<div style="font-size: 12px">
<div style="color: #166534">+ No cookies needed</div>
<div style="color: #166534">+ Works for non-HTTP</div>
<div style="color: #991b1b">- NAT breaks stickiness</div>
<div style="color: #991b1b">- Mobile IP changes</div>
</div>
</div>
<div style="background: #f3e8ff;border-radius: 12px; padding: 20px">
<h5 style="color: #7c3aed; margin: 0 0 12px 0">Application-Generated</h5>
<div style="background: white; border-radius: 8px; padding: 12px; font-family: monospace; font-size: 11px; margin-bottom: 12px">
<div style="color: #64748b">URL Parameter:</div>
<div style="color: #7c3aed">/checkout?sid=abc123</div>
<div style="color: #64748b; margin-top: 8px">LB Route Table:</div>
<div style="color: #7c3aed">abc123 --> Server 3</div>
</div>
<div style="font-size: 12px">
<div style="color: #166534">+ Full control</div>
<div style="color: #166534">+ Can encode metadata</div>
<div style="color: #991b1b">- Requires app changes</div>
<div style="color: #991b1b">- URL leakage risk</div>
</div>
</div>
</div>
</div>
<h3 id="problems-with-sticky-sessions">Problems with Sticky Sessions</h3>
<div style="background: #fef2f2;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #991b1b; margin-top: 0">Why Sticky Sessions Are Problematic</h4>
<div style="display: grid; gap: 16px">
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Uneven Load Distribution</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">Power users with many requests all go to same server. One "whale" customer can overload a server while others sit idle. Load balancing benefits are negated.</p>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Session Loss on Server Failure</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">When sticky server dies, all its sessions are lost. Users experience errors or must re-authenticate. Defeats the purpose of having multiple servers for reliability.</p>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Scaling Difficulties</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">Adding new servers doesn't help existing sessions. Removing servers requires draining connections or breaking sessions. Auto-scaling becomes complex.</p>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Deployment Complexity</strong>
<p style="color: #475569; margin: 8px 0 0 0; font-size: 14px">Rolling deployments must wait for sessions to drain. Blue-green deployments break existing sessions. Cannot quickly rollback if sessions are tied to new version.</p>
</div>
</div>
</div>
<h3 id="better-alternative-externalized-session-state">Better Alternative: Externalized Session State</h3>
<div style="background: #f0fdf4;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #166534; margin-top: 0">Externalized Session Architecture</h4>
<div style="display: flex; flex-direction: column; gap: 16px">
<div style="display: flex; align-items: center; justify-content: center; gap: 20px; flex-wrap: wrap">
<div style="background: #dbeafe; padding: 16px 24px; border-radius: 10px; text-align: center">
<div style="color: #1e40af; font-weight: 600">Client</div>
<div style="color: #64748b; font-size: 11px">Session ID in cookie</div>
</div>
<div style="color: #22c55e; font-size: 20px">---></div>
<div style="background: #fef3c7; padding: 16px 24px; border-radius: 10px; text-align: center">
<div style="color: #92400e; font-weight: 600">Load Balancer</div>
<div style="color: #64748b; font-size: 11px">Any algorithm (no stickiness)</div>
</div>
<div style="color: #22c55e; font-size: 20px">---></div>
<div style="background: #dcfce7; padding: 16px 24px; border-radius: 10px; text-align: center">
<div style="color: #166534; font-weight: 600">Any Server</div>
<div style="color: #64748b; font-size: 11px">Stateless application</div>
</div>
</div>
<div style="display: flex; justify-content: center">
<div style="color: #22c55e; font-size: 20px">|</div>
</div>
<div style="display: flex; justify-content: center">
<div style="background: #fee2e2; padding: 16px 32px; border-radius: 10px; text-align: center">
<div style="color: #991b1b; font-weight: 600">Redis/Memcached</div>
<div style="color: #64748b; font-size: 11px">Shared session store</div>
</div>
</div>
</div>
<div style="margin-top: 24px; display: grid; grid-template-columns: 1fr 1fr; gap: 16px">
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #166534">Benefits:</strong>
<ul style="color: #475569; margin: 8px 0 0 0; padding-left: 20px; font-size: 14px">
<li>Any server can handle any request</li>
<li>Server failures don't lose sessions</li>
<li>True horizontal scaling</li>
<li>Zero-downtime deployments</li>
</ul>
</div>
<div style="background: white; padding: 16px; border-radius: 8px">
<strong style="color: #166534">Implementation:</strong>
<ul style="color: #475569; margin: 8px 0 0 0; padding-left: 20px; font-size: 14px">
<li>Store sessions in [[Redis]](/topic/system-design/caching) with TTL</li>
<li>Use Redis Cluster for HA</li>
<li>Encrypt sensitive session data</li>
<li>Consider JWT for truly stateless auth</li>
</ul>
</div>
</div>
</div>
<h3 id="session-persistence-interview-questions-3-levels-deep">Session Persistence Interview Questions (3 Levels Deep)</h3>
<div style="background: #eff6ff;border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #1e40af; margin-top: 0">Level 1: What is session persistence in load balancing and when is it needed?</h4>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> Session persistence (sticky sessions) ensures requests from the same client always go to the same backend server. It's needed when servers maintain client-specific state that isn't shared, such as shopping carts in memory, file upload progress, or WebSocket connections. Without persistence, users could lose their state when routed to a different server.</p>
<div style="background: white; border-radius: 8px; padding: 20px; margin-top: 16px">
<h5 style="color: #1e40af; margin-top: 0">Level 2: How do you handle sticky sessions when the target server becomes unhealthy?</h5>
<p style="color: #1e293b; line-height: 1.7"><strong>Answer:</strong> When a sticky server fails, there are several strategies: (1) <strong>Fail to another server:</strong> Route to next server in pool; session state is lost but user can re-authenticate. (2) <strong>Session replication:</strong> Synchronously replicate sessions to backup server; expensive but preserves state. (3) <strong>External session store:</strong> Store sessions in Redis/database; any server can retrieve. (4) <strong>Client-side sessions:</strong> Encode session in encrypted cookie (JWT pattern); server is truly stateless. <span style="color: #166534; font-weight: 600">**Trade-off:**</span> Session replication adds latency to every write. External stores add network hop but provide best reliability. Client-side sessions have size limits and can't be revoked server-side. Most modern systems use external stores + JWT for authentication tokens.</p>
<div style="background: #f8fafc; border-radius: 8px; padding: 16px; margin-top: 12px">
<h6 style="color: #1e40af; margin-top: 0">Level 3: You're migrating a legacy application with in-memory sessions to Kubernetes. How do you handle session persistence during the transition?</h6>
<p style="color: #1e293b; line-height: 1.7; font-size: 14px"><strong>Answer:</strong> This requires a phased migration: (1) <strong>Phase 1 - External session store:</strong> Add Redis session storage alongside in-memory. Configure app to write to both, read from external first, fallback to local. This is "write-through" dual-write pattern. (2) <strong>Phase 2 - Sticky sessions with backup:</strong> Configure K8s Ingress for cookie-based sticky sessions. If pod dies, traffic goes to another pod which reads from Redis. Users don't notice pod restarts. (3) <strong>Phase 3 - Remove local sessions:</strong> Once confident in Redis reliability, remove in-memory session code. Now pods are stateless. (4) <strong>Phase 4 - Remove sticky sessions:</strong> With truly stateless pods, disable sticky sessions for better load distribution. <span style="color: #166534; font-weight: 600">**Assumption:**</span> This assumes you can modify application code. If not, consider sidecar pattern - run Redis session proxy as sidecar that intercepts session calls. For K8s specifically, use StatefulSets during transition if pods need stable identity, then migrate to Deployments when stateless. Monitor session Redis carefully - it becomes a critical dependency. See [[database-replication]](/topic/system-design/database-replication) for Redis HA patterns.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-5-connection-draining-and-graceful-shutdown">Section 5: Connection Draining and Graceful Shutdown</h2>
<h3 id="deep-mechanics-3">Deep Mechanics</h3>
<p>Connection draining allows in-flight requests to complete before a server is removed from the pool, preventing request failures during deployments or scale-down events.</p>
<div style="background: #f8fafc;border-radius: 16px; padding: 32px; margin: 24px 0">
<h4 style="color: #1e293b; text-align: center; margin: 0 0 24px 0">Connection Draining Timeline</h4>
<div style="display: flex; flex-direction: column; gap: 16px">
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #3b82f6; color: white; min-width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: 600">1</div>
<div style="flex: 1; background: #eff6ff; padding: 16px; border-radius: 8px">
<strong style="color: #1e40af">Drain Initiated</strong>
<div style="color: #475569; font-size: 13px; margin-top: 4px">Server marked for removal. Load balancer stops sending NEW requests.</div>
</div>
<div style="color: #64748b; font-size: 12px; min-width: 60px">t=0s</div>
</div>
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #f59e0b; color: white; min-width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: 600">2</div>
<div style="flex: 1; background: #fef3c7; padding: 16px; border-radius: 8px">
<strong style="color: #92400e">Draining</strong>
<div style="color: #475569; font-size: 13px; margin-top: 4px">Existing connections continue processing. Server completes in-flight requests.</div>
</div>
<div style="color: #64748b; font-size: 12px; min-width: 60px">t=0-30s</div>
</div>
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #22c55e; color: white; min-width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: 600">3</div>
<div style="flex: 1; background: #f0fdf4; padding: 16px; border-radius: 8px">
<strong style="color: #166534">Drained</strong>
<div style="color: #475569; font-size: 13px; margin-top: 4px">All connections closed gracefully. Server safe to terminate.</div>
</div>
<div style="color: #64748b; font-size: 12px; min-width: 60px">t=30s</div>
</div>
<div style="display: flex; align-items: center; gap: 16px">
<div style="background: #ef4444; color: white; min-width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: 600">4</div>
<div style="flex: 1; background: #fef2f2; padding: 16px; border-radius: 8px">
<strong style="color: #991b1b">Timeout (if not drained)</strong>
<div style="color: #475569; font-size: 13px; margin-top: 4px">Force close remaining connections. Some requests may fail.</div>
</div>
<div style="color: #64748b; font-size: 12px; min-width: 60px">t=60s</div>
</div>
</div>
</div>
<hr />
<h2 id="common-pitfalls">Common Pitfalls</h2>
<div style="background: #fef2f2; border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #991b1b; margin-top: 0">Mistakes to Avoid</h4>
<div style="display: flex; flex-direction: column; gap: 12px; color: #1e293b">
<div style="background: #fff; padding: 12px; border-radius: 8px">
<strong>Single Load Balancer:</strong> Your LB becomes a single point of failure. Always deploy in pairs with failover. Use DNS failover or floating IP for LB high availability.
</div>
<div style="background: #fff; padding: 12px; border-radius: 8px">
<strong>No Health Checks:</strong> Without health checks, traffic routes to dead servers causing user errors. Implement both active (polling) and passive (track real request failures) health checking.
</div>
<div style="background: #fff; padding: 12px; border-radius: 8px">
<strong>Ignoring Connection Draining:</strong> Removing servers without draining connections drops active requests. Configure drain timeout to allow in-flight requests to complete.
</div>
<div style="background: #fff; padding: 12px; border-radius: 8px">
<strong>Wrong Algorithm Choice:</strong> Using round robin for WebSocket connections ignores server load entirely. Use least connections for long-lived connections.
</div>
<div style="background: #fff; padding: 12px; border-radius: 8px">
<strong>No Monitoring:</strong> Without metrics on latency and error rates, you cannot detect degradation. Monitor RED metrics (Rate, Errors, Duration) per backend server.
</div>
<div style="background: #fff; padding: 12px; border-radius: 8px">
<strong>Sticky Sessions Without Fallback:</strong> Sessions break when sticky server fails. Always have externalized session backup or accept session loss gracefully.
</div>
</div>
</div>
<hr />
<h2 id="code-examples">Code Examples</h2>
<h3 id="python---load-balancer-framework">Python - Load Balancer Framework</h3>
<p style="color: #64748b; font-style: italic; margin-bottom: 16px">For specific algorithm implementations (Round Robin, Weighted Round Robin, Least Connections, etc.), see the dedicated algorithm pages linked in the table above.</p>
<div class="collapsible-code collapsed">
    <div class="code-header">
        <span>Python</span>
        <span class="code-toggle-icon">▶</span>
    </div>
    <div class="code-content">
        <pre><code class="language-python">from abc import ABC, abstractmethod
from typing import List
import time

class Server:
    """Represents a backend server"""
    def __init__(self, url: str):
        self.url = url
        self.is_alive = True
        self.last_health_check = time.time()

    def handle_request(self, request):
        """Process incoming request"""
        return f"Response from {self.url}"

class LoadBalancerStrategy(ABC):
    """Abstract strategy for server selection"""

    @abstractmethod
    def select_server(self, servers: List[Server]) -> Server:
        """Select next server based on algorithm"""
        pass

class LoadBalancer:
    """Generic load balancer framework"""

    def __init__(self, servers: List[Server], strategy: LoadBalancerStrategy):
        self.servers = servers
        self.strategy = strategy

    def route_request(self, request):
        """Route request to selected server"""
        # Get healthy servers only
        healthy_servers = [s for s in self.servers if s.is_alive]

        if not healthy_servers:
            raise Exception("No healthy servers available")

        # Use strategy to select server
        server = self.strategy.select_server(healthy_servers)

        # Forward request
        return server.handle_request(request)

    def health_check(self):
        """Perform health checks on all servers"""
        for server in self.servers:
            try:
                # Check server health (simplified)
                server.is_alive = self.check_server_health(server)
                server.last_health_check = time.time()
            except Exception:
                server.is_alive = False

    def check_server_health(self, server: Server) -> bool:
        """Check if server is healthy"""
        # Implementation would make actual health check request
        return True
</code></pre>
    </div>
</div>
<h3 id="nginx-configuration---production-load-balancing">Nginx Configuration - Production Load Balancing</h3>
<div class="collapsible-code collapsed">
    <div class="code-header">
        <span>Nginx</span>
        <span class="code-toggle-icon">▶</span>
    </div>
    <div class="code-content">
        <pre><code class="language-nginx"># Upstream configuration with health checks and load balancing
upstream api_backend {
    # Least connections algorithm
    least_conn;

    # Server pool with weights and health parameters
    server backend1.example.com:8080 weight=5 max_fails=3 fail_timeout=30s;
    server backend2.example.com:8080 weight=3 max_fails=3 fail_timeout=30s;
    server backend3.example.com:8080 weight=2 max_fails=3 fail_timeout=30s;

    # Backup server (only used when all primary servers are down)
    server backup.example.com:8080 backup;

    # Keep connections alive to reduce TCP handshake overhead
    keepalive 32;
    keepalive_timeout 60s;
}

# Upstream for WebSocket with consistent hashing
upstream websocket_backend {
    # Consistent hashing by client IP for session persistence
    hash $remote_addr consistent;

    server ws1.example.com:8080;
    server ws2.example.com:8080;
    server ws3.example.com:8080;
}

server {
    listen 80;
    listen 443 ssl http2;

    server_name api.example.com;

    # SSL configuration
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;

    # API endpoints
    location /api/ {
        proxy_pass http://api_backend;

        # HTTP/1.1 for keepalive
        proxy_http_version 1.1;
        proxy_set_header Connection &quot;&quot;;

        # Forward client information
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts
        proxy_connect_timeout 5s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # Retry on failure (idempotent methods only)
        proxy_next_upstream error timeout http_502 http_503;
        proxy_next_upstream_tries 3;
        proxy_next_upstream_timeout 10s;
    }

    # WebSocket endpoints
    location /ws/ {
        proxy_pass http://websocket_backend;

        # WebSocket upgrade
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection &quot;upgrade&quot;;

        # Longer timeouts for persistent connections
        proxy_read_timeout 3600s;
        proxy_send_timeout 3600s;
    }

    # Health check endpoint (for upstream health checks)
    location /health {
        access_log off;
        return 200 &quot;OK\n&quot;;
        add_header Content-Type text/plain;
    }
}
</code></pre>
    </div>
</div>
<hr />
<h2 id="best-practices">Best Practices</h2>
<div style="background: #f0fdf4; border-radius: 12px; padding: 24px; margin: 20px 0">
<h4 style="color: #166534; margin-top: 0">Production Checklist</h4>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; color: #1e293b">
<div>
<strong style="color: #166534">High Availability</strong>
<ul style="margin: 4px 0 0 0; padding-left: 20px; color: #475569">
<li>Deploy load balancers in pairs (active-passive or active-active)</li>
<li>Use DNS failover or floating IP for LB redundancy</li>
<li>Distribute across availability zones</li>
</ul>
</div>
<div>
<strong style="color: #166534">Health Checks</strong>
<ul style="margin: 4px 0 0 0; padding-left: 20px; color: #475569">
<li>Configure appropriate intervals (5-10s)</li>
<li>Set reasonable thresholds (2-3 failures)</li>
<li>Include deep health checks for dependencies</li>
</ul>
</div>
<div>
<strong style="color: #166534">Connection Management</strong>
<ul style="margin: 4px 0 0 0; padding-left: 20px; color: #475569">
<li>Enable connection draining (30-60s timeout)</li>
<li>Use connection pooling with keepalive</li>
<li>Set appropriate timeouts per endpoint type</li>
</ul>
</div>
<div>
<strong style="color: #166534">Monitoring</strong>
<ul style="margin: 4px 0 0 0; padding-left: 20px; color: #475569">
<li>Track RED metrics (Rate, Errors, Duration)</li>
<li>Monitor connection counts and queue depths</li>
<li>Alert on backend health state changes</li>
</ul>
</div>
<div>
<strong style="color: #166534">Security</strong>
<ul style="margin: 4px 0 0 0; padding-left: 20px; color: #475569">
<li>Terminate TLS at load balancer</li>
<li>Re-encrypt for backend if required</li>
<li>Implement [[rate-limiting]](/topic/system-design/rate-limiting)</li>
</ul>
</div>
<div>
<strong style="color: #166534">Scaling</strong>
<ul style="margin: 4px 0 0 0; padding-left: 20px; color: #475569">
<li>Externalize session state to [[Redis]](/topic/system-design/caching)</li>
<li>Use stateless backends when possible</li>
<li>Consider [[CDN]](/topic/system-design/cdn) for static content</li>
</ul>
</div>
</div>
</div>
<hr />
<div class="concept-section type-deep-learning">
<h2 id="deep-learning-qa">Deep Learning Q&A</h2>
<p style="color: #64748b; margin-bottom: 24px;">Challenge yourself with these open-ended questions. Each answer leads to deeper exploration.</p>

<!-- Question 1: Load Balancing Algorithm Selection -->
<div style="background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #92400e; margin: 0 0 16px 0;">Q1: You're designing a video streaming platform where some requests are quick metadata lookups (10ms) while others are heavy video transcoding jobs (30+ seconds). All requests go through the same load balancer. Which algorithm would you choose and why?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;"><strong>Weighted Least Connections</strong> is the best choice here. Pure Round Robin would send transcoding jobs evenly, potentially overwhelming servers already processing heavy jobs. Least Connections alone doesn't account for the fact that one transcoding connection is 3000x more expensive than a metadata lookup.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">Better yet: <strong>Split the traffic at Layer 7</strong>. Route <code>/api/metadata/*</code> to a lightweight server pool with Round Robin (fast, cheap requests). Route <code>/api/transcode/*</code> to a heavy compute pool with Least Connections. This prevents metadata requests from being blocked behind transcoding queues.</p>

<!-- Nested Q1.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.1: What if you can't split traffic because both request types share the same endpoint?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Use <strong>Least Response Time</strong> algorithm, which considers both active connections AND recent response latency. Servers stuck on transcoding jobs will have high response times, so new requests route elsewhere. Alternatively, implement <strong>adaptive load balancing</strong> that monitors server CPU/memory and adjusts weights dynamically. HAProxy and Envoy support this with agent checks.</p>

<!-- Nested Q1.1.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.1: How do you prevent a "thundering herd" when a previously overloaded server recovers?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>slow start</strong>: When a server recovers, gradually increase its weight over 30-60 seconds. Start at 10% capacity, increase by 10% every 5 seconds. This prevents the load balancer from immediately sending 100% traffic to a freshly recovered server. HAProxy supports this with <code>slowstart</code> parameter. Also use <strong>connection limits</strong> per backend to cap maximum concurrent connections.</p>
</div>
</details>
</div>

<!-- Nested Q1.1.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.2: What metrics would you use to tune the algorithm weights?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Track: (1) <strong>Request latency percentiles</strong> (p50, p95, p99) per server - high p99 indicates struggling servers. (2) <strong>Active connection count</strong> over time - should be roughly equal across servers. (3) <strong>Error rate</strong> per backend - timeouts indicate overload. (4) <strong>CPU/memory utilization</strong> from agent checks. Set alerts when any server's p99 latency exceeds 2x the pool average, triggering weight reduction.</p>
</div>
</details>
</div>

<!-- Nested Q1.1.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.1.3: How do you handle the case where all servers are overloaded?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>load shedding</strong> at the load balancer level: (1) Set a <strong>max queue depth</strong> - reject new requests with 503 when queue exceeds threshold. (2) Use <strong>priority queues</strong> - authenticated users get priority over anonymous. (3) Return <strong>Retry-After</strong> headers so clients back off. (4) Trigger <strong>auto-scaling</strong> when queue depth exceeds threshold for 60 seconds. It's better to reject some requests cleanly than to let all requests timeout.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q1.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.2: Some users complain that their video uploads keep failing. You discover they're being routed to different servers mid-upload. How do you fix this?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Implement <strong>session affinity (sticky sessions)</strong> for upload endpoints. Options: (1) <strong>Cookie-based</strong>: Set a <code>SERVERID</code> cookie on first request, use it for routing. (2) <strong>IP-hash</strong>: Hash client IP to consistent server (but breaks behind NAT). (3) <strong>Consistent hashing</strong> on upload session ID - most reliable. For chunked uploads, include the upload ID in the URL and use it as the hash key.</p>

<!-- Nested Q1.2.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.1: What happens if the sticky session server goes down mid-upload?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Two approaches: (1) <strong>Client-side retry</strong>: Return an error that triggers client to restart upload. Good for small files. (2) <strong>Shared storage</strong>: Store partial uploads in distributed storage (S3, shared NFS). Any server can resume. This is how large platforms handle it - upload chunks go directly to object storage, server just orchestrates. The load balancer routes to any healthy server since state is external.</p>
</div>
</details>
</div>

<!-- Nested Q1.2.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.2: Cookie-based stickiness exposes your server topology. Is this a security risk?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Yes, exposing <code>SERVERID=backend-web-3</code> leaks internal infrastructure. Mitigate by: (1) <strong>Encrypt the cookie</strong> with a server-side key - client sees random bytes. (2) Use <strong>opaque session IDs</strong> mapped to servers in load balancer memory. (3) <strong>Sign the cookie</strong> with HMAC to prevent tampering. HAProxy's <code>cookie insert indirect nocache httponly secure</code> handles this. Never expose actual hostnames or IPs in cookies.</p>
</div>
</details>
</div>

<!-- Nested Q1.2.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.2.3: How do you handle sticky sessions during a rolling deployment?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>connection draining</strong>: (1) Mark server as "draining" - no new sessions routed. (2) Existing sticky sessions continue until complete or timeout (60s). (3) After drain period, remove server from pool. (4) Deploy new version, add back to pool. For long uploads, extend drain timeout or implement resume capability. Kubernetes does this automatically with <code>terminationGracePeriodSeconds</code>.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q1.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #3b82f6;">
<h4 style="color: #1e40af; margin: 0 0 8px 0;">Q1.3: Your platform now has premium users who pay for faster transcoding. How do you prioritize their requests?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Create <strong>separate backend pools</strong>: Premium pool with dedicated high-performance servers, Standard pool with shared resources. Route at L7 based on user tier (from JWT claims or header). Set <strong>weighted traffic splitting</strong>: if premium pool is overloaded, overflow to standard pool (degraded but available). Never overflow standard to premium - that defeats the purpose.</p>

<!-- Nested Q1.3.1 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.1: How do you prevent abuse where users fake premium headers?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Validate at the load balancer</strong>: (1) Use signed JWTs - load balancer verifies signature before routing. (2) Integrate with your auth service - make a lightweight lookup to verify tier. (3) Use a <strong>trusted header</strong> that's only set by your API gateway (strip any client-provided version). HAProxy and Envoy can do JWT validation natively. Never trust client-provided tier information without cryptographic verification.</p>
</div>
</details>
</div>

<!-- Nested Q1.3.2 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.2: Premium users are only 5% of traffic but you have 50% of servers dedicated to them. How do you optimize?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>elastic pool boundaries</strong>: (1) Set a minimum guaranteed capacity for premium (e.g., 10 servers). (2) Allow premium to "borrow" from standard pool when needed. (3) Standard can use "excess" premium capacity when premium is idle. Use priority queuing - premium jobs preempt standard jobs on shared servers. Monitor and adjust based on actual usage patterns. This maximizes utilization while maintaining SLA guarantees.</p>
</div>
</details>
</div>

<!-- Nested Q1.3.3 -->
<div style="background: #e0f2fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #0369a1; margin: 0 0 8px 0;">Q1.3.3: How do you measure and report that premium users actually get better performance?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Track <strong>SLI/SLO metrics by tier</strong>: (1) <strong>Queue wait time</strong>: Premium should be <5s, Standard <60s. (2) <strong>Transcoding latency percentiles</strong>: Compare p50/p95 between tiers. (3) <strong>Availability</strong>: Premium gets 99.9%, Standard 99.0%. Build a dashboard showing real-time comparison. Alert if premium metrics approach standard levels. Report these metrics to customers in their billing dashboard to justify the premium pricing.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Question 2: Load Balancer Failover -->
<div style="background: linear-gradient(135deg, #dbeafe 0%, #bfdbfe 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #1e40af; margin: 0 0 16px 0;">Q2: Your application uses a single load balancer. The CEO asks: "What happens if the load balancer itself fails?" How do you design for high availability of the load balancer layer?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Deploy <strong>active-passive or active-active load balancer pairs</strong>. Active-passive: Two LBs share a virtual IP (VIP) via VRRP/keepalived. Primary handles traffic; if it fails, secondary claims the VIP within 1-3 seconds. Active-active: Both LBs are live behind DNS round-robin or an upstream L4 load balancer. Traffic splits across both; either can handle full load if one fails.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">In cloud environments, use <strong>managed load balancers</strong> (AWS ALB/NLB, GCP Load Balancer) which are inherently redundant across availability zones. They handle failover automatically - this is the easiest path to HA.</p>

<!-- Nested Q2.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.1: During failover, existing TCP connections are dropped. How do you minimize user impact?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Several strategies: (1) <strong>Connection state synchronization</strong>: Replicate connection tables between active/passive LBs so the standby can resume connections. (2) <strong>Client-side retry logic</strong>: Applications should automatically reconnect on connection reset. (3) <strong>Graceful degradation</strong>: Use shorter keepalive intervals so connections are naturally shorter. (4) <strong>Session externalization</strong>: Don't rely on LB connection state - store session data in Redis so any connection to any backend works.</p>

<!-- Nested Q2.1.1 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.1: What's the typical failover time, and how do you reduce it?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">VRRP-based failover is typically 1-3 seconds (3 missed heartbeats at 1s interval). To reduce: (1) <strong>Decrease heartbeat interval</strong> to 200ms (but increases network chatter). (2) <strong>Use BFD</strong> (Bidirectional Forwarding Detection) for sub-second detection. (3) <strong>Active-active eliminates failover entirely</strong> - traffic just flows to the surviving LB. (4) Cloud LBs typically achieve <100ms failover within their infrastructure.</p>
</div>
</details>
</div>

<!-- Nested Q2.1.2 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.2: How do you detect if a load balancer is "alive but not working" (e.g., routing to dead backends)?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>end-to-end health checks</strong>: (1) External monitors (Pingdom, Datadog) that hit your actual endpoints through the LB. (2) <strong>Synthetic transactions</strong> that test the full request path every 10 seconds. (3) If the LB is up but all backends are marked unhealthy, trigger failover to the secondary LB (maybe it has different health check results). (4) Monitor LB-specific metrics: connection errors, 5xx rates, latency spikes. Alert and failover on anomalies, not just on LB process death.</p>
</div>
</details>
</div>

<!-- Nested Q2.1.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.1.3: How do you prevent "split-brain" where both LBs think they're primary?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Split-brain occurs when network partition makes each LB think the other is dead. Solutions: (1) <strong>STONITH (Shoot The Other Node In The Head)</strong>: Use a fencing mechanism to power off the old primary before new one activates. (2) <strong>Quorum-based election</strong>: Require witness node to agree on leader (3-node minimum). (3) <strong>Cloud-managed LBs avoid this entirely</strong> - AWS handles leader election for you. (4) If split-brain occurs, having both LBs active is often safer than having none - duplicate traffic is better than no traffic.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q2.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.2: Your data center has two LBs, but what if the entire data center goes down?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Implement <strong>multi-region/multi-datacenter failover</strong>: (1) <strong>DNS-based failover</strong>: Use Route53, Cloudflare, or NS1 health checks. If primary DC is unhealthy, DNS automatically routes to secondary DC. TTL tradeoff: low TTL (30s) = faster failover but more DNS traffic. (2) <strong>Anycast</strong>: Same IP announced from multiple DCs via BGP. Traffic routes to nearest healthy DC automatically. (3) <strong>Global load balancers</strong> (Cloudflare, AWS Global Accelerator): Provide a single entry point with built-in geo-routing and failover.</p>

<!-- Nested Q2.2.1 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.1: DNS TTL is 5 minutes. Users will hit the dead DC for 5 minutes after failover. How do you solve this?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Multiple approaches: (1) <strong>Lower TTL proactively</strong>: Before maintenance, reduce TTL to 30s, wait 5 minutes for propagation, then failover. (2) <strong>Use Global Accelerator/Anycast</strong>: IP routing changes are instant at network layer, no DNS caching issues. (3) <strong>Client-side failover</strong>: Return multiple IPs in DNS (both DCs), client tries next IP on connection failure. (4) <strong>Edge proxy</strong>: Cloudflare/Fastly in front can route around DC failures instantly since they control the edge.</p>
</div>
</details>
</div>

<!-- Nested Q2.2.2 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.2: Your secondary DC can only handle 60% of normal traffic. What do you do during failover?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Implement <strong>graceful degradation</strong>: (1) <strong>Feature flags</strong>: Disable non-critical features (recommendations, analytics) during failover. (2) <strong>Rate limiting</strong>: Aggressively limit requests per user. (3) <strong>Static fallbacks</strong>: Serve cached/static versions of dynamic pages. (4) <strong>Priority queuing</strong>: Process paid users first, queue others. (5) <strong>Auto-scale secondary DC</strong>: Trigger aggressive scaling on failover event. Design your DR capacity based on minimum viable service, not full parity.</p>
</div>
</details>
</div>

<!-- Nested Q2.2.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.2.3: How do you test DC failover without actually causing an outage?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Chaos engineering practices</strong>: (1) <strong>GameDay exercises</strong>: Scheduled failover tests during low-traffic windows (Sunday 3 AM). (2) <strong>Synthetic traffic failover</strong>: Route only test traffic to secondary, verify it works. (3) <strong>Gradual traffic shifting</strong>: Move 1%, 5%, 10% of real traffic to secondary, monitor metrics. (4) <strong>Failure injection</strong>: Use Chaos Monkey to kill instances in primary DC, observe failover behavior. Netflix runs these continuously. Document and practice your runbooks quarterly.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q2.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #8b5cf6;">
<h4 style="color: #6d28d9; margin: 0 0 8px 0;">Q2.3: After a failover event, the primary DC comes back online. Should traffic automatically fail back?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;"><strong>Generally, no automatic failback</strong>. Reasons: (1) The primary may have come back but not be fully healthy. (2) Failback causes another disruption (connection resets, cache cold-start). (3) The root cause may not be fixed - could fail again immediately. Best practice: <strong>Manual failback</strong> after verification. Gradually shift traffic back (10% -> 50% -> 100%) while monitoring. Only automate failback if you have extremely high confidence in your health checks.</p>

<!-- Nested Q2.3.1 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.1: What checks should pass before allowing failback?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Failback readiness checklist: (1) <strong>All health checks passing</strong> for at least 5 minutes (not just one success). (2) <strong>Database replication caught up</strong> - no lag between primary and replica. (3) <strong>Cache warmed</strong> - pre-populate critical caches before taking traffic. (4) <strong>Synthetic transactions succeeding</strong> end-to-end. (5) <strong>On-call team ready</strong> - don't failback at 2 AM with skeleton crew. (6) <strong>Root cause identified</strong> or at least mitigated. Create a runbook with these steps.</p>
</div>
</details>
</div>

<!-- Nested Q2.3.2 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.2: You're running active-active across both DCs. Is failback even a concept?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">In true active-active, <strong>there's no failback - just rebalancing</strong>. When the recovered DC comes online, traffic gradually shifts back to 50/50 (or geo-based) distribution. This is the advantage of active-active: no discrete failover events, just continuous adjustment. However, data synchronization is harder - you need multi-master replication or conflict resolution. Active-active is operationally simpler but architecturally more complex.</p>
</div>
</details>
</div>

<!-- Nested Q2.3.3 -->
<div style="background: #ede9fe; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #5b21b6; margin: 0 0 8px 0;">Q2.3.3: How do you handle data written to the secondary DC during failover?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">This is the hardest problem. Options: (1) <strong>Read-only secondary</strong>: Writes queue or fail during failover, replay when primary recovers. Simplest but limits functionality. (2) <strong>Write to secondary, replicate back</strong>: Secondary accepts writes, syncs to primary when it recovers. Risk of conflicts. (3) <strong>External write store</strong>: Writes go to a globally-distributed system (DynamoDB Global Tables, CockroachDB) that handles multi-region automatically. (4) <strong>Accept data loss</strong>: For some data (analytics, logs), losing a few minutes is acceptable. Choose based on your consistency requirements.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Question 3: Scaling Load Balancers -->
<div style="background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%); border-radius: 16px; padding: 24px; margin: 20px 0;">
<h3 style="color: #166534; margin: 0 0 16px 0;">Q3: Your e-commerce platform handles 100K requests/second normally but expects 10x traffic during Black Friday. How do you scale your load balancing infrastructure?</h3>
<details style="margin-top: 16px;">
<summary style="cursor: pointer; font-weight: 600; color: #1e293b; padding: 8px; background: rgba(255,255,255,0.5); border-radius: 8px;">View Answer</summary>
<div style="padding: 16px; background: white; border-radius: 8px; margin-top: 12px;">
<p style="color: #334155; line-height: 1.7;">Layer your load balancing: (1) <strong>Edge layer</strong>: Use a CDN (Cloudflare, Fastly) to absorb static content requests - this can handle 80% of traffic without hitting your LBs. (2) <strong>DNS layer</strong>: Multiple LB IPs via weighted DNS, geo-routing to nearest LB cluster. (3) <strong>L4 tier</strong>: Hardware LBs or cloud NLBs that can handle millions of connections with minimal processing. (4) <strong>L7 tier</strong>: Horizontally scaled software LBs (HAProxy, Envoy) behind the L4 layer. Each tier can scale independently.</p>
<p style="color: #334155; line-height: 1.7; margin-top: 12px;">For cloud-native: <strong>AWS NLB + ALB combination</strong>. NLB handles TCP distribution to ALB instances. ALBs auto-scale based on load. Pre-warm by contacting AWS support before major events.</p>

<!-- Nested Q3.1 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.1: You've heard that load balancers themselves have connection limits. How do you calculate if you'll hit them?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Calculate <strong>concurrent connections</strong>: Connections = (Requests/sec) x (Average connection duration). For HTTP/1.1 with keepalive: 1M req/s with 5s keepalive = 5M concurrent connections. For HTTP/2 with multiplexing: Far fewer connections needed. Key limits to check: (1) AWS ALB: 25K concurrent connections per target (can be increased). (2) HAProxy: Limited by file descriptors (ulimit), typically 100K-500K. (3) Hardware LBs: Fixed by model, F5 goes up to 10M+. Add 2x headroom for spikes.</p>

<!-- Nested Q3.1.1 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.1: How do you monitor connection utilization and predict when you'll hit limits?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Track: (1) <strong>Active connections</strong>: Current count vs maximum. Alert at 70% utilization. (2) <strong>Connection rate</strong>: New connections/sec. (3) <strong>Connection errors</strong>: ECONNREFUSED, ETIMEDOUT indicate limit reached. (4) <strong>Time-in-state</strong>: Connections stuck in CLOSE_WAIT indicate backend issues. Plot historical trends with linear regression to predict when you'll exceed capacity. For Black Friday, use last year's data + expected growth.</p>
</div>
</details>
</div>

<!-- Nested Q3.1.2 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.2: What kernel tuning is needed for high-connection load balancers?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Key sysctl tunings: (1) <code>net.core.somaxconn</code>: Increase to 65535 (listen backlog). (2) <code>net.ipv4.tcp_max_syn_backlog</code>: 65535 for SYN flood resilience. (3) <code>net.ipv4.ip_local_port_range</code>: "1024 65535" for outbound connections. (4) <code>net.core.netdev_max_backlog</code>: 50000 for high packet rates. (5) <code>fs.file-max</code> and <code>ulimit -n</code>: 1000000+ for file descriptors. (6) Enable <code>tcp_tw_reuse</code> for faster port recycling. Document these in your provisioning automation.</p>
</div>
</details>
</div>

<!-- Nested Q3.1.3 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.1.3: HTTP/2 multiplexes requests over single connections. Does this change capacity planning?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Yes, significantly. HTTP/2 reduces connections by 10-100x (one connection per client vs. 6-8 for HTTP/1.1). However, each connection carries more streams, so: (1) <strong>Connection count decreases</strong>, but (2) <strong>Memory per connection increases</strong> (stream state tracking). (3) <strong>CPU increases</strong> for HPACK header compression. Plan for fewer connections but more resources per connection. HTTP/3 (QUIC) changes this again - no head-of-line blocking, even more efficient. Monitor actual behavior, not theoretical limits.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q3.2 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.2: Adding more load balancers means more IPs to manage. How do you abstract this from clients?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;">Several abstraction layers: (1) <strong>DNS with multiple A records</strong>: Return all LB IPs, client picks one (usually first). (2) <strong>Virtual IP (VIP)</strong>: Single IP shared by LB cluster via VRRP or ECMP. (3) <strong>Global load balancer</strong>: Cloudflare, AWS Global Accelerator provide single IP that routes to nearest healthy LB. (4) <strong>Service mesh</strong>: Client-side load balancing (Envoy sidecar) discovers backends via service registry, no central LB needed. The trend is toward (4) for microservices.</p>

<!-- Nested Q3.2.1 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.2.1: DNS returns 10 IPs but clients only try the first one. How do you fix uneven distribution?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Enable <strong>DNS round-robin shuffling</strong>: DNS server returns IPs in different order for each query. Also: (1) <strong>Short TTL</strong>: Forces more frequent lookups, more shuffling. (2) <strong>Client-side randomization</strong>: Some clients shuffle locally. (3) <strong>Happy Eyeballs (RFC 6555)</strong>: Modern clients try multiple IPs concurrently. (4) <strong>Just use a global LB</strong>: Single anycast IP solves this completely. DNS load balancing is imprecise - it's a starting point, not a complete solution.</p>
</div>
</details>
</div>

<!-- Nested Q3.2.2 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.2.2: You're using a service mesh with client-side load balancing. What happens when the service registry is down?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Client proxies (Envoy) cache the last known good configuration. If registry (Consul, Kubernetes API) is unavailable: (1) <strong>Use cached endpoints</strong>: Continue routing to known-good backends. (2) <strong>Health checks continue</strong>: Sidecar still monitors backend health, removes failed ones. (3) <strong>No new backends discovered</strong>: Can't add capacity during outage. This is why service mesh control planes must be highly available. Run multiple registry replicas across availability zones.</p>
</div>
</details>
</div>

<!-- Nested Q3.2.3 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.2.3: Client-side LB means every client needs to be updated for algorithm changes. How do you manage this?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Use <strong>xDS dynamic configuration</strong>: Envoy (and similar proxies) fetch configuration from a control plane (Istio, Consul Connect). To change algorithms: (1) Update the control plane configuration. (2) Push new config to all sidecars dynamically. (3) No client restart needed. This is why service meshes use sidecar proxies instead of SDK-based load balancing - the sidecar can be updated independently of the application. Trade-off: Added complexity and resource overhead of running sidecars.</p>
</div>
</details>
</div>
</div>
</details>
</div>

<!-- Nested Q3.3 -->
<div style="background: #f1f5f9; border-radius: 8px; padding: 16px; margin-top: 16px; border-left: 4px solid #22c55e;">
<h4 style="color: #15803d; margin: 0 0 8px 0;">Q3.3: Black Friday is in 2 weeks. What's your pre-scaling checklist?</h4>
<details>
<summary style="cursor: pointer; color: #475569;">View Answer</summary>
<div style="padding: 12px; background: white; border-radius: 6px; margin-top: 8px;">
<p style="color: #334155; font-size: 14px;"><strong>Load Balancer Readiness Checklist</strong>: (1) <strong>Capacity review</strong>: Verify LB connection limits, request AWS/GCP to pre-warm if using cloud LBs. (2) <strong>Load test</strong>: Simulate 10x traffic in staging, identify breaking points. (3) <strong>Scale horizontally</strong>: Add more LB instances, verify they're in rotation. (4) <strong>Cache warming</strong>: Pre-populate CDN caches with sale pages. (5) <strong>Feature flags ready</strong>: Prepare to disable non-essential features. (6) <strong>Runbooks updated</strong>: Document scaling procedures, rollback plans. (7) <strong>Alerts tuned</strong>: Adjust thresholds for expected higher baseline. (8) <strong>War room scheduled</strong>: Staff on-call with escalation paths.</p>

<!-- Nested Q3.3.1 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.3.1: You can't load test production and staging doesn't match. How do you validate?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;">Options: (1) <strong>Shadow traffic</strong>: Replay production traffic to staging at 10x speed. (2) <strong>Canary production testing</strong>: Route 1% of real traffic to new capacity, monitor closely. (3) <strong>Synthetic load in production</strong>: Generate fake requests during off-peak (2-4 AM) that hit real infrastructure but don't affect data. (4) <strong>Progressive rollout</strong>: Scale up 2 days early, take real traffic gradually. (5) <strong>Component testing</strong>: Test LB in isolation with mock backends that simulate latency profiles. Combine multiple approaches for confidence.</p>
</div>
</details>
</div>

<!-- Nested Q3.3.2 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.3.2: Traffic exceeds even your 10x projections. What's your emergency response?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Emergency Traffic Management</strong>: (1) <strong>Enable aggressive caching</strong>: Cache previously dynamic content. (2) <strong>Shed non-critical traffic</strong>: Return 503 for analytics, recommendations. (3) <strong>Queue with estimated wait times</strong>: Better UX than random failures. (4) <strong>Geographic isolation</strong>: Limit to primary markets if needed. (5) <strong>Contact cloud provider</strong>: AWS/GCP can often provision emergency capacity. (6) <strong>Communicate</strong>: Status page update, social media. The goal is controlled degradation, not cascading failure. Have these scripts ready to execute in minutes.</p>
</div>
</details>
</div>

<!-- Nested Q3.3.3 -->
<div style="background: #dcfce7; padding: 12px; border-radius: 6px; margin-top: 12px;">
<h5 style="color: #166534; margin: 0 0 8px 0;">Q3.3.3: After Black Friday, how do you scale back down efficiently?</h5>
<details>
<summary style="cursor: pointer; color: #475569; font-size: 13px;">View Answer</summary>
<div style="padding: 8px; background: white; border-radius: 4px; margin-top: 6px;">
<p style="color: #334155; font-size: 13px;"><strong>Gradual cooldown</strong>: (1) <strong>Don't scale down immediately</strong>: Traffic may have a long tail (returns, support). (2) <strong>Use scaling policies</strong>: Auto-scaling naturally reduces capacity as traffic drops. (3) <strong>Drain before removing</strong>: Let connections complete, don't force-terminate. (4) <strong>Keep some headroom</strong>: Maintain 20% extra capacity for a week (Cyber Monday, returns). (5) <strong>Post-mortem</strong>: Document what worked, what didn't, for next year. (6) <strong>Cost analysis</strong>: Compare actual spend to projections, optimize for next event.</p>
</div>
</details>
</div>
</div>
</details>
</div>
</div>
</details>
</div>
</div>

<!-- Pros and Cons Section -->
<hr />
<div class="concept-section type-analysis">
<h2 id="pros-cons-analysis">Load Balancing: Pros & Cons Analysis</h2>

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 24px; margin: 24px 0;">

<!-- Pros -->
<div style="background: linear-gradient(135deg, #ecfdf5 0%, #d1fae5 100%); border-radius: 16px; padding: 24px;">
<h3 style="color: #065f46; margin: 0 0 20px 0; display: flex; align-items: center; gap: 8px;">
<span style="font-size: 24px;">+</span> Pros
</h3>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Eliminates Single Points of Failure</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">If one server crashes, traffic automatically routes to healthy servers. Users experience zero downtime.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>The load balancer itself can be a SPOF - always deploy in HA pairs</li>
<li>Health check configuration is critical - too aggressive causes flapping, too slow delays failover</li>
<li>Test failover regularly - don't discover it's broken during an incident</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Enables Horizontal Scaling</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Add more servers to handle increased load without modifying application code. Scale linearly with demand.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Application must be stateless or use external session storage</li>
<li>Database often becomes the bottleneck when app tier scales</li>
<li>New servers need cache warming to avoid performance dip</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">Simplifies Deployments and Maintenance</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Rolling deployments with zero downtime. Take servers out of rotation for maintenance without affecting users.</p>
<div style="background: #f0fdf4; padding: 12px; border-radius: 8px; border-left: 3px solid #22c55e;">
<strong style="color: #166534; font-size: 13px;">What to Care About:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Connection draining timeout must be long enough for in-flight requests</li>
<li>Blue/green deployments need 2x resources during transition</li>
<li>Version compatibility between old and new servers during rollout</li>
</ul>
</div>
</div>
</div>

<!-- Cons -->
<div style="background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%); border-radius: 16px; padding: 24px;">
<h3 style="color: #991b1b; margin: 0 0 20px 0; display: flex; align-items: center; gap: 8px;">
<span style="font-size: 24px;">-</span> Cons
</h3>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Adds Latency and Complexity</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Every request passes through an additional network hop. More moving parts to monitor, configure, and debug.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Use L4 balancing for latency-critical paths (adds ~0.1ms vs ~1ms for L7)</li>
<li>Co-locate load balancers with backends to minimize network hops</li>
<li>Implement proper observability - distributed tracing through the LB layer</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px; margin-bottom: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Session Persistence Challenges</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">Stateful applications break when requests go to different servers. Sticky sessions limit load distribution effectiveness.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Externalize session state to Redis or Memcached</li>
<li>Use JWTs for stateless authentication</li>
<li>If sticky sessions required, use consistent hashing to minimize disruption on server changes</li>
</ul>
</div>
</div>

<div style="background: white; border-radius: 12px; padding: 16px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">Can Mask Backend Problems</h4>
<p style="color: #334155; font-size: 14px; margin: 0 0 12px 0;">A slow backend might not be detected until it severely impacts user experience. Load balancers can hide partial failures.</p>
<div style="background: #fef2f2; padding: 12px; border-radius: 8px; border-left: 3px solid #ef4444;">
<strong style="color: #991b1b; font-size: 13px;">How to Manage:</strong>
<ul style="color: #475569; font-size: 13px; margin: 8px 0 0 0; padding-left: 16px;">
<li>Implement deep health checks that test actual functionality, not just port availability</li>
<li>Monitor per-backend metrics (latency, error rate) independently</li>
<li>Use circuit breakers to fail fast when backends degrade</li>
</ul>
</div>
</div>
</div>
</div>
</div>

<hr />
<h2 id="related-topics">Related Topics</h2>
<ul>
<li><a href="/topic/system-design/api-gateway">[API Gateway]</a> - Layer 7 routing with authentication and transformation</li>
<li><a href="/topic/system-design/rate-limiting">[Rate Limiting]</a> - Protecting backends from overload</li>
<li><a href="/topic/system-design/circuit-breaker">[Circuit Breaker]</a> - Failing fast when backends are unhealthy</li>
<li><a href="/topic/system-design/caching">[Caching]</a> - Reducing backend load with Redis/Memcached</li>
<li><a href="/topic/system-design/cdn">[CDN]</a> - Edge caching and global load distribution</li>
<li><a href="/topic/system-design/database-sharding">[Database Sharding]</a> - Consistent hashing for data distribution</li>
<li><a href="/topic/system-design/message-queues">[Message Queues]</a> - Asynchronous load handling</li>
<li><a href="/topic/system-design/microservices">[Microservices]</a> - Service discovery and inter-service communication</li>
</ul>
<script>
document.addEventListener('DOMContentLoaded', function() {
    const headers = document.querySelectorAll('.code-header');
    headers.forEach(header => {
        header.addEventListener('click', function(e) {
            e.preventDefault();
            const container = this.closest('.collapsible-code');
            container.classList.toggle('collapsed');
        });
    });
});
</script>
