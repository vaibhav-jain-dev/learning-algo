<h1 id="event-sourcing">Event Sourcing</h1>
<h2 id="overview">Overview</h2>
<p><span><strong>Event Sourcing</strong></span> is an architectural pattern where you store all changes to application state as a sequence of <span><strong>immutable events</strong></span>, rather than storing just the current state. Think of it like a bank statement - instead of just showing your current balance, it shows every transaction that led to that balance.</p>
<p>When you need the current state, you <span><strong>replay all events</strong></span> from the beginning (or from a snapshot) to reconstruct it. This gives you a complete audit trail and the ability to understand exactly how you got to any particular state.</p>
<div>
<h4>Core Principle</h4>
<div>
    "Don't store state. Store the facts that led to that state."
</div>
<div>
    Events are immutable historical facts. The current state is a left-fold over the event stream.
</div>
</div>
<hr />
<h2 id="why-this-matters">Why This Matters</h2>
<h3 id="real-company-examples">Real Company Examples</h3>
<div>
<h4>Companies Using Event Sourcing</h4>
<div>
<div>
<div>Netflix - Viewing History</div>
<div>Netflix stores every play, pause, seek, and completion event. This enables "Continue Watching" features, personalized recommendations, and analytics on viewing patterns across millions of users.</div>
</div>
<div>
<div>Stripe - Payment Processing</div>
<div>Every payment state change is an event: created, authorized, captured, refunded. This provides complete audit trails for financial compliance and enables rebuilding payment states for dispute resolution.</div>
</div>
<div>
<div>LinkedIn - Activity Feed</div>
<div>Posts, likes, comments, and shares are all events. This enables building multiple views (feed, notifications, analytics) from the same event stream without duplicating business logic.</div>
</div>
<div>
<div>LMAX Exchange - Financial Trading</div>
<div>Processes 6 million transactions/second with sub-millisecond latency using event sourcing. Complete audit trail built-in, with ability to replay any trading day for debugging or compliance.</div>
</div>
</div>
</div>
<p><strong>Key Benefits:</strong></p>
<ul>
<li><span><strong>Complete audit trail</strong></span>: Every change is recorded with timestamp and context</li>
<li><span><strong>Temporal queries</strong></span>: Answer &quot;what was the state at time X?&quot;</li>
<li><span><strong>Debugging</strong></span>: Replay events to reproduce bugs exactly</li>
<li><span><strong>Flexibility</strong></span>: Build new read models from existing events</li>
<li><span><strong>Compliance</strong></span>: Financial and healthcare regulations often require event history</li>
</ul>
<hr />
<h2 id="core-concepts-deep-dive">Core Concepts Deep Dive</h2>
<h3 id="the-event-store">The Event Store</h3>
<p>The <span><strong>Event Store</strong></span> is the heart of an event-sourced system - an append-only log that stores all events in the order they occurred.</p>
<div>
<h4>Event Store Architecture</h4>
<div>
<div>
<div>
<div>Event Stream: order-12345</div>
<div>Aggregate ID identifies the stream</div>
</div>
<div>
  Append-Only
</div>
</div>
<div>
<div>Version</div>
<div>Event Type</div>
<div>Timestamp</div>
<div>Data (JSON)</div>
</div>
<div>
<div>1</div>
<div>OrderCreated</div>
<div>10:00:01</div>
<div>{customer: "C1"}</div>
</div>
<div>
<div>2</div>
<div>ItemAdded</div>
<div>10:00:05</div>
<div>{sku: "ABC", qty: 2}</div>
</div>
<div>
<div>3</div>
<div>ItemAdded</div>
<div>10:00:12</div>
<div>{sku: "XYZ", qty: 1}</div>
</div>
<div>
<div>4</div>
<div>OrderSubmitted</div>
<div>10:00:30</div>
<div>{total: 150.00}</div>
</div>
<div>
<div>5</div>
<div>PaymentReceived</div>
<div>10:01:15</div>
<div>{amount: 150.00}</div>
</div>
</div>
<div>
<div>
<div>Immutable</div>
<div>Events never change once written</div>
</div>
<div>
<div>Ordered</div>
<div>Version number ensures ordering</div>
</div>
<div>
<div>Complete</div>
<div>Full history preserved forever</div>
</div>
</div>
</div>
<p><strong>Event Store Key Properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><span><strong>Append-only</strong></span></td>
<td>Events can only be added, never modified or deleted</td>
<td>Guarantees audit integrity, simplifies concurrency</td>
</tr>
<tr>
<td><span><strong>Optimistic Concurrency</strong></span></td>
<td>Version check on write prevents conflicts</td>
<td>Multiple writers can't corrupt stream</td>
</tr>
<tr>
<td><span><strong>Partitioned by Aggregate</strong></span></td>
<td>Each aggregate has its own event stream</td>
<td>Enables parallel processing, isolation</td>
</tr>
<tr>
<td><span><strong>Global Ordering</strong></span></td>
<td>Global sequence number across all streams</td>
<td>Enables consistent projections</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="snapshots">Snapshots</h3>
<p><span><strong>Snapshots</strong></span> are periodic saves of aggregate state that optimize event replay performance.</p>
<div>
<h4>Snapshot Strategy</h4>
<div>
<div>
<div>Without Snapshots</div>
<div>
<div>
<div>Event 1</div>
<div>Event 2</div>
<div>...</div>
<div>Event 999</div>
<div>Event 1000</div>
</div>
<div>
<div>Replay ALL 1000 events</div>
<div>Slow startup time</div>
</div>
</div>
</div>
<div>vs</div>
<div>
<div>With Snapshots</div>
<div>
<div>
<div>
<div>Snapshot @ v900</div>
<div>Full state saved</div>
</div>
<div>load</div>
<div>Event 901</div>
<div>...</div>
<div>Event 1000</div>
</div>
<div>
<div>Replay only 100 events</div>
<div>10x faster startup</div>
</div>
</div>
</div>
</div>
</div>
<p><strong>Snapshot Strategies:</strong></p>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>When to Snapshot</th>
<th>Trade-offs</th>
</tr>
</thead>
<tbody>
<tr>
<td><span><strong>Count-based</strong></span></td>
<td>Every N events (e.g., 100)</td>
<td>Simple, predictable</td>
</tr>
<tr>
<td><span><strong>Time-based</strong></span></td>
<td>Every N minutes/hours</td>
<td>Consistent timing</td>
</tr>
<tr>
<td><span><strong>On-demand</strong></span></td>
<td>When replay takes too long</td>
<td>Adaptive, efficient</td>
</tr>
<tr>
<td><span><strong>Background</strong></span></td>
<td>Async process creates snapshots</td>
<td>No write path impact</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="projections">Projections</h3>
<p><span><strong>Projections</strong></span> transform the event stream into read-optimized views (also called <span><strong>read models</strong></span>).</p>
<div>
<h4>Multiple Projections from Single Event Stream</h4>
<div>
    <!-- Event Stream -->
<div>
<div>Event Stream</div>
<div>OrderCreated, ItemAdded, PaymentReceived, OrderShipped...</div>
</div>
<pre><code>&lt;!-- Arrows --&gt;
</code></pre>
<div>
<div>
<div>|</div>
<div>V</div>
</div>
<div>
<div>|</div>
<div>V</div>
</div>
<div>
<div>|</div>
<div>V</div>
</div>
</div>
<pre><code>&lt;!-- Projections --&gt;
</code></pre>
<div>
<div>
<div>Order Summary</div>
<div>
  {<br>
  &nbsp;&nbsp;orderId: "123",<br>
  &nbsp;&nbsp;status: "shipped",<br>
  &nbsp;&nbsp;total: $150<br>
  }
</div>
<div>Optimized for: Order details page</div>
</div>
<div>
<div>Customer Orders</div>
<div>
  {<br>
  &nbsp;&nbsp;customerId: "C1",<br>
  &nbsp;&nbsp;orders: [123, 456],<br>
  &nbsp;&nbsp;totalSpent: $500<br>
  }
</div>
<div>Optimized for: Customer dashboard</div>
</div>
<div>
<div>Sales Analytics</div>
<div>
  {<br>
  &nbsp;&nbsp;date: "2024-01",<br>
  &nbsp;&nbsp;revenue: $50K,<br>
  &nbsp;&nbsp;orderCount: 340<br>
  }
</div>
<div>Optimized for: Reports</div>
</div>
</div>
</div>
<div>
<div>Projection Characteristics</div>
<div>
<div>Derived from events (can rebuild anytime)</div>
<div>Eventually consistent with event store</div>
<div>Optimized for specific query patterns</div>
<div>Can use different storage technologies</div>
</div>
</div>
</div>
<p><strong>Projection Types:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><span><strong>Live Projection</strong></span></td>
<td>Updated in real-time as events occur</td>
<td>User-facing queries</td>
</tr>
<tr>
<td><span><strong>Catch-up Projection</strong></span></td>
<td>Periodically catches up with event stream</td>
<td>Batch analytics</td>
</tr>
<tr>
<td><span><strong>One-time Projection</strong></span></td>
<td>Built once for specific analysis</td>
<td>Ad-hoc reports</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="cqrs-integration">CQRS Integration</h3>
<p><span><strong>CQRS (Command Query Responsibility Segregation)</strong></span> separates read and write operations into different models. Event Sourcing and CQRS are natural partners - see <a href="/topic/design-patterns/cqrs">[CQRS Pattern]</a> for detailed coverage.</p>
<div>
<h4>Event Sourcing + CQRS Architecture</h4>
<div>
  <!-- Top Row: Commands and Queries -->
<div>
<div>
<div>Commands</div>
<div>PlaceOrder, AddItem, CancelOrder</div>
<div>
  Write Path
</div>
</div>
<div></div>
<div>
<div>Queries</div>
<div>GetOrder, ListOrders, GetAnalytics</div>
<div>
  Read Path
</div>
</div>
</div>
  <!-- Arrows -->
<div>
<div>|<br>V</div>
<div></div>
<div>^<br>|</div>
</div>
  <!-- Middle: Domain + Projections -->
<div>
<div>
<div>Domain / Aggregates</div>
<div>Business logic, validation</div>
</div>
<div></div>
<div>
<div>Projections / Read Models</div>
<div>Denormalized, query-optimized</div>
</div>
</div>
  <!-- Arrows -->
<div>
<div>|<br>V</div>
<div><br>----></div>
<div>^<br>|</div>
</div>
  <!-- Event Store -->
<div>
<div>Event Store</div>
<div>Append-only log of all domain events</div>
<div>
<div>Source of Truth</div>
<div>Publishes Events</div>
</div>
</div>
</div>
</div>
<p><strong>Why Combine Event Sourcing with CQRS?</strong></p>
<table>
<thead>
<tr>
<th>Benefit</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td><span><strong>Independent Scaling</strong></span></td>
<td>Scale read and write sides separately based on load</td>
</tr>
<tr>
<td><span><strong>Optimized Models</strong></span></td>
<td>Write model for consistency, read models for queries</td>
</tr>
<tr>
<td><span><strong>Multiple Views</strong></span></td>
<td>Create any number of projections from same events</td>
</tr>
<tr>
<td><span><strong>Simpler Code</strong></span></td>
<td>Each side focused on single responsibility</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="event-versioning">Event Versioning</h3>
<p><span><strong>Event Versioning</strong></span> handles schema evolution when event structures need to change over time.</p>
<div>
<h4>Event Schema Evolution Strategies</h4>
<div>
  <!-- Upcasting -->
<div>
<div>
<div>1. Upcasting (Recommended)</div>
<div>Best Practice</div>
</div>
<div>Transform old events to new schema on-the-fly during read</div>
<div>
<div>
<div>V1 (stored)</div>
  {name: "Alice"}
</div>
<div>-></div>
<div>
<div>V2 (upcasted)</div>
  {owner: "Alice"}
</div>
<div>-></div>
<div>
<div>V3 (upcasted)</div>
  {owner: "Alice", currency: "USD"}
</div>
</div>
</div>
  <!-- Weak Schema -->
<div>
<div>2. Weak Schema / Optional Fields</div>
<div>Design events with optional fields, use defaults for missing data</div>
<div>
  event.data.get("currency", "USD")  # Default if not present
</div>
</div>
  <!-- New Event Type -->
<div>
<div>3. New Event Type</div>
<div>Create new event type for breaking changes, handle both in projections</div>
<div>
<div>OrderPlacedV1</div>
<div>OrderPlacedV2</div>
</div>
</div>
</div>
<div>
<div>Golden Rule: Never Modify Stored Events</div>
<div>Events are immutable historical facts. Transform on read, never on write.</div>
</div>
</div>
<hr />
<h3 id="replay-strategies">Replay Strategies</h3>
<p><span><strong>Event Replay</strong></span> is the process of re-processing events to rebuild state or projections.</p>
<div>
<h4>Replay Strategies Comparison</h4>
<div>
  <!-- Full Replay -->
<div>
<div>
  Full Replay
</div>
<div>
<div>
<div>
<div>When to Use</div>
<ul>
<li>Rebuilding projection from scratch</li>
<li>Fixing bugs in projection logic</li>
<li>Creating new projection</li>
</ul>
</div>
<div>
<div>Considerations</div>
<ul>
<li>Can be slow for large streams</li>
<li>Run during off-peak hours</li>
<li>Consider parallelization</li>
</ul>
</div>
</div>
</div>
</div>
  <!-- Partial Replay -->
<div>
<div>
  Partial Replay (from Snapshot)
</div>
<div>
<div>
<div>
<div>When to Use</div>
<ul>
<li>Loading aggregate for command</li>
<li>Recovery after crash</li>
<li>Hot standby sync</li>
</ul>
</div>
<div>
<div>Considerations</div>
<ul>
<li>Requires snapshot management</li>
<li>Trade-off: storage vs speed</li>
<li>Snapshot frequency tuning</li>
</ul>
</div>
</div>
</div>
</div>
  <!-- Parallel Replay -->
<div>
<div>
  Parallel Replay
</div>
<div>
<div>
<div>
<div>When to Use</div>
<ul>
<li>Massive event volumes</li>
<li>Time-critical rebuilds</li>
<li>Multi-tenant systems</li>
</ul>
</div>
<div>
<div>Considerations</div>
<ul>
<li>Partition by aggregate ID</li>
<li>Merge results carefully</li>
<li>Handle cross-aggregate queries</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<hr />
<h2 id="how-it-works">How It Works</h2>
<h3 id="traditional-vs-event-sourcing">Traditional vs Event Sourcing</h3>
<div>
<h4>State Storage Comparison</h4>
<div>
<div>
<div>Traditional (CRUD)</div>
<div>
  User: {<br>
  &nbsp;&nbsp;id: 123,<br>
  &nbsp;&nbsp;name: "Alice",<br>
  &nbsp;&nbsp;balance: 150<br>
  }
</div>
<div>Only current state stored. History is lost.</div>
</div>
<div>
<div>Event Sourcing</div>
<div>
  1. AccountCreated {id: 123, name: "Alice"}<br>
  2. MoneyDeposited {amount: 200}<br>
  3. MoneyWithdrawn {amount: 50}<br>
<div>Replay = balance: 150</div>
</div>
<div>Complete history. Can rebuild any point in time.</div>
</div>
</div>
</div>
<h3 id="core-components">Core Components</h3>
<div>
<h4>Event Sourcing Architecture</h4>
<div>
<div>
<div>
<div>Command</div>
<div>User Intent</div>
</div>
<div>-></div>
<div>
<div>Aggregate</div>
<div>Business Logic</div>
</div>
<div>-></div>
<div>
<div>Event</div>
<div>Fact Recorded</div>
</div>
</div>
<div>
<div>|<br>V</div>
</div>
<div>
<div>
<div>Event Store</div>
<div>Append-Only Log</div>
</div>
<div>-></div>
<div>
<div>Projection</div>
<div>Read Model</div>
</div>
</div>
</div>
<div>
<div>
<div>Event Store</div>
<div>Immutable, append-only log of all events</div>
</div>
<div>
<div>Aggregate</div>
<div>Domain entity that produces and applies events</div>
</div>
<div>
<div>Projection</div>
<div>Read model built by processing events</div>
</div>
</div>
</div>
<h3 id="event-flow">Event Flow</h3>
<div>
<h4>Processing a Command</h4>
<div>
<div>
<div>1</div>
<div><strong>Load Events:</strong> Retrieve all events for the aggregate from the event store</div>
</div>
<div>
<div>2</div>
<div><strong>Replay Events:</strong> Apply each event to rebuild current state</div>
</div>
<div>
<div>3</div>
<div><strong>Validate Command:</strong> Check if command is valid against current state</div>
</div>
<div>
<div>4</div>
<div><strong>Produce Events:</strong> Generate new events representing state changes</div>
</div>
<div>
<div>5</div>
<div><strong>Persist Events:</strong> Append new events to event store (with optimistic concurrency)</div>
</div>
<div>
<div>6</div>
<div><strong>Update Projections:</strong> Asynchronously update read models</div>
</div>
</div>
</div>
<hr />
<h2 id="real-life-failure-story">Real-Life Failure Story</h2>
<h3 id="lmax-exchange-architecture-evolution">LMAX Exchange Architecture Evolution</h3>
<div>
<h4>How Event Sourcing Solved a Performance Crisis</h4>
<div>
<div>The Challenge</div>
<div>
  LMAX, a financial exchange, needed to process 6 million orders per second with microsecond latency. Traditional database-backed systems couldn't handle the throughput requirements, and they needed complete audit trails for regulatory compliance.
</div>
</div>
<div>
<div>Traditional Approach Problems</div>
<div>
<div>Database writes: 1-10ms latency (too slow)</div>
<div>Audit logging: Separate system, consistency issues</div>
<div>Recovery: Complex, incomplete state restoration</div>
<div>Debugging: No way to replay production issues</div>
</div>
</div>
<div>
<div>Event Sourcing Solution</div>
<div>
<div>1. All state changes stored as events in an append-only journal</div>
<div>2. In-memory processing with journal replay for recovery</div>
<div>3. Complete audit trail built into the architecture</div>
<div>4. Can replay any day's events to reproduce issues</div>
<div>Result: 6 million transactions/second with less than 1ms latency</div>
</div>
</div>
</div>
<hr />
<h2 id="implementation">Implementation</h2>
<h3 id="complete-event-sourcing-system">Complete Event Sourcing System</h3>
<pre><code>                                              ```python
                                              from dataclasses import dataclass, field
                                              from datetime import datetime
                                              from typing import List, Dict, Optional, Any, Callable
                                              from abc import ABC, abstractmethod
                                              import uuid
                                              import json


                                              # ============ Events ============

                                              @dataclass
                                              class Event:
                                              &quot;&quot;&quot;Base class for all domain events.&quot;&quot;&quot;
                                              event_id: str = field(default_factory=lambda: str(uuid.uuid4()))
                                              aggregate_id: str = &quot;&quot;
                                              aggregate_type: str = &quot;&quot;
                                              event_type: str = &quot;&quot;
                                              data: Dict[str, Any] = field(default_factory=dict)
                                              metadata: Dict[str, Any] = field(default_factory=dict)
                                              version: int = 0
                                              timestamp: datetime = field(default_factory=datetime.utcnow)

                                              def to_dict(self) -&gt; dict:
                                              return {
                                              &quot;event_id&quot;: self.event_id,
                                              &quot;aggregate_id&quot;: self.aggregate_id,
                                              &quot;aggregate_type&quot;: self.aggregate_type,
                                              &quot;event_type&quot;: self.event_type,
                                              &quot;data&quot;: self.data,
                                              &quot;metadata&quot;: self.metadata,
                                              &quot;version&quot;: self.version,
                                              &quot;timestamp&quot;: self.timestamp.isoformat()
                                              }


                                              # ============ Event Store ============

                                              class EventStore:
                                              &quot;&quot;&quot;
                                              Append-only store for events with optimistic concurrency.

                                              In production, use EventStoreDB, PostgreSQL, or Kafka.
                                              &quot;&quot;&quot;

                                              def __init__(self):
                                              self._events: List[Event] = []
                                              self._streams: Dict[str, List[Event]] = {}
                                              self._subscribers: List[Callable[[Event], None]] = []

                                              def append(self, aggregate_id: str, events: List[Event],
                                              expected_version: int) -&gt; None:
                                              &quot;&quot;&quot;
                                              Append events with optimistic concurrency control.

                                              Raises ConcurrencyError if expected_version doesn't match.
                                              &quot;&quot;&quot;
                                              if aggregate_id not in self._streams:
                                              self._streams[aggregate_id] = []

                                              current_version = len(self._streams[aggregate_id])

                                              if expected_version != current_version:
                                              raise ConcurrencyError(
                                              f&quot;Expected version {expected_version}, &quot;
                                              f&quot;but stream is at version {current_version}&quot;
                                              )

                                              for i, event in enumerate(events):
                                              event.version = current_version + i + 1
                                              event.aggregate_id = aggregate_id
                                              self._events.append(event)
                                              self._streams[aggregate_id].append(event)

                                              # Notify subscribers
                                              for subscriber in self._subscribers:
                                              subscriber(event)

                                              def get_events(self, aggregate_id: str,
                                              from_version: int = 0) -&gt; List[Event]:
                                              &quot;&quot;&quot;Get events for an aggregate starting from a version.&quot;&quot;&quot;
                                              if aggregate_id not in self._streams:
                                              return []

                                              return [e for e in self._streams[aggregate_id]
                                              if e.version &gt; from_version]

                                              def get_all_events(self, from_position: int = 0) -&gt; List[Event]:
                                              &quot;&quot;&quot;Get all events across all aggregates (for projections).&quot;&quot;&quot;
                                              return self._events[from_position:]

                                              def subscribe(self, handler: Callable[[Event], None]) -&gt; None:
                                              &quot;&quot;&quot;Subscribe to new events (for real-time projections).&quot;&quot;&quot;
                                              self._subscribers.append(handler)


                                              class ConcurrencyError(Exception):
                                              &quot;&quot;&quot;Raised when optimistic concurrency check fails.&quot;&quot;&quot;
                                              pass


                                              # ============ Aggregates ============

                                              class Aggregate(ABC):
                                              &quot;&quot;&quot;
                                              Base class for domain aggregates.

                                              Aggregates produce events and rebuild state from events.
                                              &quot;&quot;&quot;

                                              def __init__(self):
                                              self.id: str = &quot;&quot;
                                              self.version: int = 0
                                              self._pending_events: List[Event] = []

                                              @abstractmethod
                                              def apply(self, event: Event) -&gt; None:
                                              &quot;&quot;&quot;Apply an event to update aggregate state.&quot;&quot;&quot;
                                              pass

                                              def load_from_events(self, events: List[Event]) -&gt; None:
                                              &quot;&quot;&quot;Reconstruct aggregate state by replaying events.&quot;&quot;&quot;
                                              for event in events:
                                              self.apply(event)
                                              self.version = event.version

                                              def add_event(self, event_type: str, data: dict) -&gt; None:
                                              &quot;&quot;&quot;Record a new event (to be persisted).&quot;&quot;&quot;
                                              event = Event(
                                              aggregate_type=self.__class__.__name__,
                                              event_type=event_type,
                                              data=data,
                                              version=self.version + len(self._pending_events) + 1
                                              )
                                              self._pending_events.append(event)
                                              self.apply(event)

                                              def get_pending_events(self) -&gt; List[Event]:
                                              return self._pending_events.copy()

                                              def clear_pending_events(self) -&gt; None:
                                              self._pending_events.clear()


                                              class BankAccount(Aggregate):
                                              &quot;&quot;&quot;
                                              Example aggregate: A bank account with event-sourced state.
                                              &quot;&quot;&quot;

                                              def __init__(self):
                                              super().__init__()
                                              self.owner: str = &quot;&quot;
                                              self.balance: float = 0.0
                                              self.is_closed: bool = False
                                              self.transaction_count: int = 0

                                              def apply(self, event: Event) -&gt; None:
                                              &quot;&quot;&quot;Apply event to update account state.&quot;&quot;&quot;
                                              if event.event_type == &quot;AccountOpened&quot;:
                                              self.id = event.aggregate_id or event.data.get(&quot;account_id&quot;, &quot;&quot;)
                                              self.owner = event.data[&quot;owner&quot;]
                                              self.balance = event.data.get(&quot;initial_balance&quot;, 0.0)

                                              elif event.event_type == &quot;MoneyDeposited&quot;:
                                              self.balance += event.data[&quot;amount&quot;]
                                              self.transaction_count += 1

                                              elif event.event_type == &quot;MoneyWithdrawn&quot;:
                                              self.balance -= event.data[&quot;amount&quot;]
                                              self.transaction_count += 1

                                              elif event.event_type == &quot;AccountClosed&quot;:
                                              self.is_closed = True

                                              # Command handlers

                                              @classmethod
                                              def open(cls, account_id: str, owner: str,
                                              initial_balance: float = 0.0) -&gt; &quot;BankAccount&quot;:
                                              &quot;&quot;&quot;Command: Open a new account.&quot;&quot;&quot;
                                              account = cls()
                                              account.id = account_id
                                              account.add_event(&quot;AccountOpened&quot;, {
                                              &quot;account_id&quot;: account_id,
                                              &quot;owner&quot;: owner,
                                              &quot;initial_balance&quot;: initial_balance
                                              })
                                              return account

                                              def deposit(self, amount: float, description: str = &quot;&quot;) -&gt; None:
                                              &quot;&quot;&quot;Command: Deposit money into account.&quot;&quot;&quot;
                                              if self.is_closed:
                                              raise InvalidOperationError(&quot;Cannot deposit to closed account&quot;)
                                              if amount &lt;= 0:
                                              raise InvalidOperationError(&quot;Deposit amount must be positive&quot;)

                                              self.add_event(&quot;MoneyDeposited&quot;, {
                                              &quot;amount&quot;: amount,
                                              &quot;description&quot;: description
                                              })

                                              def withdraw(self, amount: float, description: str = &quot;&quot;) -&gt; None:
                                              &quot;&quot;&quot;Command: Withdraw money from account.&quot;&quot;&quot;
                                              if self.is_closed:
                                              raise InvalidOperationError(&quot;Cannot withdraw from closed account&quot;)
                                              if amount &lt;= 0:
                                              raise InvalidOperationError(&quot;Withdrawal amount must be positive&quot;)
                                              if amount &gt; self.balance:
                                              raise InvalidOperationError(
                                              f&quot;Insufficient funds. Balance: {self.balance}, &quot;
                                              f&quot;Requested: {amount}&quot;
                                              )

                                              self.add_event(&quot;MoneyWithdrawn&quot;, {
                                              &quot;amount&quot;: amount,
                                              &quot;description&quot;: description
                                              })

                                              def close(self) -&gt; None:
                                              &quot;&quot;&quot;Command: Close the account.&quot;&quot;&quot;
                                              if self.is_closed:
                                              raise InvalidOperationError(&quot;Account is already closed&quot;)
                                              if self.balance != 0:
                                              raise InvalidOperationError(
                                              &quot;Cannot close account with non-zero balance&quot;
                                              )

                                              self.add_event(&quot;AccountClosed&quot;, {})


                                              class InvalidOperationError(Exception):
                                              &quot;&quot;&quot;Raised when a command violates business rules.&quot;&quot;&quot;
                                              pass


                                              # ============ Repository ============

                                              class Repository:
                                              &quot;&quot;&quot;
                                              Repository pattern for loading and saving aggregates.
                                              &quot;&quot;&quot;

                                              def __init__(self, event_store: EventStore, aggregate_class: type):
                                              self.event_store = event_store
                                              self.aggregate_class = aggregate_class

                                              def get(self, aggregate_id: str) -&gt; Optional[Aggregate]:
                                              &quot;&quot;&quot;Load an aggregate by replaying its events.&quot;&quot;&quot;
                                              events = self.event_store.get_events(aggregate_id)

                                              if not events:
                                              return None

                                              aggregate = self.aggregate_class()
                                              aggregate.load_from_events(events)
                                              return aggregate

                                              def save(self, aggregate: Aggregate) -&gt; None:
                                              &quot;&quot;&quot;Persist pending events with optimistic concurrency.&quot;&quot;&quot;
                                              pending = aggregate.get_pending_events()

                                              if not pending:
                                              return

                                              expected_version = aggregate.version - len(pending)
                                              self.event_store.append(aggregate.id, pending, expected_version)
                                              aggregate.clear_pending_events()


                                              # ============ Projections ============

                                              class Projection(ABC):
                                              &quot;&quot;&quot;
                                              Base class for read model projections.

                                              Projections build queryable views from events.
                                              &quot;&quot;&quot;

                                              @abstractmethod
                                              def handle(self, event: Event) -&gt; None:
                                              &quot;&quot;&quot;Process an event to update the projection.&quot;&quot;&quot;
                                              pass


                                              class AccountBalanceProjection(Projection):
                                              &quot;&quot;&quot;Simple projection: account_id -&gt; balance.&quot;&quot;&quot;

                                              def __init__(self):
                                              self.balances: Dict[str, float] = {}

                                              def handle(self, event: Event) -&gt; None:
                                              if event.event_type == &quot;AccountOpened&quot;:
                                              self.balances[event.aggregate_id] = event.data.get(
                                              &quot;initial_balance&quot;, 0.0
                                              )
                                              elif event.event_type == &quot;MoneyDeposited&quot;:
                                              self.balances[event.aggregate_id] += event.data[&quot;amount&quot;]
                                              elif event.event_type == &quot;MoneyWithdrawn&quot;:
                                              self.balances[event.aggregate_id] -= event.data[&quot;amount&quot;]
                                              elif event.event_type == &quot;AccountClosed&quot;:
                                              del self.balances[event.aggregate_id]

                                              def get_balance(self, account_id: str) -&gt; Optional[float]:
                                              return self.balances.get(account_id)


                                              class AccountSummaryProjection(Projection):
                                              &quot;&quot;&quot;Rich projection with multiple fields per account.&quot;&quot;&quot;

                                              def __init__(self):
                                              self.accounts: Dict[str, dict] = {}

                                              def handle(self, event: Event) -&gt; None:
                                              if event.event_type == &quot;AccountOpened&quot;:
                                              self.accounts[event.aggregate_id] = {
                                              &quot;owner&quot;: event.data[&quot;owner&quot;],
                                              &quot;balance&quot;: event.data.get(&quot;initial_balance&quot;, 0.0),
                                              &quot;transaction_count&quot;: 0,
                                              &quot;opened_at&quot;: event.timestamp,
                                              &quot;last_activity&quot;: event.timestamp,
                                              &quot;status&quot;: &quot;active&quot;
                                              }

                                              elif event.event_type in [&quot;MoneyDeposited&quot;, &quot;MoneyWithdrawn&quot;]:
                                              account = self.accounts.get(event.aggregate_id)
                                              if account:
                                              delta = event.data[&quot;amount&quot;]
                                              if event.event_type == &quot;MoneyWithdrawn&quot;:
                                              delta = -delta
                                              account[&quot;balance&quot;] += delta
                                              account[&quot;transaction_count&quot;] += 1
                                              account[&quot;last_activity&quot;] = event.timestamp

                                              elif event.event_type == &quot;AccountClosed&quot;:
                                              account = self.accounts.get(event.aggregate_id)
                                              if account:
                                              account[&quot;status&quot;] = &quot;closed&quot;
                                              account[&quot;closed_at&quot;] = event.timestamp

                                              def get_account(self, account_id: str) -&gt; Optional[dict]:
                                              return self.accounts.get(account_id)

                                              def get_active_accounts(self) -&gt; List[dict]:
                                              return [a for a in self.accounts.values() if a[&quot;status&quot;] == &quot;active&quot;]


                                              class ProjectionManager:
                                              &quot;&quot;&quot;Manages multiple projections and keeps them in sync.&quot;&quot;&quot;

                                              def __init__(self, event_store: EventStore):
                                              self.event_store = event_store
                                              self.projections: List[Projection] = []
                                              self.position: int = 0

                                              def register(self, projection: Projection) -&gt; None:
                                              &quot;&quot;&quot;Register a projection to receive events.&quot;&quot;&quot;
                                              self.projections.append(projection)

                                              def rebuild_all(self) -&gt; None:
                                              &quot;&quot;&quot;Rebuild all projections from scratch.&quot;&quot;&quot;
                                              self.position = 0
                                              for projection in self.projections:
                                              projection.__init__()  # Reset state
                                              self.catch_up()

                                              def catch_up(self) -&gt; None:
                                              &quot;&quot;&quot;Process any new events since last catch_up.&quot;&quot;&quot;
                                              events = self.event_store.get_all_events(self.position)

                                              for event in events:
                                              for projection in self.projections:
                                              projection.handle(event)
                                              self.position += 1


                                              # ============ Snapshots ============

                                              @dataclass
                                              class Snapshot:
                                              &quot;&quot;&quot;Snapshot of aggregate state for faster loading.&quot;&quot;&quot;
                                              aggregate_id: str
                                              aggregate_type: str
                                              version: int
                                              state: dict
                                              created_at: datetime = field(default_factory=datetime.utcnow)


                                              class SnapshotStore:
                                              &quot;&quot;&quot;Store for aggregate snapshots.&quot;&quot;&quot;

                                              def __init__(self, snapshot_frequency: int = 100):
                                              self.snapshots: Dict[str, Snapshot] = {}
                                              self.snapshot_frequency = snapshot_frequency

                                              def should_snapshot(self, version: int) -&gt; bool:
                                              return version % self.snapshot_frequency == 0

                                              def save(self, aggregate: Aggregate, state: dict) -&gt; None:
                                              &quot;&quot;&quot;Save a snapshot of the aggregate.&quot;&quot;&quot;
                                              self.snapshots[aggregate.id] = Snapshot(
                                              aggregate_id=aggregate.id,
                                              aggregate_type=aggregate.__class__.__name__,
                                              version=aggregate.version,
                                              state=state
                                              )

                                              def get(self, aggregate_id: str) -&gt; Optional[Snapshot]:
                                              &quot;&quot;&quot;Get the latest snapshot for an aggregate.&quot;&quot;&quot;
                                              return self.snapshots.get(aggregate_id)


                                              # ============ Usage Example ============

                                              def main():
                                              # Set up infrastructure
                                              event_store = EventStore()
                                              repo = Repository(event_store, BankAccount)

                                              # Set up projections
                                              balance_projection = AccountBalanceProjection()
                                              summary_projection = AccountSummaryProjection()
                                              projection_manager = ProjectionManager(event_store)
                                              projection_manager.register(balance_projection)
                                              projection_manager.register(summary_projection)

                                              # Subscribe projections to real-time updates
                                              event_store.subscribe(balance_projection.handle)
                                              event_store.subscribe(summary_projection.handle)

                                              # Create and use an account
                                              account = BankAccount.open(&quot;acc-001&quot;, &quot;Alice&quot;, initial_balance=100.0)
                                              repo.save(account)

                                              # Perform operations
                                              account.deposit(50.0, &quot;Paycheck&quot;)
                                              account.withdraw(30.0, &quot;Groceries&quot;)
                                              repo.save(account)

                                              # Query via projection (fast)
                                              balance = balance_projection.get_balance(&quot;acc-001&quot;)
                                              print(f&quot;Balance from projection: ${balance}&quot;)  # $120.0

                                              # Query via aggregate (replay events)
                                              loaded = repo.get(&quot;acc-001&quot;)
                                              print(f&quot;Balance from replay: ${loaded.balance}&quot;)  # $120.0

                                              # Get rich account data
                                              summary = summary_projection.get_account(&quot;acc-001&quot;)
                                              print(f&quot;Transaction count: {summary['transaction_count']}&quot;)  # 2


                                              if __name__ == &quot;__main__&quot;:
                                              main()
                                              ```
</code></pre>
<h3 id="event-schema-evolution">Event Schema Evolution</h3>
<pre><code>                                              ```python
                                              class EventUpcaster:
                                              &quot;&quot;&quot;
                                              Transform old event schemas to current version.

                                              Never modify stored events - upcast on read instead.
                                              &quot;&quot;&quot;

                                              def __init__(self):
                                              self.upcasters = {}

                                              def register(self, event_type: str, from_version: int,
                                              upcaster: Callable[[dict], dict]) -&gt; None:
                                              &quot;&quot;&quot;Register an upcaster for a specific event type and version.&quot;&quot;&quot;
                                              key = (event_type, from_version)
                                              self.upcasters[key] = upcaster

                                              def upcast(self, event: dict) -&gt; dict:
                                              &quot;&quot;&quot;Apply all necessary upcasters to bring event to current schema.&quot;&quot;&quot;
                                              event_type = event[&quot;event_type&quot;]
                                              version = event.get(&quot;schema_version&quot;, 1)

                                              while True:
                                              key = (event_type, version)
                                              if key not in self.upcasters:
                                              break

                                              event = self.upcasters[key](event)
                                              version += 1

                                              event[&quot;schema_version&quot;] = version
                                              return event


                                              # Example: Evolving AccountOpened event
                                              def upcast_account_opened_v1_to_v2(event: dict) -&gt; dict:
                                              &quot;&quot;&quot;V1 had 'name', V2 renamed to 'owner'.&quot;&quot;&quot;
                                              data = event[&quot;data&quot;].copy()
                                              data[&quot;owner&quot;] = data.pop(&quot;name&quot;, &quot;Unknown&quot;)
                                              return {**event, &quot;data&quot;: data}


                                              def upcast_account_opened_v2_to_v3(event: dict) -&gt; dict:
                                              &quot;&quot;&quot;V3 added 'currency' field with default.&quot;&quot;&quot;
                                              data = event[&quot;data&quot;].copy()
                                              data.setdefault(&quot;currency&quot;, &quot;USD&quot;)
                                              return {**event, &quot;data&quot;: data}


                                              # Usage
                                              upcaster = EventUpcaster()
                                              upcaster.register(&quot;AccountOpened&quot;, 1, upcast_account_opened_v1_to_v2)
                                              upcaster.register(&quot;AccountOpened&quot;, 2, upcast_account_opened_v2_to_v3)
                                              ```
</code></pre>
<hr />
<h2 id="3-level-recursive-interview-questions">3-Level Recursive Interview Questions</h2>
<div>
<h3>Deep Interview Q&A: Event Sourcing Mastery</h3>
<p>3-level recursive questions that demonstrate deep understanding</p>
</div>
<h3 id="q1-when-should-you-use-event-sourcing-vs-traditional-crud">Q1: When should you use Event Sourcing vs traditional CRUD?</h3>
<div>
<p><strong>Use Event Sourcing when:</strong></p>
<ul>
<li><span><strong>Complete audit trail</strong></span> is a requirement (finance, healthcare, legal)</li>
<li>You need <span><strong>temporal queries</strong></span> (&quot;what was the state on March 15?&quot;)<br />
- Complex domain with many state transitions<br />
- Multiple read models needed from the same data<br />
- Debugging production issues requires exact replay</li>
</ul>
<p><strong>Use CRUD when:</strong><br />
- Simple domain with straightforward state<br />
- No audit requirements<br />
- High-frequency updates to same records<br />
- Team unfamiliar with event sourcing patterns<br />
- Query patterns are simple and predictable</p>
<div>
<div>Follow-up L2: What are the hidden costs of Event Sourcing that teams often underestimate?</div>
<div>
<p><strong>Hidden costs include:</strong></p>
<ol>
<li><span><strong>Event schema evolution complexity</strong></span> - Every schema change requires upcasting logic</li>
<li><span><strong>Storage growth</strong></span> - Events never deleted, requires archival strategy</li>
<li><span><strong>Eventual consistency UX</strong></span> - UI must handle projection lag gracefully</li>
<li><span><strong>Testing complexity</strong></span> - Need to test event replay, projections, upcasters</li>
<li><span><strong>Operational overhead</strong></span> - Monitoring projection lag, snapshot health, replay times</li>
</ol>
<div>
<div>Follow-up L3: How would you migrate from CRUD to Event Sourcing for a live system?</div>
<div>
<p><strong>Migration Strategy (Strangler Fig Pattern):</strong></p>
<ol>
<li><strong>Dual-write phase</strong>: Write to both old DB and new event store</li>
<li><strong>Shadow projection</strong>: Build projections from events, compare with old DB</li>
<li><strong>Read migration</strong>: Gradually shift reads to projections</li>
<li><strong>Write migration</strong>: Route new writes only to event store</li>
<li><strong>Backfill</strong>: Generate synthetic events for historical data</li>
<li><strong>Decommission</strong>: Remove old CRUD system</li>
</ol>
<p><strong>Key considerations:</strong><br />
- Use <a href="/topic/system-design/cdc">[Change Data Capture]</a> to generate events from existing DB changes<br />
- Maintain idempotency keys to handle duplicate events<br />
- Plan for rollback if projections show data inconsistencies</p>
</div>
</div>
</div>
</div>
</div>
<hr />
<h3 id="q2-how-do-you-handle-large-event-streams-efficiently">Q2: How do you handle large event streams efficiently?</h3>
<div>
<p><strong>Answer:</strong></p>
<ol>
<li>
<p><strong>Snapshots</strong>: Periodically save aggregate state. Load from snapshot + replay only newer events.<br />
<code>python def load_with_snapshot(aggregate_id): snapshot = snapshot_store.get(aggregate_id) if snapshot: aggregate.restore_from_snapshot(snapshot) events = event_store.get_events(aggregate_id, from_version=snapshot.version) else: events = event_store.get_events(aggregate_id) aggregate.load_from_events(events) </code></p>
</li>
<li>
<p><strong>Event archiving</strong>: Move old events to cold storage, keep recent events hot</p>
</li>
<li>
<p><strong>Aggregate design</strong>: Keep aggregates small with bounded event streams</p>
</li>
<li>
<p><strong>Parallel projection rebuild</strong>: Partition events and process in parallel</p>
</li>
</ol>
<div>
<div>Follow-up L2: When should you take snapshots and what trade-offs are involved?</div>
<div>
<p><strong>Snapshot Frequency Trade-offs:</strong></p>
<table>
<thead>
<tr>
<th>Frequency</th>
<th>Storage Cost</th>
<th>Load Time</th>
<th>Complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td>Every 10 events</td>
<td>High</td>
<td>Fastest</td>
<td>Low</td>
</tr>
<tr>
<td>Every 100 events</td>
<td>Medium</td>
<td>Fast</td>
<td>Low</td>
</tr>
<tr>
<td>Every 1000 events</td>
<td>Low</td>
<td>Slower</td>
<td>Medium</td>
</tr>
<tr>
<td>Adaptive (time-based)</td>
<td>Variable</td>
<td>Predictable</td>
<td>High</td>
</tr>
</tbody>
</table>
<p><strong>When NOT to snapshot:</strong><br />
- Aggregates with few events (&lt; 50)<br />
- Events are small and replay is fast<br />
- Write-heavy with infrequent reads</p>
<p><strong>Snapshot strategies:</strong></p>
<ul>
<li><span><strong>Count-based</strong></span>: Every N events - simple and predictable</li>
<li><span><strong>Time-based</strong></span>: Every N hours - consistent timing</li>
<li><span><strong>Adaptive</strong></span>: When replay time exceeds threshold - efficient but complex</li>
</ul>
<div>
<div>Follow-up L3: How do you handle snapshot invalidation when aggregate logic changes?</div>
<div>
<p><strong>Snapshot Versioning Strategy:</strong></p>
<pre><code>                                                        ```python
                                                        @dataclass
                                                        class Snapshot:
                                                        aggregate_id: str
                                                        version: int
                                                        schema_version: int  # Snapshot schema version
                                                        state: dict

                                                        class SnapshotAwareRepository:
                                                        CURRENT_SCHEMA_VERSION = 3

                                                        def load(self, aggregate_id: str) -&gt; Aggregate:
                                                        snapshot = self.snapshot_store.get(aggregate_id)

                                                        if snapshot and snapshot.schema_version == self.CURRENT_SCHEMA_VERSION:
                                                        # Valid snapshot - use it
                                                        aggregate = self.restore_from_snapshot(snapshot)
                                                        events = self.event_store.get_events(
                                                        aggregate_id, from_version=snapshot.version
                                                        )
                                                        else:
                                                        # Stale snapshot - full replay
                                                        aggregate = self.aggregate_class()
                                                        events = self.event_store.get_events(aggregate_id)

                                                        aggregate.load_from_events(events)

                                                        # Optionally create new snapshot
                                                        if self.should_snapshot(aggregate):
                                                        self.create_snapshot(aggregate)

                                                        return aggregate
                                                        ```
</code></pre>
<p><strong>Handling logic changes:</strong></p>
<ol>
<li>Increment <code>CURRENT_SCHEMA_VERSION</code> when aggregate <code>apply()</code> logic changes</li>
<li>Background job rebuilds snapshots with new version</li>
<li>Use <a href="/topic/system-design/deployment-strategies">[Blue-Green Deployment]</a> to avoid serving stale reads during transition</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<hr />
<h3 id="q3-how-do-you-ensure-consistency-between-the-event-store-and-projections">Q3: How do you ensure consistency between the event store and projections?</h3>
<div>
<p><strong>Answer:</strong></p>
<p>Projections are <span><strong>eventually consistent</strong></span> by design. To manage this:</p>
<ol>
<li><strong>Idempotent handlers</strong>: Projections must handle duplicate events safely</li>
<li><strong>Position tracking</strong>: Store the last processed event position</li>
<li><strong>Replay capability</strong>: Rebuild projections from events at any time</li>
<li><strong>Ordering guarantees</strong>: Process events in order per aggregate</li>
</ol>
<p>For stronger consistency, use the <span><strong>Outbox Pattern</strong></span>:<br />
- Write events to database table in same transaction as projection update<br />
- Background process publishes events to message bus</p>
<div>
<div>Follow-up L2: How do you handle projection lag in user-facing applications?</div>
<div>
<p><strong>Strategies for handling eventual consistency in UX:</strong></p>
<ol>
<li>
<p><strong>Read-your-writes consistency</strong>: After command, poll projection until updated<br />
```python<br />
async def place_order_and_wait(order_data):<br />
event_version = await command_handler.place_order(order_data)</p>
<pre><code>                                               # Wait for projection to catch up
                                               while True:
                                               projection = await order_projection.get(order_data.id)
                                               if projection and projection.version &gt;= event_version:
                                               return projection
                                               await asyncio.sleep(0.1)
                                               ```
</code></pre>
</li>
<li>
<p><strong>Optimistic UI updates</strong>: Update UI immediately, sync later</p>
</li>
<li>
<p><strong>Version tokens</strong>: Return event version, client includes in subsequent reads</p>
</li>
<li>
<p><strong>Dedicated read-after-write projection</strong>: Synchronous projection for immediate consistency</p>
</li>
</ol>
<div>
<div>Follow-up L3: How do you design idempotent projection handlers for exactly-once semantics?</div>
<div>
<p><strong>Idempotent Projection Pattern:</strong></p>
<pre><code>                                                        ```python
                                                        class IdempotentProjection:
                                                        def __init__(self, db):
                                                        self.db = db

                                                        def handle(self, event: Event) -&gt; None:
                                                        # Check if event already processed
                                                        if self._is_processed(event.event_id):
                                                        return  # Skip duplicate

                                                        # Process event and mark as processed atomically
                                                        with self.db.transaction():
                                                        self._apply_event(event)
                                                        self._mark_processed(event.event_id, event.version)

                                                        def _is_processed(self, event_id: str) -&gt; bool:
                                                        return self.db.exists(
                                                        &quot;processed_events&quot;,
                                                        {&quot;event_id&quot;: event_id}
                                                        )

                                                        def _mark_processed(self, event_id: str, version: int) -&gt; None:
                                                        self.db.insert(&quot;processed_events&quot;, {
                                                        &quot;event_id&quot;: event_id,
                                                        &quot;version&quot;: version,
                                                        &quot;processed_at&quot;: datetime.utcnow()
                                                        })
                                                        ```
</code></pre>
<p><strong>Key techniques:</strong></p>
<ul>
<li>
<p><span><strong>Deduplication table</strong></span>: Track processed event IDs</p>
</li>
<li>
<p><span><strong>Idempotency keys</strong></span>: Use event_id as natural idempotency key</p>
</li>
<li>
<p><span><strong>Upsert operations</strong></span>: Use <code>INSERT ... ON CONFLICT UPDATE</code></p>
</li>
<li>
<p><span><strong>Version checks</strong></span>: Only apply if version &gt; current</p>
<p>See also: <a href="/topic/system-design/distributed-transactions">[Distributed Transactions]</a> for related patterns</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<hr />
<h3 id="q4-how-do-you-handle-event-schema-changes">Q4: How do you handle event schema changes?</h3>
<div>
<p><strong>Answer:</strong></p>
<p><strong>Golden Rule</strong>: <span>Never modify stored events</span>. Events are immutable facts.</p>
<p><strong>Strategies:</strong></p>
<ol>
<li><strong>Upcasting</strong>: Transform old events to new schema on read</li>
<li><strong>Event versioning</strong>: Include schema_version in events</li>
<li><strong>Copy-and-transform</strong>: Create new events from old (for major changes)</li>
<li><strong>Weak schema</strong>: Design events with optional fields</li>
</ol>
<p><strong>Example upcaster chain:</strong><br />
<code>V1: {name: &quot;Alice&quot;} -&gt; V2: {owner: &quot;Alice&quot;} -&gt; V3: {owner: &quot;Alice&quot;, currency: &quot;USD&quot;}</code></p>
<div>
<div>Follow-up L2: What happens when an upcaster has a bug that corrupts projected data?</div>
<div>
<p><strong>Recovery Strategy:</strong></p>
<ol>
<li><strong>Fix the upcaster</strong>: Correct the transformation logic</li>
<li><strong>Rebuild projections</strong>: Full replay from events with corrected upcaster</li>
<li><strong>No data loss</strong>: Original events unchanged, only projections affected</li>
</ol>
<p><strong>Prevention techniques:</strong><br />
- Unit test upcasters with sample events from each version<br />
- Keep old event samples in test fixtures<br />
- Integration test full replay path<br />
- Monitor projection checksums after deployments</p>
<pre><code>                                                    ```python
                                                    def test_upcaster_chain():
                                                    v1_event = {&quot;event_type&quot;: &quot;AccountOpened&quot;, &quot;data&quot;: {&quot;name&quot;: &quot;Alice&quot;}}

                                                    result = upcaster.upcast(v1_event)

                                                    assert result[&quot;data&quot;][&quot;owner&quot;] == &quot;Alice&quot;
                                                    assert result[&quot;data&quot;][&quot;currency&quot;] == &quot;USD&quot;
                                                    assert result[&quot;schema_version&quot;] == 3
                                                    ```
</code></pre>
<div>
<div>Follow-up L3: How do you handle breaking changes that can't be upcasted?</div>
<div>
<p><strong>Strategies for non-upcastable changes:</strong></p>
<ol>
<li>
<p><strong>Create new event type</strong>: <code>OrderPlacedV2</code> alongside <code>OrderPlacedV1</code><br />
- Projections handle both types<br />
- New code emits V2, old events remain V1</p>
</li>
<li>
<p><strong>Compensating events</strong>: Emit correction events<br />
```python<br />
# Original event (wrong)<br />
OrderPlaced {amount: 100}  # Should have been 110</p>
<pre><code>                                                   # Compensation event
                                                   OrderAmountCorrected {
                                                   original_event_id: &quot;evt-123&quot;,
                                                   old_amount: 100,
                                                   new_amount: 110,
                                                   reason: &quot;Pricing bug fix&quot;
                                                   }
                                                   ```
</code></pre>
</li>
<li>
<p><strong>Event store migration</strong> (last resort):<br />
- Create new event store with transformed events<br />
- Use <a href="/topic/system-design/deployment-strategies">[Blue-Green Deployment]</a> to switch<br />
- Keep old store for audit/legal requirements</p>
</li>
</ol>
<p><strong>When to use each:</strong><br />
- New event type: Semantic changes (new fields change meaning)<br />
- Compensating events: Data corrections, business adjustments<br />
- Migration: Fundamental structural changes, compliance requirements</p>
</div>
</div>
</div>
</div>
</div>
<hr />
<h3 id="q5-what-is-cqrs-and-how-does-it-relate-to-event-sourcing">Q5: What is CQRS and how does it relate to Event Sourcing?</h3>
<div>
<p><strong>Answer:</strong></p>
<p><span><strong>CQRS (Command Query Responsibility Segregation)</strong></span> separates read and write models:<br />
- <strong>Write side</strong>: Receives commands, produces events<br />
- <strong>Read side</strong>: Optimized projections for queries</p>
<p>Event Sourcing and CQRS are complementary:<br />
- Event Sourcing provides the write model (append-only event log)<br />
- CQRS provides multiple read models (projections built from events)</p>
<p><strong>Benefits together:</strong><br />
- Write model optimized for consistency (events)<br />
- Read models optimized for specific queries (denormalized views)<br />
- Can scale read and write sides independently</p>
<div>
<div>Follow-up L2: When would you use Event Sourcing without CQRS, or CQRS without Event Sourcing?</div>
<div>
<p><strong>Event Sourcing without CQRS:</strong><br />
- Single, simple read model sufficient<br />
- Audit trail is primary requirement, not query flexibility<br />
- Example: Compliance logging system</p>
<p><strong>CQRS without Event Sourcing:</strong><br />
- Need read/write separation for scaling<br />
- Traditional database on write side is sufficient<br />
- Example: E-commerce product catalog (read-heavy, simple writes)</p>
<pre><code>                                                    ```
                                                    CQRS without ES:
                                                    [Command] -&gt; [Write DB] -&gt; [Change Data Capture] -&gt; [Read DB]
                                                    |                                      |
                                                    Normalized                           Denormalized
                                                    ```
</code></pre>
<div>
<div>Follow-up L3: How do you handle cross-aggregate queries in an Event Sourced CQRS system?</div>
<div>
<p><strong>Cross-Aggregate Query Strategies:</strong></p>
<ol>
<li>
<p><strong>Denormalized projection</strong>: Build read model spanning aggregates<br />
```python<br />
class CustomerOrdersProjection:<br />
&quot;&quot;&quot;Combines Customer and Order aggregate data.&quot;&quot;&quot;</p>
<pre><code>                                                   def handle(self, event: Event):
                                                   if event.event_type == &quot;CustomerCreated&quot;:
                                                   self.data[event.aggregate_id] = {
                                                   &quot;customer_name&quot;: event.data[&quot;name&quot;],
                                                   &quot;orders&quot;: []
                                                   }
                                                   elif event.event_type == &quot;OrderPlaced&quot;:
                                                   customer_id = event.data[&quot;customer_id&quot;]
                                                   self.data[customer_id][&quot;orders&quot;].append({
                                                   &quot;order_id&quot;: event.aggregate_id,
                                                   &quot;total&quot;: event.data[&quot;total&quot;]
                                                   })
                                                   ```
</code></pre>
</li>
<li>
<p><strong>Composite ID projection</strong>: Key by combination of aggregate IDs</p>
</li>
<li>
<p><strong>GraphQL/API composition</strong>: Combine projections at API layer</p>
</li>
<li>
<p><strong>Event-carried state transfer</strong>: Include related data in events<br />
<code>python OrderPlaced { order_id: &quot;ord-123&quot;, customer_id: &quot;cust-456&quot;, customer_name: &quot;Alice&quot;,  # Denormalized for projection total: 150.00 } </code></p>
</li>
</ol>
<p><strong>Trade-offs:</strong><br />
- Denormalized projections: Faster queries, more storage, eventual consistency<br />
- API composition: Flexible, slower, consistent at query time</p>
<p>See <a href="/topic/system-design/api-gateway">[API Gateway]</a> for aggregation patterns</p>
</div>
</div>
</div>
</div>
</div>
<hr />
<h3 id="q6-how-do-you-implement-replay-for-debugging-production-issues">Q6: How do you implement replay for debugging production issues?</h3>
<div>
<p><strong>Answer:</strong></p>
<p><strong>Production Replay Strategy:</strong></p>
<ol>
<li>
<p><strong>Copy events</strong> to isolated environment</p>
</li>
<li>
<p><strong>Replay with instrumentation</strong>: Add logging/breakpoints</p>
</li>
<li>
<p><strong>Time-travel debugging</strong>: Stop at specific event, inspect state</p>
</li>
<li>
<p><strong>Hypothesis testing</strong>: Modify event data to test fixes</p>
<pre><code>                                           ```python
                                           class DebuggingReplayer:
                                           def replay_until(self, aggregate_id: str, target_version: int,
                                           breakpoint_fn: Callable[[Event, Aggregate], bool] = None):
                                           aggregate = self.aggregate_class()
                                           events = self.event_store.get_events(aggregate_id)

                                           for event in events:
                                           if event.version &gt; target_version:
                                           break

                                           print(f&quot;Applying: {event.event_type} v{event.version}&quot;)
                                           aggregate.apply(event)

                                           if breakpoint_fn and breakpoint_fn(event, aggregate):
                                           print(f&quot;Breakpoint hit at v{event.version}&quot;)
                                           import pdb; pdb.set_trace()

                                           return aggregate
                                           ```
</code></pre>
</li>
</ol>
<div>
<div>Follow-up L2: How do you handle side effects during replay (sending emails, API calls)?</div>
<div>
<p><strong>Side Effect Management:</strong></p>
<ol>
<li>
<p><strong>Separate side effects from state changes</strong>:<br />
```python<br />
class OrderAggregate:<br />
def place_order(self, data):<br />
# State change - replayed<br />
self.add_event(&quot;OrderPlaced&quot;, data)</p>
<pre><code>                                               # Side effects handled separately by process manager
                                               class OrderProcessManager:
                                               def handle(self, event: Event):
                                               if event.event_type == &quot;OrderPlaced&quot;:
                                               if not self.is_replay_mode:
                                               self.email_service.send_confirmation(event.data)
                                               ```
</code></pre>
</li>
<li>
<p><strong>Event handlers track execution</strong>:<br />
<code>python class IdempotentEmailHandler: def handle(self, event: Event): if self.already_sent(event.event_id): return  # Skip during replay self.send_email(event) self.mark_sent(event.event_id) </code></p>
</li>
<li>
<p><strong>Replay mode flag</strong>: Disable side effects during rebuild</p>
</li>
</ol>
<div>
<div>Follow-up L3: How do you handle time-dependent logic during replay?</div>
<div>
<p><strong>Time-Dependent Replay Strategies:</strong></p>
<p><strong>Problem:</strong> Code like <code>if datetime.now() &gt; event.timestamp + timedelta(days=30)</code> behaves differently during replay.</p>
<p><strong>Solutions:</strong></p>
<ol>
<li>
<p><strong>Use event timestamp, not system time</strong>:<br />
<code>python class OrderAggregate: def apply(self, event: Event): if event.event_type == &quot;OrderPlaced&quot;: # Use event time, not now() self.placed_at = event.timestamp self.expires_at = event.timestamp + timedelta(days=30) </code></p>
</li>
<li>
<p><strong>Clock abstraction</strong>:<br />
```python<br />
class EventSourcedAggregate:<br />
def <strong>init</strong>(self, clock: Callable[[], datetime] = datetime.utcnow):<br />
self.clock = clock</p>
<pre><code>                                                   def current_time(self) -&gt; datetime:
                                                   return self.clock()

                                                   # During replay, inject event timestamp as clock
                                                   def replay_clock(event: Event):
                                                   return lambda: event.timestamp
                                                   ```
</code></pre>
</li>
<li>
<p><strong>Time events</strong>: Model time passage as events<br />
<code>python # Instead of checking &quot;now &gt; 30 days after order&quot; # Emit explicit event when expiration occurs DailyExpirationCheck {} OrderExpired {order_id: &quot;123&quot;, reason: &quot;30 day limit&quot;} </code></p>
</li>
</ol>
<p>See <a href="/topic/design-patterns/saga">[Saga Pattern]</a> for handling long-running processes</p>
</div>
</div>
</div>
</div>
</div>
<hr />
<h3 id="q7-what-are-the-best-practices-for-event-design">Q7: What are the best practices for event design?</h3>
<div>
<p><strong>Answer:</strong></p>
<p><strong>Event Design Principles:</strong></p>
<ol>
<li>
<p><span><strong>Past tense naming</strong></span>: Events are facts that happened<br />
- Good: <code>OrderPlaced</code>, <code>PaymentReceived</code><br />
- Bad: <code>PlaceOrder</code>, <code>ProcessPayment</code></p>
</li>
<li>
<p><span><strong>Self-contained</strong></span>: Include all data needed to understand the change<br />
```python<br />
# Good - self-contained<br />
OrderPlaced {<br />
order_id: &quot;123&quot;,<br />
customer_id: &quot;456&quot;,<br />
items: [{sku: &quot;ABC&quot;, qty: 2, price: 25.00}],<br />
total: 50.00<br />
}</p>
<pre><code>                                             # Bad - requires lookup
                                             OrderPlaced {order_id: &quot;123&quot;}  # Missing context
                                             ```
</code></pre>
</li>
<li>
<p><span><strong>Domain language</strong></span>: Use business terms, not technical<br />
- Good: <code>SubscriptionRenewed</code><br />
- Bad: <code>SubscriptionRowUpdated</code></p>
</li>
<li>
<p><span><strong>Granular events</strong></span>: One event per business fact<br />
- Good: <code>ItemAddedToCart</code>, <code>ItemRemovedFromCart</code><br />
- Bad: <code>CartUpdated</code> (loses specific intent)</p>
</li>
</ol>
<div>
<div>Follow-up L2: How much data should an event contain - minimal or denormalized?</div>
<div>
<p><strong>The Tension:</strong></p>
<table>
<thead>
<tr>
<th>Minimal Events</th>
<th>Denormalized Events</th>
</tr>
</thead>
<tbody>
<tr>
<td>Smaller storage</td>
<td>Larger storage</td>
</tr>
<tr>
<td>Projections need lookups</td>
<td>Self-contained for projections</td>
</tr>
<tr>
<td>Schema changes easier</td>
<td>More data to upcast</td>
</tr>
<tr>
<td>Consistent with source</td>
<td>May drift from source</td>
</tr>
</tbody>
</table>
<p><strong>Recommended approach</strong>: <span><strong>Event-Carried State Transfer</strong></span></p>
<p>Include data that:</p>
<ol>
<li>
<p>Is needed by multiple projections</p>
</li>
<li>
<p>Won't change after event (immutable references)</p>
</li>
<li>
<p>Would require expensive lookups</p>
<pre><code>                                               ```python
                                               # Good balance
                                               OrderPlaced {
                                               order_id: &quot;123&quot;,
                                               customer_id: &quot;456&quot;,
                                               customer_name: &quot;Alice&quot;,  # Denormalized - needed for display
                                               items: [...],
                                               total: 50.00,
                                               currency: &quot;USD&quot;
                                               }
                                               ```
</code></pre>
</li>
</ol>
<div>
<div>Follow-up L3: How do you handle large payloads like file uploads in events?</div>
<div>
<p><strong>Large Payload Strategies:</strong></p>
<ol>
<li>
<p><strong>Reference pattern</strong>: Store payload externally, event contains reference<br />
<code>python DocumentUploaded { document_id: &quot;doc-123&quot;, storage_location: &quot;s3://bucket/doc-123.pdf&quot;,  # Reference content_hash: &quot;sha256:abc...&quot;, size_bytes: 5242880, metadata: {filename: &quot;contract.pdf&quot;, mime: &quot;application/pdf&quot;} } </code></p>
</li>
<li>
<p><strong>Claim check pattern</strong>: Similar but with expiring claim<br />
<code>python LargeOrderReceived { order_id: &quot;123&quot;, claim_check: &quot;claims/order-123&quot;,  # Temporary storage claim_expires_at: &quot;2024-01-15T00:00:00Z&quot; } </code></p>
</li>
<li>
<p><strong>Event chunking</strong> (for very large events):<br />
<code>python DataImportStarted {import_id: &quot;imp-1&quot;, total_chunks: 100} DataChunkReceived {import_id: &quot;imp-1&quot;, chunk: 1, data: [...]} DataChunkReceived {import_id: &quot;imp-1&quot;, chunk: 2, data: [...]} DataImportCompleted {import_id: &quot;imp-1&quot;} </code></p>
</li>
</ol>
<p><strong>Storage considerations:</strong><br />
- Event store for metadata and references<br />
- Blob storage (S3, GCS) for large payloads<br />
- Content-addressable storage for deduplication</p>
<p>See <a href="/topic/system-design/object-storage">[Object Storage]</a> for blob storage patterns</p>
</div>
</div>
</div>
</div>
</div>
<hr />
<h3 id="q8-how-do-you-test-event-sourced-systems">Q8: How do you test event-sourced systems?</h3>
<div>
<p><strong>Answer:</strong></p>
<p><strong>Testing Layers:</strong></p>
<ol>
<li>
<p><span><strong>Aggregate unit tests</strong></span>: Given events, when command, then events<br />
```python<br />
def test_withdraw_from_account():<br />
# Given<br />
account = BankAccount()<br />
account.load_from_events([<br />
Event(event_type=&quot;AccountOpened&quot;, data={&quot;owner&quot;: &quot;Alice&quot;, &quot;initial_balance&quot;: 100})<br />
])</p>
<pre><code>                                             # When
                                             account.withdraw(30)

                                             # Then
                                             pending = account.get_pending_events()
                                             assert len(pending) == 1
                                             assert pending[0].event_type == &quot;MoneyWithdrawn&quot;
                                             assert pending[0].data[&quot;amount&quot;] == 30
                                             ```
</code></pre>
</li>
<li>
<p><span><strong>Projection tests</strong></span>: Given events, projection state matches</p>
</li>
<li>
<p><span><strong>Integration tests</strong></span>: Full command -&gt; event store -&gt; projection flow</p>
</li>
<li>
<p><span><strong>Upcaster tests</strong></span>: Old events transform correctly</p>
</li>
</ol>
<div>
<div>Follow-up L2: How do you write integration tests that verify eventual consistency?</div>
<div>
<p><strong>Eventual Consistency Testing:</strong></p>
<pre><code>                                                    ```python
                                                    @pytest.fixture
                                                    def event_sourced_system():
                                                    event_store = InMemoryEventStore()
                                                    projection = OrderProjection()
                                                    event_store.subscribe(projection.handle)
                                                    return event_store, projection

                                                    def test_projection_eventually_consistent(event_sourced_system):
                                                    event_store, projection = event_sourced_system

                                                    # When: Place order via command
                                                    order = Order.create(&quot;order-1&quot;, customer_id=&quot;cust-1&quot;, total=100)
                                                    event_store.append(&quot;order-1&quot;, order.pending_events, expected_version=0)

                                                    # Then: Projection reflects change (sync subscription)
                                                    result = projection.get_order(&quot;order-1&quot;)
                                                    assert result[&quot;total&quot;] == 100

                                                    def test_projection_handles_out_of_order_events(event_sourced_system):
                                                    &quot;&quot;&quot;Verify projection handles events arriving out of order.&quot;&quot;&quot;
                                                    event_store, projection = event_sourced_system

                                                    # Simulate out-of-order delivery
                                                    events = [
                                                    Event(event_type=&quot;ItemAdded&quot;, version=2),
                                                    Event(event_type=&quot;OrderCreated&quot;, version=1),  # Arrives second
                                                    ]

                                                    for event in events:
                                                    projection.handle(event)

                                                    # Projection should buffer/reorder correctly
                                                    assert projection.get_order(&quot;order-1&quot;) is not None
                                                    ```
</code></pre>
<div>
<div>Follow-up L3: How do you implement property-based testing for event-sourced aggregates?</div>
<div>
<p><strong>Property-Based Testing with Hypothesis:</strong></p>
<pre><code>                                                        ```python
                                                        from hypothesis import given, strategies as st
                                                        from hypothesis.stateful import RuleBasedStateMachine, rule

                                                        class BankAccountStateMachine(RuleBasedStateMachine):
                                                        &quot;&quot;&quot;Property: Replaying events always produces same state.&quot;&quot;&quot;

                                                        def __init__(self):
                                                        super().__init__()
                                                        self.account = BankAccount.open(&quot;test&quot;, &quot;Alice&quot;, initial_balance=1000)
                                                        self.event_store = InMemoryEventStore()

                                                        @rule(amount=st.floats(min_value=0.01, max_value=100))
                                                        def deposit(self, amount):
                                                        self.account.deposit(amount)
                                                        self._verify_replay_consistency()

                                                        @rule(amount=st.floats(min_value=0.01, max_value=100))
                                                        def withdraw(self, amount):
                                                        if amount &lt;= self.account.balance:
                                                        self.account.withdraw(amount)
                                                        self._verify_replay_consistency()

                                                        def _verify_replay_consistency(self):
                                                        # Save events
                                                        events = self.account.get_pending_events()
                                                        self.event_store.append(self.account.id, events,
                                                        expected_version=self.account.version - len(events))
                                                        self.account.clear_pending_events()

                                                        # Replay and compare
                                                        replayed = BankAccount()
                                                        replayed.load_from_events(
                                                        self.event_store.get_events(self.account.id)
                                                        )

                                                        assert replayed.balance == self.account.balance
                                                        assert replayed.version == self.account.version

                                                        TestBankAccount = BankAccountStateMachine.TestCase
                                                        ```
</code></pre>
<p><strong>Properties to test:</strong><br />
- Replay produces identical state<br />
- Events are idempotent when applied<br />
- Concurrent commands with same expected_version fail<br />
- Upcasters are reversible (can downcast for testing)</p>
</div>
</div>
</div>
</div>
</div>
<hr />
<h2 id="common-mistakes">Common Mistakes</h2>
<div>
<h4>Event Sourcing Anti-Patterns</h4>
<div>
<div>
<div>Storing CRUD operations as events</div>
<div>Events should represent domain facts ("OrderPlaced"), not database operations ("OrderRowInserted"). Capture business intent, not technical actions.</div>
</div>
<div>
<div>Large aggregates with too many events</div>
<div>If an aggregate has thousands of events, loading becomes slow. Use snapshots, or redesign aggregates to be smaller and more focused.</div>
</div>
<div>
<div>Modifying stored events</div>
<div>Events are immutable historical facts. Use upcasting to transform old schemas on read, never modify the stored event data.</div>
</div>
<div>
<div>Non-idempotent projection handlers</div>
<div>Projections may receive duplicate events during replays or failures. Handlers must produce the same result when applied multiple times.</div>
</div>
<div>
<div>Querying the event store directly</div>
<div>Event stores are optimized for append and replay, not ad-hoc queries. Build projections for query needs instead of scanning events.</div>
</div>
<div>
<div>Ignoring eventual consistency in UX</div>
<div>Projections lag behind writes. Design UI to handle this - show optimistic updates, indicate "syncing" state, or use read-your-writes consistency.</div>
</div>
<div>
<div>Coupling aggregates through events</div>
<div>One aggregate should not directly consume another's events. Use sagas or process managers to coordinate across boundaries. See [[Saga Pattern]](/topic/design-patterns/saga).</div>
</div>
<div>
<div>Missing correlation/causation IDs</div>
<div>Without tracking which command caused which events, debugging distributed flows becomes nearly impossible. Always include correlation_id in event metadata.</div>
</div>
</div>
</div>
<hr />
<h2 id="event-store-technologies-comparison">Event Store Technologies Comparison</h2>
<div>
<h4>Choosing an Event Store</h4>
<div>
<table>
  <thead>
<tr>
<th>Technology</th>
<th>Best For</th>
<th>Strengths</th>
<th>Limitations</th>
</tr>
  </thead>
  <tbody>
<tr>
<td>EventStoreDB</td>
<td>Purpose-built ES</td>
<td>Projections built-in, optimized for ES patterns</td>
<td>Specialized knowledge required</td>
</tr>
<tr>
<td>PostgreSQL</td>
<td>Teams with SQL expertise</td>
<td>Familiar, transactional, JSONB support</td>
<td>Manual optimistic concurrency</td>
</tr>
<tr>
<td>Apache Kafka</td>
<td>High-throughput streaming</td>
<td>Scalable, built-in pub/sub</td>
<td>No per-aggregate ordering guarantee</td>
</tr>
<tr>
<td>DynamoDB</td>
<td>Serverless, AWS ecosystem</td>
<td>Managed, scalable, streams for projections</td>
<td>25 item transaction limit</td>
</tr>
<tr>
<td>Marten (.NET)</td>
<td>.NET applications</td>
<td>PostgreSQL-backed, strong tooling</td>
<td>.NET specific</td>
</tr>
  </tbody>
</table>
</div>
</div>
<hr />
<h2 id="quick-reference-card">Quick Reference Card</h2>
<div>
<h4>Event Sourcing Cheat Sheet</h4>
<div>
<div>
<div>Event Design Principles</div>
<div>
<div>Events are past tense facts (OrderPlaced)</div>
<div>Include all data needed to understand the change</div>
<div>Events are immutable - never modify</div>
<div>Use domain language, not technical terms</div>
</div>
</div>
<div>
<div>Event Store Technologies</div>
<div>
<div><strong>EventStoreDB:</strong> Purpose-built for ES</div>
<div><strong>PostgreSQL:</strong> With append-only table</div>
<div><strong>Kafka:</strong> As an event log</div>
<div><strong>DynamoDB:</strong> With version attribute</div>
</div>
</div>
<div>
<div>Performance Strategies</div>
<div>
<div>Snapshots every N events (50-100)</div>
<div>Keep aggregates small</div>
<div>Parallel projection rebuilds</div>
<div>Archive old events to cold storage</div>
</div>
</div>
<div>
<div>Consistency Patterns</div>
<div>
<div><strong>Optimistic concurrency:</strong> Version checks</div>
<div><strong>Projections:</strong> Eventually consistent</div>
<div><strong>Outbox pattern:</strong> Reliable publishing</div>
<div><strong>Idempotency:</strong> Safe replay</div>
</div>
</div>
</div>
</div>
<hr />
<h2 id="related-topics">Related Topics</h2>
<pre><code>                                              - [[CQRS Pattern]](/topic/design-patterns/cqrs) - Separating read and write models
                                              - [[Message Queues]](/topic/system-design/message-queues) - Publishing events to subscribers
                                              - [[Distributed Locking]](/topic/system-design/distributed-locking) - Concurrency control
                                              - [[Saga Pattern]](/topic/design-patterns/saga) - Coordinating distributed transactions
                                              - [[API Gateway]](/topic/system-design/api-gateway) - Aggregating read models
                                              - [[Change Data Capture]](/topic/system-design/cdc) - Generating events from databases
                                              - [[Microservices Event Strategies]](/topic/microservices/event-strategies) - Event-driven architecture patterns
</code></pre>
