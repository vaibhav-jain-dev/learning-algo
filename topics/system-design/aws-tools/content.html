<h1 id="aws-tools-for-system-design">AWS Tools for System Design</h1>
<h2 id="overview">Overview</h2>
<p>AWS provides a comprehensive suite of managed services that solve common distributed systems problems. Understanding these tools deeply is essential for system design interviews and real-world architecture decisions.</p>
<div>
<h4>Core AWS Services for Distributed Systems</h4>
<div>
<div>
<div>Messaging</div>
<div>SNS, SQS, EventBridge</div>
</div>
<div>
<div>Compute</div>
<div>Lambda, ECS, EKS, EC2</div>
</div>
<div>
<div>Storage</div>
<div>S3, DynamoDB, RDS, ElastiCache</div>
</div>
</div>
</div>
<hr />
<h2 id="amazon-sqs-simple-queue-service">Amazon SQS (Simple Queue Service)</h2>
<h3 id="what-is-sqs">What is SQS?</h3>
<p><span>SQS is a fully managed message queuing service that enables decoupling of distributed systems</span>. It acts as a buffer between producers and consumers, allowing them to operate independently and at different rates.</p>
<div>
<h4>SQS Architecture Flow</h4>
<div>
<div>
<div>Producer</div>
<div>Sends messages</div>
</div>
<div>
<div>→</div>
</div>
<div>
<div>SQS Queue</div>
<div>Stores & delivers</div>
</div>
<div>
<div>→</div>
</div>
<div>
<div>Consumer</div>
<div>Processes messages</div>
</div>
</div>
</div>
<h3 id="sqs-queue-types">SQS Queue Types</h3>
<div>
<h4>Standard vs FIFO Queues</h4>
<div>
<div>
<div>Standard Queue</div>
<div>
<div><strong>Throughput:</strong> Unlimited</div>
<div><strong>Ordering:</strong> Best-effort (may be out of order)</div>
<div><strong>Delivery:</strong> At-least-once (may have duplicates)</div>
<div><strong>Use Case:</strong> High throughput, order not critical</div>
</div>
</div>
<div>
<div>FIFO Queue</div>
<div>
<div><strong>Throughput:</strong> 3,000 msg/sec (with batching)</div>
<div><strong>Ordering:</strong> Strictly preserved</div>
<div><strong>Delivery:</strong> Exactly-once processing</div>
<div><strong>Use Case:</strong> Financial transactions, order processing</div>
</div>
</div>
</div>
</div>
<h3 id="how-sqs-works-internally">How SQS Works Internally</h3>
<div>
<h4>Message Lifecycle</h4>
<div>
<div>
<div>1</div>
<div>
<div>Send Message</div>
<div>Producer sends message → SQS stores across multiple AZs for durability</div>
</div>
</div>
<div>
<div>2</div>
<div>
<div>Receive Message</div>
<div>Consumer polls queue → Message becomes "in-flight" (invisible to others)</div>
</div>
</div>
<div>
<div>3</div>
<div>
<div>Visibility Timeout</div>
<div>Message hidden for configured time (default 30s) → Prevents duplicate processing</div>
</div>
</div>
<div>
<div>4</div>
<div>
<div>Delete Message</div>
<div>After successful processing → Consumer explicitly deletes message from queue</div>
</div>
</div>
</div>
</div>
<h3 id="key-sqs-concepts">Key SQS Concepts</h3>
<h4 id="visibility-timeout">Visibility Timeout</h4>
<p><span>Critical assumption: Visibility timeout must be longer than your processing time</span>. If processing takes longer than visibility timeout, another consumer may receive the same message.</p>
<pre><code class="language-python">import boto3
import json

sqs = boto3.client('sqs')
queue_url = 'https://sqs.us-east-1.amazonaws.com/123456789/my-queue'

# Send message
response = sqs.send_message(
    QueueUrl=queue_url,
    MessageBody=json.dumps({'order_id': '12345', 'action': 'process'}),
    DelaySeconds=0,  # Optional delay before message becomes visible
    MessageAttributes={
        'Priority': {
            'DataType': 'String',
            'StringValue': 'high'
        }
    }
)
print(f&quot;Message ID: {response['MessageId']}&quot;)

# Receive message
response = sqs.receive_message(
    QueueUrl=queue_url,
    MaxNumberOfMessages=10,  # Max 10 per call
    WaitTimeSeconds=20,      # Long polling (reduces API calls)
    VisibilityTimeout=60,    # 60 seconds to process
    MessageAttributeNames=['All']
)

for message in response.get('Messages', []):
    try:
        body = json.loads(message['Body'])
        # Process the message
        process_order(body['order_id'])

        # Delete after successful processing
        sqs.delete_message(
            QueueUrl=queue_url,
            ReceiptHandle=message['ReceiptHandle']
        )
    except Exception as e:
        # Message will become visible again after timeout
        print(f&quot;Error processing: {e}&quot;)
</code></pre>
<h4 id="dead-letter-queue-dlq">Dead Letter Queue (DLQ)</h4>
<p><span>Design choice: DLQ captures messages that fail processing multiple times</span>. This prevents poison messages from blocking the queue.</p>
<div>
<h4>DLQ Flow</h4>
<div>
<div>
<div>Main Queue</div>
</div>
<div>
<div>Fail 3x</div>
<div>→</div>
</div>
<div>
<div>Dead Letter Queue</div>
</div>
<div>
<div>Alert & Review</div>
<div>→</div>
</div>
<div>
<div>Manual Handling</div>
</div>
</div>
</div>
<pre><code class="language-python"># Configure DLQ in CloudFormation/Terraform
dlq_config = {
    'RedrivePolicy': json.dumps({
        'deadLetterTargetArn': 'arn:aws:sqs:us-east-1:123456789:my-queue-dlq',
        'maxReceiveCount': 3  # Move to DLQ after 3 failed attempts
    })
}
</code></pre>
<h4 id="long-polling-vs-short-polling">Long Polling vs Short Polling</h4>
<div>
<h4>Polling Comparison</h4>
<table>
<tr>
<th>Aspect</th>
<th>Short Polling</th>
<th>Long Polling</th>
</tr>
<tr>
<td><strong>Behavior</strong></td>
<td>Returns immediately (even if empty)</td>
<td>Waits up to 20 seconds for messages</td>
</tr>
<tr>
<td><strong>API Calls</strong></td>
<td>Many (costly)</td>
<td>Fewer (cost-effective)</td>
</tr>
<tr>
<td><strong>Empty Responses</strong></td>
<td>Common</td>
<td>Rare</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Immediate response needed</td>
<td>Most use cases (recommended)</td>
</tr>
</table>
</div>
<hr />
<h2 id="amazon-sns-simple-notification-service">Amazon SNS (Simple Notification Service)</h2>
<h3 id="what-is-sns">What is SNS?</h3>
<p><span>SNS is a fully managed pub/sub messaging service that enables fan-out messaging patterns</span>. Unlike SQS (point-to-point), SNS delivers messages to multiple subscribers simultaneously.</p>
<div>
<h4>SNS Fan-Out Architecture</h4>
<div>
<div>
<div>Publisher</div>
<div>Sends message once</div>
</div>
<div>↓</div>
<div>
<div>SNS Topic</div>
<div>Distributes to all subscribers</div>
</div>
<div>
<div>↓</div>
<div>↓</div>
<div>↓</div>
<div>↓</div>
</div>
<div>
<div>
<div>SQS Queue</div>
</div>
<div>
<div>Lambda</div>
</div>
<div>
<div>HTTP/S</div>
</div>
<div>
<div>Email/SMS</div>
</div>
</div>
</div>
</div>
<h3 id="sns-vs-sqs---key-differences">SNS vs SQS - Key Differences</h3>
<div>
<h4>When to Use Each</h4>
<div>
<div>
<div>SNS (Pub/Sub)</div>
<div>
<div>One-to-many messaging</div>
<div>Push-based delivery</div>
<div>No message persistence</div>
<div>Multiple subscriber types</div>
<div>Use for: Notifications, alerts, fan-out</div>
</div>
</div>
<div>
<div>SQS (Queue)</div>
<div>
<div>One-to-one messaging</div>
<div>Pull-based (polling)</div>
<div>Messages persist until processed</div>
<div>Single consumer type</div>
<div>Use for: Work queues, decoupling, buffering</div>
</div>
</div>
</div>
</div>
<h3 id="sns--sqs-fan-out-pattern">SNS + SQS Fan-Out Pattern</h3>
<p><span>Common pattern: Combine SNS with multiple SQS queues for reliable fan-out with persistence</span>.</p>
<div>
<h4>SNS + SQS Fan-Out</h4>
<div>
<div>
<strong>Order Service</strong>
</div>
<div>↓ Publish</div>
<div>
<strong>orders-topic (SNS)</strong>
</div>
<div>
<div>↓</div>
<div>↓</div>
<div>↓</div>
</div>
<div>
<div>
<div>inventory-queue</div>
<div>Update stock</div>
</div>
<div>
<div>shipping-queue</div>
<div>Create shipment</div>
</div>
<div>
<div>analytics-queue</div>
<div>Track metrics</div>
</div>
</div>
</div>
</div>
<pre><code class="language-python">import boto3
import json

sns = boto3.client('sns')
topic_arn = 'arn:aws:sns:us-east-1:123456789:orders-topic'

# Publish to SNS topic (fans out to all subscribers)
response = sns.publish(
    TopicArn=topic_arn,
    Message=json.dumps({
        'order_id': '12345',
        'customer_id': 'cust-789',
        'total': 99.99,
        'items': ['item-1', 'item-2']
    }),
    Subject='New Order Created',
    MessageAttributes={
        'order_type': {
            'DataType': 'String',
            'StringValue': 'standard'
        }
    }
)
print(f&quot;Message published: {response['MessageId']}&quot;)

# Message filtering (only send to subscribers matching filter)
# Subscriber can set filter policy:
filter_policy = {
    'order_type': ['priority', 'express']  # Only receive priority/express orders
}
</code></pre>
<h3 id="message-filtering">Message Filtering</h3>
<p><span>Trade-off: Message filtering reduces unnecessary processing but adds complexity</span>.</p>
<pre><code class="language-python"># Set filter policy on subscription
sns.set_subscription_attributes(
    SubscriptionArn='arn:aws:sns:us-east-1:123456789:orders-topic:subscription-id',
    AttributeName='FilterPolicy',
    AttributeValue=json.dumps({
        'order_type': ['priority'],
        'region': ['us-east', 'us-west'],
        'total': [{'numeric': ['&gt;=', 100]}]  # Orders &gt;= $100
    })
)
</code></pre>
<hr />
<h2 id="interview-deep-dive">Interview Deep Dive</h2>
<h3 id="level-1-questions">Level 1 Questions</h3>
<div>
<h4 id="q1-how-would-you-design-a-system-that-processes-orders-with-guaranteed-exactly-once-processing">Q1: How would you design a system that processes orders with guaranteed exactly-once processing?</h4>
<p><strong>Answer:</strong></p>
<p>Use SQS FIFO queue with message deduplication:</p>
<ol>
<li><strong>FIFO Queue</strong>: Ensures strict ordering within message groups</li>
<li><strong>MessageDeduplicationId</strong>: Prevents duplicate message delivery (5-minute window)</li>
<li><strong>MessageGroupId</strong>: Enables parallel processing while maintaining order within groups</li>
<li><strong>Idempotent Processing</strong>: Design consumers to handle potential reprocessing</li>
</ol>
<pre><code class="language-python"># Send order with deduplication
sqs.send_message(
QueueUrl=fifo_queue_url,
MessageBody=json.dumps(order),
MessageGroupId=f&quot;customer-{order['customer_id']}&quot;,  # Orders per customer in order
MessageDeduplicationId=f&quot;order-{order['order_id']}&quot;  # Prevent duplicates
)
</code></pre>
<p><span>Key insight: Even with FIFO, design for idempotency - distributed systems can still have edge cases</span>.</p>
<h5 id="level-2-follow-ups">Level 2 Follow-ups:</h5>
<p><strong>Q1.1: What happens if processing takes longer than visibility timeout?</strong></p>
<p>The message becomes visible again and another consumer may pick it up. Solutions:</p>
<ul>
<li>Extend visibility timeout during processing using <code>ChangeMessageVisibility</code></li>
<li>Use heartbeat pattern to periodically extend timeout</li>
<li>Set conservative initial timeout based on P99 processing time</li>
</ul>
<pre><code class="language-python">def process_with_heartbeat(message, queue_url):
receipt_handle = message['ReceiptHandle']

def extend_visibility():
while not processing_complete:
sqs.change_message_visibility(
QueueUrl=queue_url,
ReceiptHandle=receipt_handle,
VisibilityTimeout=60
)
time.sleep(30)  # Extend every 30 seconds

heartbeat_thread = threading.Thread(target=extend_visibility)
heartbeat_thread.start()

try:
process_order(message)
processing_complete = True
finally:
heartbeat_thread.join()
</code></pre>
<h6 id="level-3-follow-ups">Level 3 Follow-ups:</h6>
<p><strong>Q1.1.1: How do you handle the case where heartbeat thread fails but processing continues?</strong></p>
<p>Implement multiple safeguards:</p>
<ul>
<li>Use idempotency keys to ensure reprocessing is safe</li>
<li>Store processing state in DynamoDB with conditional writes</li>
<li>Implement distributed locking using DynamoDB or Redis</li>
</ul>
<p><strong>Q1.1.2: What's the maximum visibility timeout and how do you handle processing that exceeds it?</strong></p>
<p>Maximum is 12 hours. For longer processing:</p>
<ul>
<li>Break work into smaller chunks</li>
<li>Use Step Functions for orchestration</li>
<li>Store progress in database and resume from checkpoints</li>
</ul>
<p><strong>Q1.1.3: How does this interact with DLQ configuration?</strong></p>
<p>DLQ counts receive attempts, not visibility timeout extensions. Each time a message becomes visible counts as a receive. Coordinate maxReceiveCount with your retry strategy.</p>
<hr />
<p><strong>Q1.2: How do you scale consumers while maintaining message ordering?</strong></p>
<p>Use MessageGroupId strategically:</p>
<ul>
<li>Messages with same GroupId are processed in order by one consumer</li>
<li>Different GroupIds can be processed in parallel</li>
<li>Partition by natural keys (customer_id, tenant_id, etc.)</li>
</ul>
<pre><code>Group A: Consumer 1 → [msg1, msg2, msg3] (in order)
Group B: Consumer 2 → [msg4, msg5, msg6] (in order)
Group C: Consumer 3 → [msg7, msg8, msg9] (in order)
</code></pre>
<h6 id="level-3-follow-ups-1">Level 3 Follow-ups:</h6>
<p><strong>Q1.2.1: What if one MessageGroup has much higher traffic than others?</strong></p>
<p>Hot partition problem. Solutions:</p>
<ul>
<li>Sub-partition within group (customer-123-partition-1, customer-123-partition-2)</li>
<li>Accept eventual consistency for high-volume groups</li>
<li>Use separate queue for high-volume entities</li>
</ul>
<p><strong>Q1.2.2: How many consumers can process from a FIFO queue simultaneously?</strong></p>
<p>Up to 20,000 in-flight messages per queue. Each MessageGroup limited to 20,000 in-flight. For higher scale, use multiple queues with load balancing.</p>
<p><strong>Q1.2.3: What happens if a consumer dies mid-processing?</strong></p>
<p>Message becomes visible after visibility timeout. Ensure idempotent processing and potentially use XA transactions or saga pattern for multi-step operations.</p>
<hr />
<p><strong>Q1.3: When would you choose Standard queue over FIFO despite needing ordering?</strong></p>
<p>When throughput requirements exceed FIFO limits (3,000 msg/sec with batching):</p>
<ul>
<li>Implement ordering at application level using timestamps</li>
<li>Accept eventual consistency with conflict resolution</li>
<li>Use DynamoDB to track and reorder messages</li>
<li>Partition workload across multiple FIFO queues</li>
</ul>
<h6 id="level-3-follow-ups-2">Level 3 Follow-ups:</h6>
<p><strong>Q1.3.1: How do you implement application-level ordering with Standard queues?</strong></p>
<pre><code class="language-python"># Include sequence number and buffer for reordering
message = {
'sequence': 12345,
'timestamp': '2024-01-15T10:30:00Z',
'entity_id': 'order-789',
'data': {...}
}

# Consumer buffers and reorders
class OrderedProcessor:
def __init__(self):
self.buffer = {}
self.expected_sequence = {}

def process(self, message):
entity_id = message['entity_id']
seq = message['sequence']

if seq == self.expected_sequence.get(entity_id, 0):
self.handle(message)
self.expected_sequence[entity_id] = seq + 1
self.flush_buffer(entity_id)
else:
self.buffer[(entity_id, seq)] = message
</code></pre>
<p><strong>Q1.3.2: What are the failure modes of application-level ordering?</strong></p>
<ul>
<li>Missing messages create gaps (need timeout and skip logic)</li>
<li>Buffer can grow unbounded (need size limits)</li>
<li>Clock skew can affect timestamp ordering</li>
<li>Consumer restarts lose buffer state (persist to Redis/DynamoDB)</li>
</ul>
<p><strong>Q1.3.3: How does at-least-once delivery affect your ordering implementation?</strong></p>
<p>Duplicates can arrive out of order. Solutions:</p>
<ul>
<li>Track processed message IDs in database</li>
<li>Use idempotency keys</li>
<li>Design operations to be naturally idempotent (SET vs INCREMENT)</li>
</ul>
</div>
<div>
<h4 id="q2-design-a-notification-system-that-sends-alerts-through-multiple-channels-email-sms-push-with-different-priority-levels">Q2: Design a notification system that sends alerts through multiple channels (email, SMS, push) with different priority levels.</h4>
<p><strong>Answer:</strong></p>
<p>Use SNS with message filtering and multiple SQS queues:</p>
<div>
<div>
<div>Notification Service</div>
<div>↓</div>
<div>notifications-topic (SNS)</div>
<div>
<div>
<div>priority=high</div>
<div>↓</div>
<div>high-priority-queue</div>
</div>
<div>
<div>channel=email</div>
<div>↓</div>
<div>email-queue</div>
</div>
<div>
<div>channel=sms</div>
<div>↓</div>
<div>sms-queue</div>
</div>
</div>
</div>
</div>
<pre><code class="language-python"># Publish notification with attributes for filtering
sns.publish(
TopicArn=topic_arn,
Message=json.dumps({
'user_id': 'user-123',
'title': 'Payment Received',
'body': 'Your payment of $99.99 was processed',
'channels': ['email', 'push']
}),
MessageAttributes={
'priority': {'DataType': 'String', 'StringValue': 'high'},
'notification_type': {'DataType': 'String', 'StringValue': 'payment'},
'channels': {'DataType': 'String.Array', 'StringValue': '[&quot;email&quot;, &quot;push&quot;]'}
}
)
</code></pre>
<h5 id="level-2-follow-ups-1">Level 2 Follow-ups:</h5>
<p><strong>Q2.1: How do you handle rate limiting for SMS/email providers?</strong></p>
<p>Implement token bucket rate limiter in consumer:</p>
<pre><code class="language-python">class RateLimitedConsumer:
def __init__(self, rate_per_second):
self.rate = rate_per_second
self.tokens = rate_per_second
self.last_update = time.time()

def consume(self):
# Refill tokens
now = time.time()
self.tokens = min(
self.rate,
self.tokens + (now - self.last_update) * self.rate
)
self.last_update = now

if self.tokens &gt;= 1:
self.tokens -= 1
return True
return False
</code></pre>
<p>Also use SQS delay queues for backoff when rate limited.</p>
<h6 id="level-3-follow-ups-3">Level 3 Follow-ups:</h6>
<p><strong>Q2.1.1: How do you distribute rate limits across multiple consumers?</strong></p>
<p>Use Redis for distributed rate limiting:</p>
<pre><code class="language-python">def distributed_rate_limit(key, limit, window_seconds):
pipe = redis.pipeline()
now = time.time()
window_start = now - window_seconds

pipe.zremrangebyscore(key, 0, window_start)
pipe.zadd(key, {str(now): now})
pipe.zcard(key)
pipe.expire(key, window_seconds)

results = pipe.execute()
return results[2] &lt;= limit
</code></pre>
<p><strong>Q2.1.2: What happens to messages when you hit rate limits?</strong></p>
<p>Options:</p>
<ol>
<li>Return to queue with delay (DelaySeconds)</li>
<li>Move to throttle queue with slower processing</li>
<li>Store in DynamoDB and process via scheduled Lambda</li>
<li>Implement exponential backoff at consumer level</li>
</ol>
<p><strong>Q2.1.3: How do you prioritize high-priority notifications when rate limited?</strong></p>
<p>Separate queues with different consumer allocations:</p>
<ul>
<li>High priority: 70% of rate limit capacity</li>
<li>Normal priority: 25% of rate limit capacity</li>
<li>Low priority: 5% of rate limit capacity</li>
</ul>
<hr />
<p><strong>Q2.2: How do you ensure a notification is delivered to at least one channel?</strong></p>
<p>Implement saga pattern with compensation:</p>
<pre><code class="language-python">async def send_notification(notification):
results = {}

for channel in notification['channels']:
try:
results[channel] = await send_via_channel(channel, notification)
except Exception as e:
results[channel] = {'error': str(e)}

# Check if at least one succeeded
successes = [c for c, r in results.items() if 'error' not in r]

if not successes:
# All channels failed - store for retry
await store_failed_notification(notification, results)
raise AllChannelsFailedException(results)

return results
</code></pre>
<h6 id="level-3-follow-ups-4">Level 3 Follow-ups:</h6>
<p><strong>Q2.2.1: How do you track delivery status across channels?</strong></p>
<p>Use DynamoDB with GSIs for querying:</p>
<pre><code class="language-python">notification_record = {
'pk': f&quot;NOTIF#{notification_id}&quot;,
'sk': f&quot;CHANNEL#{channel}&quot;,
'user_id': user_id,
'status': 'delivered',  # pending, delivered, failed
'delivered_at': timestamp,
'provider_id': external_message_id
}
</code></pre>
<p><strong>Q2.2.2: How do you handle partial failures in multi-channel delivery?</strong></p>
<ul>
<li>Track each channel independently</li>
<li>Implement per-channel retry with backoff</li>
<li>Alert on channels with high failure rates</li>
<li>Allow user to configure fallback channel preferences</li>
</ul>
<p><strong>Q2.2.3: What if email succeeds but user requested push notification?</strong></p>
<p>Define delivery semantics:</p>
<ul>
<li>&quot;Any channel&quot; - success if any works</li>
<li>&quot;Preferred channel&quot; - try preferred first, fallback allowed</li>
<li>&quot;All channels&quot; - must deliver to all requested</li>
<li>Store user preferences and apply business rules</li>
</ul>
</div>
<div>
<h4 id="q3-how-would-you-handle-message-replay-for-debugging-or-reprocessing-in-sqs">Q3: How would you handle message replay for debugging or reprocessing in SQS?</h4>
<p><strong>Answer:</strong></p>
<p>SQS doesn't natively support replay. Implement event sourcing pattern:</p>
<ol>
<li><strong>Dual Write</strong>: Publish to SQS and archive to S3/DynamoDB</li>
<li><strong>Event Store</strong>: Use DynamoDB Streams or Kinesis for ordered, replayable log</li>
<li><strong>Dead Letter Replay</strong>: Process DLQ messages with modified handling</li>
</ol>
<pre><code class="language-python">class ReplayableMessageHandler:
def __init__(self):
self.s3 = boto3.client('s3')
self.sqs = boto3.client('sqs')

def send_with_archive(self, queue_url, message):
message_id = str(uuid.uuid4())
timestamp = datetime.utcnow().isoformat()

# Archive to S3 for replay capability
self.s3.put_object(
Bucket='message-archive',
Key=f&quot;messages/{timestamp[:10]}/{message_id}.json&quot;,
Body=json.dumps({
'id': message_id,
'timestamp': timestamp,
'body': message,
'queue': queue_url
})
)

# Send to SQS
self.sqs.send_message(
QueueUrl=queue_url,
MessageBody=json.dumps(message),
MessageAttributes={
'archive_key': {
'DataType': 'String',
'StringValue': f&quot;messages/{timestamp[:10]}/{message_id}.json&quot;
}
}
)

def replay_messages(self, queue_url, start_date, end_date):
&quot;&quot;&quot;Replay archived messages to queue&quot;&quot;&quot;
paginator = self.s3.get_paginator('list_objects_v2')

for date in date_range(start_date, end_date):
prefix = f&quot;messages/{date}/&quot;

for page in paginator.paginate(Bucket='message-archive', Prefix=prefix):
for obj in page.get('Contents', []):
archived = json.loads(
self.s3.get_object(Bucket='message-archive', Key=obj['Key'])['Body'].read()
)

self.sqs.send_message(
QueueUrl=queue_url,
MessageBody=json.dumps(archived['body']),
MessageAttributes={
'replay': {'DataType': 'String', 'StringValue': 'true'},
'original_timestamp': {'DataType': 'String', 'StringValue': archived['timestamp']}
}
)
</code></pre>
<h5 id="level-2-follow-ups-2">Level 2 Follow-ups:</h5>
<p><strong>Q3.1: How do you handle idempotency during replay?</strong></p>
<p>Track processed message IDs:</p>
<pre><code class="language-python">def process_with_idempotency(message, dynamodb_table):
message_id = message['MessageId']

try:
# Conditional put - fails if already exists
dynamodb_table.put_item(
Item={
'pk': f&quot;PROCESSED#{message_id}&quot;,
'processed_at': datetime.utcnow().isoformat(),
'ttl': int(time.time()) + 86400 * 7  # 7 day TTL
},
ConditionExpression='attribute_not_exists(pk)'
)
except ClientError as e:
if e.response['Error']['Code'] == 'ConditionalCheckFailedException':
print(f&quot;Message {message_id} already processed, skipping&quot;)
return
raise

# Process the message
handle_message(message)
</code></pre>
<h6 id="level-3-follow-ups-5">Level 3 Follow-ups:</h6>
<p><strong>Q3.1.1: What's the storage cost of tracking all processed message IDs?</strong></p>
<p>With TTL-based cleanup:</p>
<ul>
<li>1M messages/day × 7 days = 7M records</li>
<li>~100 bytes per record = 700MB</li>
<li>DynamoDB cost: ~$0.25/GB/month = negligible</li>
<li>Use TTL to auto-expire old records</li>
</ul>
<p><strong>Q3.1.2: How do you handle the case where processing succeeded but idempotency record failed to write?</strong></p>
<p>Use transactional writes:</p>
<pre><code class="language-python">dynamodb.transact_write_items(
TransactItems=[
{
'Put': {
'TableName': 'idempotency',
'Item': {'pk': message_id, 'status': 'completed'}
}
},
{
'Put': {
'TableName': 'results',
'Item': {'pk': result_id, 'data': result_data}
}
}
]
)
</code></pre>
<p><strong>Q3.1.3: How do you handle replay for messages that modify external systems?</strong></p>
<ul>
<li>External systems need their own idempotency (payment providers usually have this)</li>
<li>Store external transaction IDs for reconciliation</li>
<li>Use compensating transactions for rollback scenarios</li>
</ul>
</div>
<hr />
<h2 id="common-mistakes">Common Mistakes</h2>
<div>
<h4>SQS/SNS Anti-Patterns</h4>
<div>
<div>
<div>Not using Long Polling</div>
<div>Short polling wastes API calls and increases costs. Always use WaitTimeSeconds=20.</div>
</div>
<div>
<div>Ignoring Visibility Timeout</div>
<div>Setting timeout too low causes duplicate processing. Set based on P99 processing time + buffer.</div>
</div>
<div>
<div>Not Configuring DLQ</div>
<div>Poison messages can block queue indefinitely. Always configure DLQ with appropriate maxReceiveCount.</div>
</div>
<div>
<div>Assuming Exactly-Once with Standard Queue</div>
<div>Standard queues are at-least-once. Design consumers to be idempotent or use FIFO.</div>
</div>
<div>
<div>Large Message Bodies</div>
<div>SQS max is 256KB. Use S3 for large payloads and pass reference in message.</div>
</div>
<div>
<div>SNS Without Persistence</div>
<div>SNS doesn't persist messages. If subscriber is down, messages are lost. Use SNS+SQS pattern.</div>
</div>
</div>
</div>
<hr />
<h2 id="quick-reference-card">Quick Reference Card</h2>
<div>
<h4>SQS/SNS Cheat Sheet</h4>
<div>
<div>
<div>SQS Limits</div>
<div>
<div><strong>Message size:</strong> 256 KB</div>
<div><strong>Retention:</strong> 1 min - 14 days (default 4 days)</div>
<div><strong>Visibility timeout:</strong> 0 sec - 12 hours</div>
<div><strong>Long poll wait:</strong> 1-20 seconds</div>
<div><strong>FIFO throughput:</strong> 3,000 msg/sec (batched)</div>
</div>
</div>
<div>
<div>SNS Limits</div>
<div>
<div><strong>Message size:</strong> 256 KB</div>
<div><strong>Subscriptions/topic:</strong> 12.5 million</div>
<div><strong>Topics/account:</strong> 100,000</div>
<div><strong>Filter policies/sub:</strong> 1</div>
<div><strong>FIFO throughput:</strong> 300 msg/sec</div>
</div>
</div>
<div>
<div>When to Use SQS</div>
<div>
<div>Work queues / job processing</div>
<div>Decoupling microservices</div>
<div>Buffering for rate limiting</div>
<div>Guaranteed delivery needed</div>
</div>
</div>
<div>
<div>When to Use SNS</div>
<div>
<div>Fan-out to multiple subscribers</div>
<div>Push notifications</div>
<div>Event broadcasting</div>
<div>Multi-protocol delivery</div>
</div>
</div>
</div>
</div>
<hr />
<h2 id="related-topics">Related Topics</h2>
<ul>
<li><a href="/topic/system-design/message-queues">[Message Queues]</a> - General queuing concepts</li>
<li><a href="/topic/system-design/event-sourcing">[Event Sourcing]</a> - Event-driven patterns</li>
<li><a href="/topic/system-design/microservices">[Microservices]</a> - Service communication</li>
<li><a href="/topic/system-design/rate-limiting">[Rate Limiting]</a> - Throttling strategies</li>
<li><a href="/topic/system-design/distributed-locking">[Distributed Locking]</a> - Coordination patterns</li>
</ul>
