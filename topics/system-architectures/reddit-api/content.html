<h1 id="design-the-reddit-api">Design The Reddit API</h1>
<h2 id="problem-statement">Problem Statement</h2>
<p>Design a social news aggregation and discussion platform like Reddit with subreddits, posts, comments, voting, and content moderation.</p>
<div>
<h3 id="core-requirements">Core Requirements</h3>
<ul>
<li><strong>Subreddits</strong>: Community creation and management</li>
<li><strong>Posts</strong>: Text, links, images, videos with voting</li>
<li><strong>Comments</strong>: Threaded discussions with voting</li>
<li><strong>Voting System</strong>: Upvotes/downvotes with karma</li>
<li><strong>Feed Generation</strong>: Home, popular, subreddit feeds</li>
<li><strong>Moderation</strong>: Content rules, spam detection, banning</li>
</ul>
</div>
<hr />
<h2 id="high-level-architecture">High-Level Architecture</h2>
<div>
<h3>REDDIT SYSTEM ARCHITECTURE</h3>
<div>
<pre><code>&lt;!-- CDN Layer --&gt;
</code></pre>
<div>
<strong>CloudFront (CDN)</strong>
</div>
<div>↓</div>
<pre><code>&lt;!-- Client Apps --&gt;
</code></pre>
<div>
<div>
<strong>Web App</strong><br><span>(Next.js)</span>
</div>
<div>
<strong>Mobile API</strong><br><span>Gateway</span>
</div>
<div>
<strong>OAuth</strong><br><span>Server</span>
</div>
</div>
<div>↓</div>
  <!-- API Gateway -->
<div>
<strong>API Gateway</strong><br><span>Rate Limiting, Auth</span>
</div>
<div>↓</div>
  <!-- Services Layer -->
<div>
<div>
<div><strong>Post</strong><br><span>Service</span></div>
<div><strong>Comment</strong><br><span>Service</span></div>
<div><strong>Vote</strong><br><span>Service</span></div>
</div>
<div>
<div><strong>Subreddit</strong><br><span>Service</span></div>
<div><strong>User</strong><br><span>Service</span></div>
<div><strong>Feed</strong><br><span>Service</span></div>
</div>
</div>
<div>↓</div>
  <!-- Data Layer -->
<div>
<div>
<strong>PostgreSQL</strong><br><span>(Data)</span>
</div>
<div>
<strong>Redis</strong><br><span>(Cache)</span>
</div>
<div>
<strong>S3</strong><br><span>(Media)</span>
</div>
</div>
</div>
</div>
<hr />
<h2 id="phase-1-starting-phase-low-budget">Phase 1: Starting Phase (Low Budget)</h2>
<div>
<div>
<h3 id="assumptions">Assumptions</h3>
<pre><code>                          - **Users**: 10,000 - 100,000 monthly active
                          - **Posts**: 10,000 posts/day
                          - **Comments**: 50,000 comments/day
                          - **Budget**: $500 - $2,000/month
</code></pre>
<h3 id="monolithic-architecture">Monolithic Architecture</h3>
<div>
<div>
  <!-- Monolith Container -->
<div>
<h4>REDDIT MONOLITH</h4>
  <!-- Modules Layer -->
<div>
<div>MODULES</div>
<div>
<div><strong>Subreddits</strong></div>
<div><strong>Posts</strong></div>
<div><strong>Comments</strong></div>
<div><strong>Votes</strong></div>
</div>
<div>
<div><strong>Users</strong></div>
<div><strong>Feeds</strong></div>
<div><strong>Search</strong></div>
<div><strong>Mods</strong></div>
</div>
</div>
  <!-- Data Access Layer -->
<div>
<strong>DATA ACCESS</strong>
</div>
</div>
<div>↓</div>
  <!-- Databases -->
<div>
<div>
<strong>PostgreSQL</strong>
</div>
<div>
<strong>Redis</strong>
</div>
<div>
<strong>S3</strong>
</div>
</div>
</div>
</div>
<h4 id="data-model">Data Model</h4>
<pre><code>                          ```sql
                          -- Core Tables
                          CREATE TABLE subreddits (
                          id SERIAL PRIMARY KEY,
                          name VARCHAR(50) UNIQUE NOT NULL,
                          description TEXT,
                          created_by INT REFERENCES users(id),
                          subscriber_count INT DEFAULT 0,
                          created_at TIMESTAMP DEFAULT NOW()
                          );

                          CREATE TABLE posts (
                          id SERIAL PRIMARY KEY,
                          subreddit_id INT REFERENCES subreddits(id),
                          author_id INT REFERENCES users(id),
                          title VARCHAR(300) NOT NULL,
                          content TEXT,
                          url VARCHAR(2000),
                          post_type VARCHAR(20), -- text, link, image, video
                          score INT DEFAULT 0,
                          comment_count INT DEFAULT 0,
                          created_at TIMESTAMP DEFAULT NOW()
                          );

                          CREATE TABLE comments (
                          id SERIAL PRIMARY KEY,
                          post_id INT REFERENCES posts(id),
                          parent_id INT REFERENCES comments(id), -- For threading
                          author_id INT REFERENCES users(id),
                          content TEXT NOT NULL,
                          score INT DEFAULT 0,
                          depth INT DEFAULT 0,
                          created_at TIMESTAMP DEFAULT NOW()
                          );

                          CREATE TABLE votes (
                          user_id INT REFERENCES users(id),
                          target_type VARCHAR(10), -- 'post' or 'comment'
                          target_id INT,
                          vote_type SMALLINT, -- 1 or -1
                          created_at TIMESTAMP DEFAULT NOW(),
                          PRIMARY KEY (user_id, target_type, target_id)
                          );
                          ```
</code></pre>
<h4 id="abstract-code">Abstract Code</h4>
<pre><code>                          ```python
                          class VotingService:
                          def vote(self, user_id, target_type, target_id, vote_type):
                          with transaction.atomic():
                          # Get existing vote
                          existing = Vote.objects.filter(
                          user_id=user_id,
                          target_type=target_type,
                          target_id=target_id
                          ).first()

                          score_delta = vote_type
                          if existing:
                          if existing.vote_type == vote_type:
                          # Remove vote (toggle off)
                          existing.delete()
                          score_delta = -vote_type
                          else:
                          # Change vote
                          score_delta = vote_type * 2
                          existing.vote_type = vote_type
                          existing.save()
                          else:
                          Vote.objects.create(
                          user_id=user_id,
                          target_type=target_type,
                          target_id=target_id,
                          vote_type=vote_type
                          )

                          # Update score
                          if target_type == 'post':
                          Post.objects.filter(id=target_id).update(
                          score=F('score') + score_delta
                          )
                          else:
                          Comment.objects.filter(id=target_id).update(
                          score=F('score') + score_delta
                          )

                          # Update user karma (async in production)
                          self.update_author_karma(target_type, target_id, score_delta)
                          ```
</code></pre>
</div>
</div>
<hr />
<h2 id="phase-2-medium-user-phase">Phase 2: Medium User Phase</h2>
<div>
<div>
<h3 id="assumptions-1">Assumptions</h3>
<pre><code>                          - **Users**: 5M - 50M monthly active
                          - **Posts**: 500K posts/day
                          - **Votes**: 50M votes/day
                          - **Budget**: $50,000 - $200,000/month
</code></pre>
<h3 id="microservices-architecture">Microservices Architecture</h3>
<div>
<!-- API Gateway Layer -->
<div>
<div>
<div>API Gateway</div>
<div>Load Balancer + Rate Limiting</div>
</div>
</div>
<!-- Arrow down -->
<div>
<div></div>
</div>
<!-- Core Services Layer -->
<div>
<div>
<div>POST SERVICE</div>
<div>PostgreSQL (sharded)</div>
</div>
<div>
<div>COMMENT SERVICE</div>
<div>PostgreSQL (sharded)</div>
</div>
<div>
<div>VOTE SERVICE</div>
<div>Redis + Cassandra</div>
</div>
</div>
<!-- Arrow down -->
<div>
<div></div>
</div>
<!-- Kafka Event Bus -->
<div>
<div>
<div>KAFKA Event Bus</div>
<div>Async Message Queue</div>
</div>
</div>
<!-- Arrow down -->
<div>
<div></div>
</div>
<!-- Consumer Services Layer -->
<div>
<div>
<div>FEED SERVICE</div>
<div>Redis + Cassandra</div>
</div>
<div>
<div>SEARCH SERVICE</div>
<div>Elasticsearch</div>
</div>
<div>
<div>NOTIFICATION</div>
<div>Redis + Firebase</div>
</div>
</div>
</div>
<h3 id="feed-generation">Feed Generation</h3>
<div>
<h4>FEED RANKING ALGORITHM</h4>
<!-- Hot Score Algorithm Formula -->
<div>
<div>Hot Score Algorithm (Reddit-style):</div>
<div>
<span>score</span> = log10(max(|ups - downs|, 1))
</div>
<div>
<span>order</span> = sign(ups - downs)
</div>
<div>
<span>seconds</span> = epoch_seconds(created_at) - 1134028003
</div>
<div>
<span>hot_score</span> = round(score + order * seconds / 45000, 7)
</div>
</div>
<!-- Hot Score Factors Box -->
<div>
<div>HOT SCORE FACTORS</div>
<div>
<div>
<div>+</div>
<div><strong>Vote Score:</strong> Higher = Better</div>
</div>
<div>
<div>&#9201;</div>
<div><strong>Time Decay:</strong> Newer = Better</div>
</div>
<div>
<div>&#8644;</div>
<div><strong>Controversy:</strong> Balanced = Featured</div>
</div>
</div>
</div>
<pre><code>                            ```python
                            # Feed generation with caching
                            class FeedService:
                            def get_home_feed(self, user_id, page=1, limit=25):
                            cache_key = f&quot;feed:home:{user_id}:{page}&quot;

                            # Try cache first
                            cached = redis.get(cache_key)
                            if cached:
                            return json.loads(cached)

                            # Get user subscriptions
                            subscriptions = self.get_subscriptions(user_id)

                            # Fetch top posts from each subreddit
                            posts = Post.objects.filter(
                            subreddit_id__in=subscriptions,
                            created_at__gte=now() - timedelta(days=7)
                            ).order_by('-hot_score')[:limit * 3]  # Over-fetch

                            # Apply personalization
                            ranked_posts = self.personalize(user_id, posts)[:limit]

                            # Cache result
                            redis.setex(cache_key, 60, json.dumps(ranked_posts))

                            return ranked_posts

                            def personalize(self, user_id, posts):
                            # Get user preferences from ML model
                            user_vector = self.get_user_embedding(user_id)

                            for post in posts:
                            post_vector = self.get_post_embedding(post.id)
                            post.relevance_score = cosine_similarity(user_vector, post_vector)

                            return sorted(posts, key=lambda p: p.hot_score * p.relevance_score, reverse=True)
                            ```
</code></pre>
</div>
<h3 id="comment-threading">Comment Threading</h3>
<div>
<!-- Comment Tree Structure Diagram -->
<div>
<div>Comment Tree Structure:</div>
<!-- Post -->
<div>
Post: "What's your favorite programming language?"
</div>
<!-- Comment 1 -->
<div>
<div>
<span>Comment 1</span>
<span>depth: 0</span>
<span>score: 150</span>
</div>
<!-- Reply 1.1 -->
<div>
<div>
<span>Reply 1.1</span>
<span>depth: 1</span>
<span>score: 45</span>
</div>
<!-- Reply 1.1.1 -->
<div>
<div>
<span>Reply 1.1.1</span>
<span>depth: 2</span>
<span>score: 12</span>
</div>
</div>
</div>
<!-- Reply 1.2 -->
<div>
<div>
<span>Reply 1.2</span>
<span>depth: 1</span>
<span>score: 30</span>
</div>
</div>
</div>
<!-- Comment 2 -->
<div>
<div>
<span>Comment 2</span>
<span>depth: 0</span>
<span>score: 120</span>
</div>
<!-- Reply 2.1 -->
<div>
<div>
<span>Reply 2.1</span>
<span>depth: 1</span>
<span>score: 25</span>
</div>
</div>
</div>
<!-- Comment 3 -->
<div>
<div>
<span>Comment 3</span>
<span>depth: 0</span>
<span>score: 80</span>
</div>
</div>
</div>
<!-- Storage Strategy -->
<div>
<div>Storage Strategy:</div>
<div>
<div>
<span>/1/1.1/1.1.1</span>
<span>Materialized Path</span>
</div>
<div>Allows efficient subtree queries</div>
<div>Easy depth calculation</div>
</div>
</div>
<pre><code>                            ```python
                            # Efficient comment loading
                            class CommentService:
                            def get_comments(self, post_id, sort='best', max_depth=10):
                            # Load top-level comments
                            root_comments = Comment.objects.filter(
                            post_id=post_id,
                            parent_id=None
                            ).order_by(self.get_sort_key(sort))[:200]

                            # Batch load all children up to max_depth
                            all_ids = [c.id for c in root_comments]
                            children = self.load_children_batch(all_ids, max_depth)

                            # Build tree structure
                            return self.build_tree(root_comments, children)

                            def load_children_batch(self, parent_ids, max_depth):
                            &quot;&quot;&quot;Load children using recursive CTE&quot;&quot;&quot;
                            query = &quot;&quot;&quot;
                            WITH RECURSIVE comment_tree AS (
                            SELECT *, 1 as depth FROM comments WHERE parent_id = ANY(%s)
                            UNION ALL
                            SELECT c.*, ct.depth + 1
                            FROM comments c
                            JOIN comment_tree ct ON c.parent_id = ct.id
                            WHERE ct.depth &lt; %s
                            )
                            SELECT * FROM comment_tree ORDER BY depth, score DESC
                            &quot;&quot;&quot;
                            return Comment.objects.raw(query, [parent_ids, max_depth])
                            ```
</code></pre>
</div>
</div>
</div>
<hr />
<h2 id="phase-3-high-user-base-phase">Phase 3: High User Base Phase</h2>
<div>
<div>
<h3 id="assumptions-2">Assumptions</h3>
<pre><code>                          - **Users**: 500M+ monthly active
                          - **Posts**: 10M posts/day
                          - **Votes**: 2B votes/day
                          - **Budget**: $5M+/month
</code></pre>
<h3 id="global-architecture">Global Architecture</h3>
<div>
<!-- Global Reddit Infrastructure Diagram -->
<div>
<div>GLOBAL REDDIT INFRASTRUCTURE</div>
<!-- Global Traffic Manager -->
<div>
<div>
<div>Global Traffic Manager</div>
</div>
</div>
<!-- Arrow down -->
<div>
<div></div>
</div>
<!-- Regional Clusters -->
<div>
<!-- US-EAST -->
<div>
<div>US-EAST</div>
<div>
<div>EKS Cluster</div>
</div>
<div>
<div>Cassandra</div>
<div>(Multi-Master)</div>
</div>
</div>
<!-- EU-WEST -->
<div>
<div>EU-WEST</div>
<div>
<div>EKS Cluster</div>
</div>
<div>
<div>Cassandra</div>
<div>Replica</div>
</div>
</div>
<!-- AP-EAST -->
<div>
<div>AP-EAST</div>
<div>
<div>EKS Cluster</div>
</div>
<div>
<div>Cassandra</div>
<div>Replica</div>
</div>
</div>
</div>
<!-- Replication arrows -->
<div>
<div>&#8644; Replication &#8644;</div>
</div>
<!-- Global Services -->
<div>
<div>GLOBAL SERVICES</div>
<div>
<div>Kafka (Global)</div>
<div>S3 (Global)</div>
<div>Aurora Global</div>
<div>Redis Global</div>
</div>
</div>
</div>
</div>
<h3 id="vote-aggregation-at-scale">Vote Aggregation at Scale</h3>
<div>
<h4>HIGH-THROUGHPUT VOTING SYSTEM</h4>
<!-- Vote Flow Diagram -->
<div>
<div>Vote Flow (2B votes/day = 23K votes/second)</div>
<!-- Client -->
<div>
<div>
<div>Client</div>
<div>(Vote +1)</div>
</div>
</div>
<!-- Arrow -->
<div>
<div></div>
</div>
<!-- Vote Service with annotation -->
<div>
<div>
<div>Vote Service</div>
<div>(Stateless)</div>
</div>
<div>
Optimistic update to Redis<br/>(immediate response)
</div>
</div>
<!-- Arrow -->
<div>
<div></div>
</div>
<!-- Kafka Topic with annotation -->
<div>
<div>
<div>Kafka Topic</div>
<div>(Buffer)</div>
</div>
<div>
votes.raw<br/>(partitioned by post_id)
</div>
</div>
<!-- Arrow -->
<div>
<div></div>
</div>
<!-- Vote Aggregator with annotation -->
<div>
<div>
<div>Vote Aggregator</div>
</div>
<div>
Micro-batch aggregation<br/>(every 100ms)
</div>
</div>
<!-- Arrow -->
<div>
<div></div>
</div>
<!-- Storage Layer -->
<div>
<div>
<div>Cassandra</div>
<div>(Persist)</div>
</div>
<div>
<div>Redis</div>
<div>(Cache)</div>
</div>
</div>
<!-- Benefits -->
<div>
<div>Benefits:</div>
<div>
<div>
<span>&#10003;</span> Immediate feedback (optimistic)
</div>
<div>
<span>&#10003;</span> High throughput (batching)
</div>
<div>
<span>&#10003;</span> Eventual consistency (acceptable)
</div>
</div>
</div>
</div>
<pre><code>                            ```go
                            // Vote aggregator (Kafka consumer)
                            type VoteAggregator struct {
                            buffer    map[string]*VoteCount
                            flushLock sync.Mutex
                            }

                            func (va *VoteAggregator) ProcessBatch(votes []Vote) {
                            va.flushLock.Lock()
                            defer va.flushLock.Unlock()

                            // Aggregate votes in memory
                            for _, vote := range votes {
                            key := fmt.Sprintf(&quot;%s:%d&quot;, vote.TargetType, vote.TargetID)
                            if va.buffer[key] == nil {
                            va.buffer[key] = &amp;VoteCount{}
                            }
                            va.buffer[key].Delta += vote.Value
                            }
                            }

                            func (va *VoteAggregator) Flush() {
                            va.flushLock.Lock()
                            buffer := va.buffer
                            va.buffer = make(map[string]*VoteCount)
                            va.flushLock.Unlock()

                            // Batch update to Cassandra
                            batch := cassandra.NewBatch()
                            for key, count := range buffer {
                            batch.Query(
                            &quot;UPDATE scores SET score = score + ? WHERE id = ?&quot;,
                            count.Delta, key,
                            )
                            }
                            cassandra.ExecuteBatch(batch)

                            // Update Redis cache
                            pipe := redis.Pipeline()
                            for key, count := range buffer {
                            pipe.IncrBy(fmt.Sprintf(&quot;score:%s&quot;, key), count.Delta)
                            }
                            pipe.Exec()
                            }
                            ```
</code></pre>
</div>
</div>
</div>
<hr />
<h2 id="aws-technologies--alternatives">AWS Technologies &amp; Alternatives</h2>
<div>
<table>
<thead>
<tr>
<th>Component</th>
<th>AWS Service</th>
<th>Alternative</th>
<th>Trade-offs</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Posts/Comments DB</strong></td>
<td>Aurora PostgreSQL</td>
<td>CockroachDB</td>
<td>Aurora: Managed, Cockroach: Multi-region native</td>
</tr>
<tr>
<td><strong>Vote Storage</strong></td>
<td>DynamoDB</td>
<td>Cassandra</td>
<td>DynamoDB: Simpler, Cassandra: Better write throughput</td>
</tr>
<tr>
<td><strong>Cache</strong></td>
<td>ElastiCache Redis</td>
<td>Redis Enterprise</td>
<td>ElastiCache: Managed, Enterprise: Multi-active</td>
</tr>
<tr>
<td><strong>Feed Storage</strong></td>
<td>ElastiCache + DynamoDB</td>
<td>Cassandra</td>
<td>DynamoDB: Less ops, Cassandra: Better for time-series</td>
</tr>
<tr>
<td><strong>Search</strong></td>
<td>OpenSearch</td>
<td>Algolia</td>
<td>OpenSearch: Control, Algolia: Better relevance</td>
</tr>
<tr>
<td><strong>Media</strong></td>
<td>S3 + CloudFront</td>
<td>Cloudflare R2</td>
<td>S3: Ecosystem, R2: No egress fees</td>
</tr>
</tbody>
</table>
</div>
<hr />
<h2 id="distributed-systems-considerations">Distributed Systems Considerations</h2>
<div>
<h3 id="1-vote-consistency">1. Vote Consistency</h3>
<div>
<!-- Vote Consistency Diagram -->
<div>
<div>
<div>
<span>Problem:</span>
<span> Duplicate votes from race conditions</span>
</div>
<div>
<span>Solution:</span>
<span> Idempotency key</span>
</div>
</div>
<div>
<div>Vote Request:</div>
<div>
<div>{</div>
<div><span>"user_id"</span>: <span>"u123"</span>,</div>
<div><span>"target"</span>: <span>"post:456"</span>,</div>
<div><span>"value"</span>: <span>1</span>,</div>
<div><span>"idempotency_key"</span>: <span>"u123:post:456:v1"</span> <span>&larr; unique key</span></div>
<div>}</div>
</div>
<div>Redis:</div>
<div>
<div>
<code>SETNX idempotency:u123:post:456:v1</code>
<span>&rarr; 1 (success)</span>
</div>
<div>
<code>SETNX idempotency:u123:post:456:v1</code>
<span>&rarr; 0 (duplicate)</span>
</div>
</div>
</div>
</div>
</div>
<h3 id="2-hot-posts-problem">2. Hot Posts Problem</h3>
<!-- Hot Posts Handling Diagram -->
<div>
<div>
<div>
<span>Scenario:</span>
<span> Viral post with 100K comments/minute</span>
</div>
<div>
<span>Solution:</span>
<span> Tiered caching + sampling</span>
</div>
</div>
<div>
<div>HOT POST HANDLING</div>
<!-- Tier 1 -->
<div>
<div>
<div>Tier 1</div>
<div>Edge Cache (30s TTL)</div>
</div>
<div>
<span>Top 100 comments</span>
<span>Score approximation</span>
</div>
</div>
<!-- Tier 2 -->
<div>
<div>
<div>Tier 2</div>
<div>Regional Cache (5min TTL)</div>
</div>
<div>
<span>Full comment tree</span>
<span>Accurate scores</span>
</div>
</div>
<!-- Tier 3 -->
<div>
<div>
<div>Tier 3</div>
<div>Database</div>
</div>
<div>
<span>Source of truth</span>
</div>
</div>
<!-- Comment sampling -->
<div>
<div>Comment sampling for display:</div>
<div>
<div>&bull; Show top 200 only</div>
<div>&bull; "Load more" fetches from cache</div>
<div>&bull; Real-time updates via WebSocket</div>
</div>
</div>
</div>
</div>
<h3 id="3-subreddit-sharding">3. Subreddit Sharding</h3>
<pre><code>                        ```python
                        # Consistent hashing for subreddit sharding
                        class SubredditRouter:
                        def __init__(self, num_shards=256):
                        self.num_shards = num_shards
                        self.ring = ConsistentHashRing(num_shards)

                        def get_shard(self, subreddit_id):
                        # Hash subreddit ID to shard
                        return self.ring.get_node(str(subreddit_id))

                        def get_connection(self, subreddit_id):
                        shard = self.get_shard(subreddit_id)
                        return self.connections[shard]
                        ```
</code></pre>
</div>
<hr />
<h2 id="interview-deep-dive-questions">Interview Deep Dive Questions</h2>
<div>
<h3 id="1-why-not-show-real-time-vote-counts">1. &quot;Why not show real-time vote counts?&quot;</h3>
<div>
<p><strong>What They're Probing</strong>: Understanding of eventual consistency trade-offs, performance at scale, and user experience pragmatism.</p>
<p><strong>Strong Answer</strong>:</p>
<blockquote>
<p>&quot;Real-time vote counts at Reddit's scale (2B votes/day) would require synchronous writes and invalidation across all cache layers for every vote. The user doesn't actually need millisecond accuracy - seeing '1.2k upvotes' vs '1,247 upvotes' doesn't change behavior. We can batch vote aggregations every 100ms, giving us 10x write throughput while maintaining a 'feels real-time' experience. The key insight is that votes are high-write, low-consistency-requirement data - perfect for eventual consistency.&quot;</p>
</blockquote>
<p><strong>When Simpler Works</strong>:</p>
<blockquote>
<p>&quot;At 10K users, store vote counts directly in the post row. A PostgreSQL <code>UPDATE posts SET score = score + 1</code> with row-level locking handles hundreds of concurrent votes fine. Add Redis caching when you hit 1000+ votes/second on hot posts.&quot;</p>
</blockquote>
</div>
<h3 id="2-how-does-the-hot-ranking-algorithm-actually-work">2. &quot;How does the hot ranking algorithm actually work?&quot;</h3>
<div>
<p><strong>What They're Probing</strong>: Algorithm design thinking, understanding of decay functions, and ability to explain complex math simply.</p>
<p><strong>Strong Answer</strong>:</p>
<blockquote>
<p>&quot;Reddit's hot score combines logarithmic vote scaling with linear time decay. The formula <code>log10(score) + (timestamp / 45000)</code> means a post needs 10x more votes to overcome 12.5 hours of age. This creates natural content cycling - viral content rises fast but decays predictably. The logarithm prevents vote brigading from dominating (10,000 votes isn't 10x better than 1,000). I'd precompute hot scores on write, store in a sorted set, and recalculate periodically for older posts.&quot;</p>
</blockquote>
<p><strong>When Simpler Works</strong>:</p>
<blockquote>
<p>&quot;For a small community forum, <code>ORDER BY (upvotes - downvotes) * 0.5 + EXTRACT(EPOCH FROM created_at) / 86400</code> gives you decent hot ranking. Add a materialized view refreshed every 5 minutes. No Kafka, no precomputation needed until you're generating 10K+ posts/day.&quot;</p>
</blockquote>
</div>
<h3 id="3-why-separate-read-and-write-paths-for-voting">3. &quot;Why separate read and write paths for voting?&quot;</h3>
<div>
<p><strong>What They're Probing</strong>: CQRS understanding, performance optimization strategies, and recognizing when complexity pays off.</p>
<p><strong>Strong Answer</strong>:</p>
<blockquote>
<p>&quot;Votes have asymmetric read/write patterns: writes are bursty (viral posts), reads are constant (every page view shows scores). CQRS lets us optimize each path independently. Writes go to Kafka for buffering and batch processing - we can absorb 100K vote spikes without database pressure. Reads come from Redis with eventual consistency. The separation also enables different scaling: add more Kafka partitions for write throughput, add Redis replicas for read capacity. The key is the write path updates the read model asynchronously.&quot;</p>
</blockquote>
<p><strong>When Simpler Works</strong>:</p>
<blockquote>
<p>&quot;Below 1M monthly users, a single PostgreSQL instance handles both paths. Use <code>SELECT ... FOR UPDATE SKIP LOCKED</code> for vote deduplication, and application-level caching with a 30-second TTL. The complexity of CQRS adds operational overhead that isn't worth it until you're seeing clear database contention.&quot;</p>
</blockquote>
</div>
<h3 id="4-how-do-you-handle-the-thundering-herd-on-viral-posts">4. &quot;How do you handle the 'thundering herd' on viral posts?&quot;</h3>
<div>
<p><strong>What They're Probing</strong>: Cache stampede prevention, rate limiting strategies, and graceful degradation thinking.</p>
<p><strong>Strong Answer</strong>:</p>
<blockquote>
<p>&quot;Three-layer defense: First, probabilistic cache refresh - instead of all requests hitting DB when cache expires, use <code>if random() &lt; 0.01 and ttl &lt; 10s: refresh_async()</code>. Second, request coalescing - use a distributed lock so only one request fetches from DB while others wait on the same promise. Third, stale-while-revalidate - serve slightly stale data while refreshing in background. For truly viral posts (100K+ concurrent), we circuit-break to sampling mode: show top 200 comments only, disable real-time updates, and use edge caching with 30-second TTL.&quot;</p>
</blockquote>
<p><strong>When Simpler Works</strong>:</p>
<blockquote>
<p>&quot;For a forum with occasional popular threads, simple cache-aside with mutex is enough: <code>if cache miss: if acquire_lock(): fetch_and_cache() else: wait_for_cache()</code>. The singleflight pattern in Go or similar constructs handle this elegantly without distributed locks.&quot;</p>
</blockquote>
</div>
<h3 id="5-why-use-cassandra-for-votes-instead-of-postgresql">5. &quot;Why use Cassandra for votes instead of PostgreSQL?&quot;</h3>
<div>
<p><strong>What They're Probing</strong>: Database selection rationale, understanding of write patterns, and cost-benefit analysis.</p>
<p><strong>Strong Answer</strong>:</p>
<blockquote>
<p>&quot;Votes are append-heavy, time-series-like data with a simple access pattern: write once, read by user+target compound key. Cassandra excels here because: 1) Linear write scaling - add nodes for more throughput without sharding complexity. 2) Tunable consistency - we can use LOCAL_QUORUM for writes and ONE for reads. 3) Natural TTL support for vote history cleanup. 4) No single-point-of-failure - important when votes are happening 24/7. PostgreSQL would require manual sharding and has write amplification from its MVCC model that hurts at this scale.&quot;</p>
</blockquote>
<p><strong>When Simpler Works</strong>:</p>
<blockquote>
<p>&quot;PostgreSQL with a partitioned votes table (by month) handles 10M votes/day comfortably. Use <code>INSERT ... ON CONFLICT DO UPDATE</code> for idempotency. The operational simplicity of one database type beats Cassandra's performance until you're genuinely hitting PostgreSQL's write limits. I'd consider Cassandra only after seeing sustained 5K+ writes/second.&quot;</p>
</blockquote>
</div>
</div>
<hr />
<h2 id="why-this-technology">Why This Technology?</h2>
<div>
<h3 id="decision-matrix">Decision Matrix</h3>
<table>
<thead>
<tr>
<th>Decision Point</th>
<th>Options Considered</th>
<th>Chosen</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Vote Storage</strong></td>
<td>PostgreSQL, DynamoDB, Cassandra</td>
<td>Cassandra (scale) / PostgreSQL (start)</td>
<td>Write throughput at scale; start simple</td>
</tr>
<tr>
<td><strong>Comment Threading</strong></td>
<td>Adjacency List, Nested Sets, Closure Table, Materialized Path</td>
<td>Materialized Path</td>
<td>Balance of read/write performance; easy depth queries</td>
</tr>
<tr>
<td><strong>Feed Ranking</strong></td>
<td>Real-time calculation, Pre-computed scores, Hybrid</td>
<td>Hybrid with Redis Sorted Sets</td>
<td>Hot scores pre-computed on write; personalization at read time</td>
</tr>
<tr>
<td><strong>Caching Layer</strong></td>
<td>Memcached, Redis, Redis Cluster</td>
<td>Redis Cluster</td>
<td>Sorted sets for feeds, pub/sub for real-time, Lua for atomic ops</td>
</tr>
<tr>
<td><strong>Search</strong></td>
<td>PostgreSQL FTS, Elasticsearch, Algolia</td>
<td>Elasticsearch</td>
<td>Faceted search, relevance tuning, horizontal scaling</td>
</tr>
<tr>
<td><strong>Event Streaming</strong></td>
<td>RabbitMQ, Kafka, AWS Kinesis</td>
<td>Kafka</td>
<td>Replay capability, partitioning by subreddit, exactly-once semantics</td>
</tr>
</tbody>
</table>
<h3 id="technology-justification-deep-dive">Technology Justification Deep Dive</h3>
<div>
<p><strong>Why Materialized Path for Comments?</strong></p>
<!-- Alternatives Analysis Diagram -->
<div>
<div>Alternatives Analysis:</div>
<!-- Adjacency List -->
<div>
<div>
<div>Adjacency List (parent_id only)</div>
<div>
<div>
<span>PRO</span>
<span>Simple writes</span>
</div>
<div>
<span>CON</span>
<span>Recursive queries for tree loading (N+1 or CTE)</span>
</div>
<div>Good for: &lt; 100K comments, shallow nesting</div>
</div>
</div>
</div>
<!-- Nested Sets -->
<div>
<div>
<div>Nested Sets (left/right integers)</div>
<div>
<div>
<span>CON</span>
<span>Expensive writes (rebalancing)</span>
</div>
<div>
<span>PRO</span>
<span>Single query for subtrees</span>
</div>
<div>Good for: Read-heavy, rarely-changing trees</div>
</div>
</div>
</div>
<!-- Closure Table -->
<div>
<div>
<div>Closure Table (ancestor/descendant pairs)</div>
<div>
<div>
<span>CON</span>
<span>O(depth) storage overhead</span>
</div>
<div>
<span>PRO</span>
<span>Fast subtree queries</span>
</div>
<div>Good for: Deep trees with frequent subtree operations</div>
</div>
</div>
</div>
<!-- Materialized Path - CHOSEN -->
<div>
<div>
<div>
<div>Materialized Path ("/1/2/3/")</div>
<span>CHOSEN</span>
</div>
<div>
<div>
<span>PRO</span>
<span>Single-query subtree (LIKE 'path%')</span>
</div>
<div>
<span>PRO</span>
<span>Easy depth calculation (count slashes)</span>
</div>
<div>
<span>PRO</span>
<span>No joins needed</span>
</div>
<div>
<strong>Trade-off:</strong> Path length limits, string operations
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr />
<h2 id="when-simpler-solutions-work">When Simpler Solutions Work</h2>
<div>
<div>
<h3 id="postgresql-jsonb-for-comments">PostgreSQL JSONB for Comments</h3>
<div>
<p><strong>When It Works</strong>: Under 1M total comments, posts with &lt; 500 comments average</p>
<pre><code>                            ```sql
                            -- Store entire comment tree as JSONB
                            CREATE TABLE posts (
                            id SERIAL PRIMARY KEY,
                            title TEXT,
                            content TEXT,
                            comments JSONB DEFAULT '[]',  -- Denormalized tree
                            comment_count INT DEFAULT 0
                            );

                            -- Fetch post with all comments in one query
                            SELECT * FROM posts WHERE id = 123;

                            -- Add comment (PostgreSQL 14+)
                            UPDATE posts
                            SET comments = jsonb_insert(
                            comments,
                            '{0,replies,0}',  -- Path to insert
                            '{&quot;author&quot;: &quot;user1&quot;, &quot;text&quot;: &quot;Great post!&quot;, &quot;replies&quot;: []}'
                            )
                            WHERE id = 123;
                            ```
</code></pre>
<p><strong>Why It Breaks</strong>: JSONB updates rewrite the entire column. At 500+ comments, you're moving megabytes per comment. Switch to normalized tables with materialized path when you see post sizes exceeding 100KB regularly.</p>
</div>
<h3 id="when-you-dont-need-redis-for-votes">When You Don't Need Redis for Votes</h3>
<div>
<p><strong>When It Works</strong>: Under 100K daily active users, &lt; 1M votes/day</p>
<pre><code>                            ```sql
                            -- Votes directly in PostgreSQL
                            CREATE TABLE votes (
                            user_id INT,
                            post_id INT,
                            vote_type SMALLINT,  -- 1 or -1
                            PRIMARY KEY (user_id, post_id)
                            );

                            -- Atomic vote with score update
                            WITH vote_change AS (
                            INSERT INTO votes (user_id, post_id, vote_type)
                            VALUES (123, 456, 1)
                            ON CONFLICT (user_id, post_id) DO UPDATE
                            SET vote_type = EXCLUDED.vote_type
                            RETURNING
                            vote_type - COALESCE(
                            (SELECT vote_type FROM votes WHERE user_id = 123 AND post_id = 456),
                            0
                            ) as delta
                            )
                            UPDATE posts SET score = score + (SELECT delta FROM vote_change)
                            WHERE id = 456;
                            ```
</code></pre>
<p><strong>Why It Breaks</strong>: Row-level locks on hot posts cause contention. When you see <code>lock wait</code> times exceeding 50ms on popular posts, introduce Redis for optimistic counting with async reconciliation.</p>
</div>
<h3 id="simpler-alternatives-reference">Simpler Alternatives Reference</h3>
<div>
<table>
<thead>
<tr>
<th>Full Solution</th>
<th>Simpler Alternative</th>
<th>Switch When</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kafka + Vote Aggregator</td>
<td>PostgreSQL triggers</td>
<td>&gt; 5K votes/second sustained</td>
</tr>
<tr>
<td>Elasticsearch</td>
<td>PostgreSQL pg_trgm + GIN</td>
<td>&gt; 10M searchable posts</td>
</tr>
<tr>
<td>Redis Sorted Sets for feeds</td>
<td>Materialized views</td>
<td>&gt; 1M feed generations/day</td>
</tr>
<tr>
<td>Cassandra for votes</td>
<td>Partitioned PostgreSQL</td>
<td>&gt; 50M votes/day</td>
</tr>
<tr>
<td>CDN + Edge caching</td>
<td>Nginx proxy_cache</td>
<td>&gt; 10K requests/second</td>
</tr>
<tr>
<td>Microservices</td>
<td>Modular monolith</td>
<td>Team &gt; 20 engineers</td>
</tr>
</tbody>
</table>
</div>
<h3 id="the-300month-forum">The $300/month Forum</h3>
<div>
<p><strong>Scenario</strong>: 50K monthly users, 1K posts/day, 10K comments/day</p>
<pre><code>                            ```
                            Architecture:
                            ├── Single $150/month managed PostgreSQL (db.t3.medium)
                            │   ├── Posts, comments, votes, users - all in one DB
                            │   ├── Materialized view for hot feed (refresh every 5 min)
                            │   └── pg_trgm extension for search
                            │
                            ├── $100/month application server (2 vCPU, 4GB RAM)
                            │   ├── Rails/Django/Next.js monolith
                            │   ├── In-process caching (Rails.cache / Django cache)
                            │   └── Background jobs for email, notifications
                            │
                            ├── $50/month Redis (cache.t3.micro)
                            │   ├── Session storage
                            │   ├── Rate limiting
                            │   └── Hot post cache
                            │
                            └── Cloudflare Free Tier
                            ├── CDN for static assets
                            └── Basic DDoS protection

                            Performance Expectations:
                            - 500 concurrent users: No problem
                            - 100ms average response time
                            - Search across 100K posts: &lt; 200ms
                            - Comment threads 1000 deep: Works with recursive CTE
                            ```
</code></pre>
<p><strong>Growth Triggers</strong>:<br />
- Database CPU &gt; 70% sustained → Add read replica<br />
- Application memory &gt; 3GB → Upgrade or add instance<br />
- Redis hit rate &lt; 80% → Increase cache size<br />
- Search latency &gt; 500ms → Consider Elasticsearch</p>
</div>
</div>
</div>
<hr />
<h2 id="trade-off-analysis--mitigation">Trade-off Analysis &amp; Mitigation</h2>
<div>
<h3 id="core-trade-offs">Core Trade-offs</h3>
<div>
<table>
<thead>
<tr>
<th>Trade-off</th>
<th>Choice Made</th>
<th>What We Lose</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Vote Consistency</strong></td>
<td>Eventual (100ms lag)</td>
<td>Real-time accuracy</td>
<td>Optimistic UI updates; reconcile on refresh</td>
</tr>
<tr>
<td><strong>Comment Loading</strong></td>
<td>Lazy load children</td>
<td>Full tree view</td>
<td>&quot;Load more replies&quot; with prefetch hints</td>
</tr>
<tr>
<td><strong>Feed Freshness</strong></td>
<td>60s cache TTL</td>
<td>Instant new post visibility</td>
<td>WebSocket push for subscribed subreddits</td>
</tr>
<tr>
<td><strong>Search Indexing</strong></td>
<td>Async (5-30s delay)</td>
<td>Immediate searchability</td>
<td>Show &quot;Post submitted&quot; with direct link</td>
</tr>
<tr>
<td><strong>Media Processing</strong></td>
<td>Async transcode</td>
<td>Immediate media display</td>
<td>Progressive loading with blur placeholder</td>
</tr>
</tbody>
</table>
</div>
<h3 id="mitigation-strategies-deep-dive">Mitigation Strategies Deep Dive</h3>
<div>
<pre><code>                          ```
                          EVENTUAL CONSISTENCY MITIGATION
                          ================================

                          Problem: User votes, refreshes, doesn't see their vote

                          Solutions (layered):
                          ├── 1. Optimistic UI
                          │   └── Immediately show vote in client state
                          │
                          ├── 2. Write-through to session
                          │   └── Store user's recent votes in Redis session
                          │   └── Merge with server response: user_votes ∪ cached_votes
                          │
                          ├── 3. Read-your-writes consistency
                          │   └── After write, read from primary for 5 seconds
                          │   └── Cookie: &quot;last_write_ts=1234567890&quot;
                          │
                          └── 4. Sticky sessions for hot content
                          └── Route user to same cache node for 60s
                          └── Ensures they see their own writes

                          CACHE INVALIDATION STRATEGY
                          ===========================

                          Problem: Stale feeds, outdated scores, phantom content

                          Approach: Event-driven selective invalidation

                          post.created →
                          ├── Invalidate subreddit feed cache
                          ├── Invalidate author's profile cache
                          └── Queue for follower feed fan-out

                          post.voted →
                          ├── Update score in sorted set (not invalidate)
                          └── Rerank only if score crosses threshold

                          comment.created →
                          ├── Increment post.comment_count (atomic)
                          ├── Invalidate post detail cache
                          └── Don't touch feed caches (count is denormalized)
                          ```
</code></pre>
</div>
<h3 id="failure-modes--recovery">Failure Modes &amp; Recovery</h3>
<div>
<table>
<thead>
<tr>
<th>Failure</th>
<th>Impact</th>
<th>Detection</th>
<th>Recovery</th>
</tr>
</thead>
<tbody>
<tr>
<td>Redis cluster down</td>
<td>No caching, DB overload</td>
<td>Health checks, latency spike</td>
<td>Circuit breaker → serve stale, shed load</td>
</tr>
<tr>
<td>Kafka lag &gt; 10s</td>
<td>Vote counts delayed</td>
<td>Consumer lag metrics</td>
<td>Scale consumers, increase batch size</td>
</tr>
<tr>
<td>PostgreSQL replica lag</td>
<td>Stale reads</td>
<td>Replication lag monitor</td>
<td>Route to primary, alert on-call</td>
</tr>
<tr>
<td>S3 unavailable</td>
<td>No media</td>
<td>5xx from CloudFront</td>
<td>Serve placeholder, queue retry</td>
</tr>
<tr>
<td>Elasticsearch down</td>
<td>Search broken</td>
<td>Health endpoint</td>
<td>Fallback to PostgreSQL pg_trgm</td>
</tr>
</tbody>
</table>
</div>
</div>
<hr />
<h2 id="interview-tips">Interview Tips</h2>
<div>
<h3 id="key-discussion-points">Key Discussion Points</h3>
<ol>
<li><strong>Vote count accuracy</strong>: Eventual consistency is acceptable - users don't need millisecond precision</li>
<li><strong>Feed personalization</strong>: Balance relevance vs freshness vs diversity - avoid filter bubbles</li>
<li><strong>Spam detection</strong>: Layered approach - rate limits → heuristics → ML → community reports</li>
<li><strong>Rate limiting</strong>: Token bucket per-user, sliding window per-IP, separate limits for reads/writes</li>
<li><strong>Moderation at scale</strong>: Automod rules + ML flagging + human review queue with SLAs</li>
</ol>
<h3 id="common-follow-ups">Common Follow-ups</h3>
<pre><code>                        - **&quot;How would you handle a subreddit going viral?&quot;** → Edge caching, request coalescing, graceful degradation
                        - **&quot;How do you prevent vote manipulation?&quot;** → Device fingerprinting, velocity limits, graph analysis for bot rings
                        - **&quot;How would you implement Reddit Premium?&quot;** → Feature flags, separate CDN tier, no-ads rendering path
</code></pre>
<h3 id="red-flags-to-avoid">Red Flags to Avoid</h3>
<div>
<table>
<thead>
<tr>
<th>Red Flag</th>
<th>Why It's Bad</th>
<th>Better Approach</th>
</tr>
</thead>
<tbody>
<tr>
<td>&quot;We need Kafka from day one&quot;</td>
<td>Over-engineering; PostgreSQL LISTEN/NOTIFY works for 90% of cases</td>
<td>&quot;Start with PostgreSQL notifications, add Kafka when we need replay or multi-consumer&quot;</td>
</tr>
<tr>
<td>&quot;Microservices because Netflix uses them&quot;</td>
<td>Cargo culting; ignores team size and operational cost</td>
<td>&quot;Modular monolith with clear boundaries, extract services when team/scale demands&quot;</td>
</tr>
<tr>
<td>&quot;Real-time vote counts via WebSocket&quot;</td>
<td>Massive fan-out cost for low-value feature</td>
<td>&quot;Polling with smart refresh, WebSocket only for user's own actions&quot;</td>
</tr>
<tr>
<td>&quot;Shard by user_id for everything&quot;</td>
<td>Wrong access patterns; posts are accessed by subreddit, not author</td>
<td>&quot;Shard votes by post_id, posts by subreddit, users stay unsharded longest&quot;</td>
</tr>
<tr>
<td>&quot;NoSQL because we need scale&quot;</td>
<td>SQL scales fine with proper indexing and read replicas</td>
<td>&quot;PostgreSQL to 10TB, evaluate migration at clear pain points&quot;</td>
</tr>
<tr>
<td>&quot;Cache everything for 1 hour&quot;</td>
<td>Stale data, cache invalidation nightmares</td>
<td>&quot;Tiered TTLs based on data volatility: user profiles 1hr, feeds 60s, scores 5s&quot;</td>
</tr>
</tbody>
</table>
</div>
<h3 id="impressive-statements">Impressive Statements</h3>
<div>
<table>
<thead>
<tr>
<th>Topic</th>
<th>Statement</th>
<th>Why It Impresses</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Consistency</strong></td>
<td>&quot;For votes, we can accept a 100ms consistency window because the UX cost of stronger consistency exceeds the value of real-time accuracy&quot;</td>
<td>Shows cost-benefit thinking, not just technical knowledge</td>
</tr>
<tr>
<td><strong>Scaling</strong></td>
<td>&quot;I'd keep everything in PostgreSQL until we see specific bottlenecks - premature optimization with specialized databases adds operational complexity without proven benefit&quot;</td>
<td>Demonstrates pragmatism and operational awareness</td>
</tr>
<tr>
<td><strong>Caching</strong></td>
<td>&quot;Cache invalidation is harder than caching - I'd use event-driven selective invalidation rather than TTL-based expiry to maintain consistency guarantees&quot;</td>
<td>Shows deep understanding of distributed systems challenges</td>
</tr>
<tr>
<td><strong>Trade-offs</strong></td>
<td>&quot;The hot ranking formula trades computational complexity for content freshness - we precompute on write to shift work from the read path&quot;</td>
<td>Demonstrates understanding of read/write trade-offs</td>
</tr>
<tr>
<td><strong>Failure modes</strong></td>
<td>&quot;When Redis fails, we circuit-break to database with rate limiting rather than complete outage - graceful degradation over hard failure&quot;</td>
<td>Shows production mindset and resilience thinking</td>
</tr>
<tr>
<td><strong>Growth</strong></td>
<td>&quot;At 10K users, I'd use PostgreSQL JSONB for comments. At 1M, normalize to tables with materialized paths. At 100M, consider comment service with Cassandra&quot;</td>
<td>Demonstrates ability to right-size solutions</td>
</tr>
</tbody>
</table>
</div>
<h3 id="closing-strong">Closing Strong</h3>
<div>
<p><strong>&quot;What would you build first?&quot;</strong></p>
<blockquote>
<p>&quot;The core voting and feed loop - that's Reddit's flywheel. A user can vote, see updated scores, and get a personalized feed. Everything else (awards, chat, video) are features on top. I'd nail the data model for posts, comments, and votes, get the hot ranking working, then iterate. Shipping a working MVP in PostgreSQL + Redis beats architecting a perfect distributed system that takes 6 months to build.&quot;</p>
</blockquote>
<p><strong>&quot;Where does this design break?&quot;</strong></p>
<blockquote>
<p>&quot;Three places: First, single-subreddit hotspots - r/all or viral AMAs can overwhelm any caching strategy; we'd need request sampling and edge compute. Second, real-time features like chat and live threads require WebSocket infrastructure we haven't designed. Third, global latency - this design assumes single-region; multi-region would need conflict resolution for votes and eventually consistent subreddit state.&quot;</p>
</blockquote>
</div>
</div>
