<h1 id="design-a-parking-system">Design a Parking System</h1>
<h2 id="problem-statement">Problem Statement</h2>
<p>Design a smart parking management system for multi-level parking lots with real-time availability, reservations, and payments.</p>
<div>
<h3 id="core-requirements">Core Requirements</h3>
<ul>
<li><strong>Spot Management</strong>: Track available/occupied spots</li>
<li><strong>Vehicle Entry/Exit</strong>: Automated ticketing</li>
<li><strong>Reservations</strong>: Book spots in advance</li>
<li><strong>Payments</strong>: Time-based or flat-rate billing</li>
<li><strong>Different Vehicle Types</strong>: Compact, regular, large, handicap</li>
<li><strong>Real-time Display</strong>: Show availability per level</li>
</ul>
</div>
<hr />
<h2 id="core-concepts-overview">Core Concepts Overview</h2>
<div>
<h4>Fundamental Parking System Equation</h4>
<div>
Parking System = <span>Spot Allocation</span> + <span>Sensor Integration</span> + <span>Payment Processing</span> + <span>Real-time Availability</span> + <span>Dynamic Pricing</span>
</div>
</div>
<p><strong>Critical Assumption</strong>: The system assumes <span>eventual consistency</span> is acceptable for spot availability displays - a spot shown as available might be taken by the time the driver arrives. True real-time accuracy would require prohibitively expensive per-spot sensors.</p>
<p><strong>Key Trade-off</strong>: <span>Sensor granularity vs. cost</span>. Per-spot sensors provide accurate &quot;find my car&quot; features but cost $50-150 per spot. Entry/exit counters cost $500 total but only provide aggregate availability. See <a href="/topics/system-design/connection-pooling">[connection-pooling]</a> for similar resource management patterns.</p>
<hr />
<h2 id="high-level-architecture">High-Level Architecture</h2>
<div>
<h3>PARKING SYSTEM ARCHITECTURE</h3>
  <!-- Entry/Exit Gates Layer -->
<div>
<div>ENTRY/EXIT GATES</div>
<div>
<div>
<div>
<div>Camera/LPR</div>
</div>
<div>&#8595;</div>
<div>
<div>Entry Kiosk</div>
</div>
</div>
<div>
<div>
<div>Camera/LPR</div>
</div>
<div>&#8595;</div>
<div>
<div>Exit Kiosk</div>
</div>
</div>
</div>
</div>
  <!-- Arrow Down -->
<div>&#8595;</div>
  <!-- Parking Service Layer -->
<div>
<div>PARKING SERVICE</div>
<div>
<div>
<span>Spot Management</span>
</div>
<div>
<span>Ticket/Session</span>
</div>
<div>
<span>Reservations</span>
</div>
<div>
<span>Payments</span>
</div>
</div>
</div>
  <!-- Arrow Down -->
<div>&#8595;</div>
  <!-- Data Layer -->
<div>
<div>
<div>PostgreSQL</div>
<div>(Data)</div>
</div>
<div>
<div>Redis</div>
<div>(Cache)</div>
</div>
<div>
<div>Display Boards</div>
<div>(Real-time)</div>
</div>
</div>
</div>
<hr />
<h2 id="section-1-spot-allocation">Section 1: Spot Allocation</h2>
<h3 id="deep-mechanics">Deep Mechanics</h3>
<p><span>Spot allocation</span> is the process of assigning parking spaces to vehicles based on vehicle type, availability, and optimization goals. The core challenge is matching vehicle dimensions to spot types while considering business objectives like maximizing utilization or minimizing walking distance.</p>
<div>
<h4>Spot Allocation Decision Hierarchy</h4>
<div>
<div>
<strong>1. Vehicle Type Compatibility</strong>
<p>Match vehicle to spot size. Larger spots can accommodate smaller vehicles (LARGE spot fits COMPACT car) but not vice versa. This creates the <span>size compatibility matrix</span>.</p>
</div>
<div>
<strong>2. Availability Check</strong>
<p>Query available spots by type with <span>optimistic locking</span> to prevent race conditions. See [[distributed-locking]](/topics/system-design/distributed-locking) for implementation patterns.</p>
</div>
<div>
<strong>3. Allocation Strategy</strong>
<p>Apply business rules: nearest to entrance, distribute across levels, or preserve larger spots for appropriate vehicles.</p>
</div>
<div>
<strong>4. Reservation Conflict Resolution</strong>
<p>Handle overlap between walk-in vehicles and pre-reserved spots. Requires <span>temporal availability checking</span> across time windows.</p>
</div>
</div>
</div>
<h3 id="spot-allocation-architecture">Spot Allocation Architecture</h3>
<div>
<h4>SPOT ALLOCATION FLOW</h4>
  <!-- Vehicle Entry -->
<div>
<div>
<span>Vehicle Entry Request</span>
<div>{license_plate, vehicle_type}</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Allocation Engine -->
<div>
<div>ALLOCATION ENGINE</div>
<div>
<div>
<div>Compatibility Check</div>
<div>Match vehicle to spot types</div>
</div>
<div>
<div>Availability Query</div>
<div>Redis cache + DB fallback</div>
</div>
<div>
<div>Strategy Selection</div>
<div>Nearest/Spread/Compact-first</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Allocation Result -->
<div>
<div>
<div>Success: Spot Assigned</div>
<div>Create ticket, mark spot occupied</div>
</div>
<div>
<div>Failure: Lot Full</div>
<div>Redirect to nearby lot or waitlist</div>
</div>
</div>
</div>
<h3 id="spot-allocation-strategies-implementation">Spot Allocation Strategies Implementation</h3>
<pre><code class="language-python">class SpotAllocationStrategy:
    &quot;&quot;&quot;
    Production-grade spot allocation with multiple strategies.

    Key Insight: Most lots don't need per-spot tracking. A simple counter
    by vehicle type is sufficient unless you need &quot;find my car&quot; features.
    &quot;&quot;&quot;

    def __init__(self, lot_id: str, cache: Redis, db: Database):
        self.lot_id = lot_id
        self.cache = cache
        self.db = db

    def get_compatible_types(self, vehicle_type: str) -&gt; List[str]:
        &quot;&quot;&quot;
        Larger spots can accommodate smaller vehicles.
        This is the core compatibility matrix.
        &quot;&quot;&quot;
        compatibility = {
            'MOTORCYCLE': ['MOTORCYCLE', 'COMPACT', 'REGULAR', 'LARGE'],
            'COMPACT': ['COMPACT', 'REGULAR', 'LARGE'],
            'REGULAR': ['REGULAR', 'LARGE'],
            'LARGE': ['LARGE'],
            'EV': ['EV'],  # EV spots are exclusive (charging)
            'HANDICAP': ['HANDICAP'],  # Restricted access
        }
        return compatibility.get(vehicle_type, [])

    def allocate_nearest_entrance(self, vehicle_type: str) -&gt; Optional[Spot]:
        &quot;&quot;&quot;
        Strategy 1: Minimize walking distance.
        Best for: Short-term parking, mall visitors.

        Trade-off: Creates hotspots near entrance, uneven wear.
        &quot;&quot;&quot;
        compatible_types = self.get_compatible_types(vehicle_type)

        # Query spots ordered by distance to entrance
        available_spots = self.db.query(&quot;&quot;&quot;
            SELECT * FROM spots
            WHERE lot_id = %s
            AND spot_type IN %s
            AND status = 'AVAILABLE'
            ORDER BY distance_to_entrance ASC
            LIMIT 1
            FOR UPDATE SKIP LOCKED
        &quot;&quot;&quot;, (self.lot_id, tuple(compatible_types)))

        return available_spots[0] if available_spots else None

    def allocate_spread_across_levels(self, vehicle_type: str) -&gt; Optional[Spot]:
        &quot;&quot;&quot;
        Strategy 2: Distribute load across levels.
        Best for: Large garages, event parking.

        Trade-off: May increase walking distance but improves traffic flow.
        &quot;&quot;&quot;
        compatible_types = self.get_compatible_types(vehicle_type)

        # Find level with lowest occupancy
        level_occupancy = self.cache.hgetall(f&quot;lot:{self.lot_id}:level_occupancy&quot;)
        least_occupied_level = min(level_occupancy.items(), key=lambda x: float(x[1]))[0]

        available_spots = self.db.query(&quot;&quot;&quot;
            SELECT * FROM spots
            WHERE lot_id = %s
            AND level_id = %s
            AND spot_type IN %s
            AND status = 'AVAILABLE'
            LIMIT 1
            FOR UPDATE SKIP LOCKED
        &quot;&quot;&quot;, (self.lot_id, least_occupied_level, tuple(compatible_types)))

        return available_spots[0] if available_spots else None

    def allocate_preserve_larger_spots(self, vehicle_type: str) -&gt; Optional[Spot]:
        &quot;&quot;&quot;
        Strategy 3: Exact match first, preserve larger spots.
        Best for: Mixed vehicle populations, maximizing capacity.

        Trade-off: Small vehicles may park further from entrance.
        &quot;&quot;&quot;
        compatible_types = self.get_compatible_types(vehicle_type)

        # Try exact match first
        for spot_type in compatible_types:
            spot = self._find_spot_by_type(spot_type)
            if spot:
                return spot

        return None

    def allocate_with_reservation_awareness(
        self,
        vehicle_type: str,
        arrival_time: datetime,
        expected_duration: timedelta
    ) -&gt; Optional[Spot]:
        &quot;&quot;&quot;
        Strategy 4: Consider future reservations.
        Best for: Premium lots with advance booking.

        This prevents allocating a spot to a walk-in that will
        conflict with an upcoming reservation.
        &quot;&quot;&quot;
        compatible_types = self.get_compatible_types(vehicle_type)
        expected_exit = arrival_time + expected_duration

        # Find spots without conflicting reservations
        available_spots = self.db.query(&quot;&quot;&quot;
            SELECT s.* FROM spots s
            WHERE s.lot_id = %s
            AND s.spot_type IN %s
            AND s.status = 'AVAILABLE'
            AND NOT EXISTS (
                SELECT 1 FROM reservations r
                WHERE r.spot_id = s.id
                AND r.status = 'CONFIRMED'
                AND r.start_time &lt; %s
                AND r.end_time &gt; %s
            )
            ORDER BY s.distance_to_entrance ASC
            LIMIT 1
            FOR UPDATE SKIP LOCKED
        &quot;&quot;&quot;, (self.lot_id, tuple(compatible_types), expected_exit, arrival_time))

        return available_spots[0] if available_spots else None
</code></pre>
<h3 id="spot-allocation-interview-questions-3-levels-deep">Spot Allocation Interview Questions (3 Levels Deep)</h3>
<div>
<h4>Level 1: How would you design spot allocation for a parking system?</h4>
<p><strong>Answer:</strong> Spot allocation matches vehicles to available parking spaces based on <span>vehicle type compatibility</span> and <span>allocation strategy</span>. The basic flow is: (1) identify vehicle type from entry input, (2) query available spots that can accommodate that vehicle size, (3) apply an allocation strategy like "nearest to entrance" or "distribute across levels", (4) atomically assign the spot and create a parking ticket. The key data structures are a spot availability cache for fast lookups and a database with proper locking for consistent assignment.</p>
<div>
<h5>Level 2: How do you handle concurrent allocation requests to prevent double-booking?</h5>
<p><strong>Answer:</strong> Concurrent allocation requires <span>optimistic locking</span> or <span>pessimistic locking</span> depending on contention levels. For low-contention scenarios (most parking lots), I'd use database-level `SELECT FOR UPDATE SKIP LOCKED` - this locks the row being allocated and skips already-locked rows, allowing parallel processing. For high-contention scenarios during events, I'd use Redis-based distributed locks with TTL (see [[distributed-locking]](/topics/system-design/distributed-locking)). The critical insight is that most lots don't actually allocate specific spots - they just decrement a counter atomically, which sidesteps the entire problem.</p>
<div>
<h6>Level 3: How would you handle allocation when reservations conflict with walk-in vehicles?</h6>
<p><strong>Answer:</strong> Reservation-aware allocation requires <span>temporal availability checking</span>. When a walk-in arrives, we must check not just current availability but also upcoming reservations. Implementation: (1) estimate expected parking duration from historical data or user input, (2) query spots that are both currently available AND have no conflicting reservations within the expected window, (3) if no spots meet both criteria, offer a spot with a "you may need to move" warning, or redirect to a different lot. Edge case: if the walk-in overstays into a reservation window, trigger a notification for lot attendants. Trade-off: strict enforcement creates better reservation experience but risks empty spots when reservations no-show. Many lots solve this by over-allocating (allowing 110% reservation capacity) based on historical no-show rates. This is similar to [[event-sourcing]](/topics/system-design/event-sourcing) patterns where we track events to reconstruct availability at any point in time.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-2-sensor-integration">Section 2: Sensor Integration</h2>
<h3 id="deep-mechanics-1">Deep Mechanics</h3>
<p><span>Sensor integration</span> connects physical detection hardware to the software system for real-time occupancy tracking. The fundamental trade-off is between <span>detection granularity</span> (per-spot vs. entry/exit counters) and cost/complexity.</p>
<div>
<h4>Sensor Technology Comparison</h4>
<div>
<div>
<strong>Ultrasonic Sensors</strong>
<p>$50-100/spot. Ceiling-mounted, detect presence by sound reflection. 99% accuracy. Require wiring infrastructure.</p>
</div>
<div>
<strong>Magnetic Sensors</strong>
<p>$80-150/spot. Embedded in pavement, detect metal mass. 97% accuracy. Battery-powered (5-year life), wireless.</p>
</div>
<div>
<strong>Camera + ML</strong>
<p>$200-500/camera covering 10-20 spots. Requires ML processing. Also enables LPR, security footage.</p>
</div>
</div>
</div>
<h3 id="sensor-integration-architecture">Sensor Integration Architecture</h3>
<div>
<h4>SENSOR DATA PIPELINE</h4>
  <!-- Sensor Layer -->
<div>
<div>PHYSICAL SENSORS</div>
<div>
<div>
<div>Entry Loop</div>
<div>Inductive coil</div>
</div>
<div>
<div>Exit Loop</div>
<div>Inductive coil</div>
</div>
<div>
<div>LPR Camera</div>
<div>License plate OCR</div>
</div>
<div>
<div>Spot Sensors</div>
<div>Ultrasonic/Magnetic</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Edge Controller -->
<div>
<div>EDGE CONTROLLER (Local Processing)</div>
<div>
<div>
<div>Signal Processing</div>
<div>Debounce, filter noise</div>
</div>
<div>
<div>Local State</div>
<div>Offline operation</div>
</div>
<div>
<div>Event Batching</div>
<div>Reduce cloud traffic</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- MQTT/Cloud Layer -->
<div>
<div>
<div>MQTT Broker</div>
<div>IoT message transport</div>
<div>Topics: lot/+/spot/+/status</div>
</div>
<div>
<div>Event Processor</div>
<div>Update cache + DB</div>
<div>Idempotent event handling</div>
</div>
</div>
</div>
<h3 id="sensor-data-processing-implementation">Sensor Data Processing Implementation</h3>
<pre><code class="language-python">class SensorEventProcessor:
    &quot;&quot;&quot;
    Process sensor events with reliability guarantees.

    Key Challenges:
    1. Debouncing: Rapid on/off signals when vehicle enters slowly
    2. Failure detection: Differentiate sensor failure from empty spot
    3. Reconciliation: Sync edge state with cloud after offline period
    &quot;&quot;&quot;

    def __init__(self, cache: Redis, db: Database, mqtt: MQTTClient):
        self.cache = cache
        self.db = db
        self.mqtt = mqtt
        self.debounce_window = timedelta(seconds=3)

    async def handle_spot_event(self, event: SpotEvent):
        &quot;&quot;&quot;
        Process individual spot sensor events.

        Event structure:
        {
            &quot;lot_id&quot;: &quot;LOT-001&quot;,
            &quot;spot_id&quot;: &quot;A-15&quot;,
            &quot;status&quot;: &quot;OCCUPIED&quot;,  # or &quot;AVAILABLE&quot;
            &quot;timestamp&quot;: &quot;2024-01-15T10:30:00Z&quot;,
            &quot;sensor_type&quot;: &quot;ultrasonic&quot;,
            &quot;confidence&quot;: 0.98,  # ML-based sensors report confidence
            &quot;event_id&quot;: &quot;uuid&quot;  # For idempotency
        }
        &quot;&quot;&quot;
        # Idempotency check - prevent duplicate processing
        if await self._is_duplicate_event(event.event_id):
            return

        # Debounce rapid state changes
        last_event = await self._get_last_event(event.lot_id, event.spot_id)
        if last_event and (event.timestamp - last_event.timestamp) &lt; self.debounce_window:
            # Too fast - likely sensor noise or slow-moving vehicle
            await self._queue_for_confirmation(event)
            return

        # Low confidence events require additional verification
        if event.confidence &lt; 0.9:
            await self._trigger_verification(event)
            return

        # Process confirmed state change
        await self._update_spot_status(event)
        await self._update_availability_cache(event.lot_id)
        await self._publish_availability_update(event.lot_id)

    async def _update_spot_status(self, event: SpotEvent):
        &quot;&quot;&quot;Atomic spot status update with audit trail.&quot;&quot;&quot;
        async with self.db.transaction():
            # Update spot
            await self.db.execute(&quot;&quot;&quot;
                UPDATE spots
                SET status = %s,
                    last_sensor_update = %s,
                    sensor_confidence = %s
                WHERE lot_id = %s AND spot_id = %s
            &quot;&quot;&quot;, (event.status, event.timestamp, event.confidence,
                  event.lot_id, event.spot_id))

            # Record event for audit/reconciliation
            await self.db.execute(&quot;&quot;&quot;
                INSERT INTO spot_events (lot_id, spot_id, status, timestamp, sensor_type, event_id)
                VALUES (%s, %s, %s, %s, %s, %s)
                ON CONFLICT (event_id) DO NOTHING
            &quot;&quot;&quot;, (event.lot_id, event.spot_id, event.status,
                  event.timestamp, event.sensor_type, event.event_id))

    async def reconcile_after_offline(self, lot_id: str, edge_state: Dict):
        &quot;&quot;&quot;
        Reconcile cloud state with edge controller after network outage.

        Strategy: Edge controller is authoritative for sensor state.
        Cloud may have stale data during outage.
        &quot;&quot;&quot;
        for spot_id, spot_state in edge_state.items():
            cloud_state = await self._get_cloud_spot_state(lot_id, spot_id)

            if cloud_state.last_update &lt; spot_state.last_update:
                # Edge has newer data - update cloud
                await self._update_spot_status(SpotEvent(
                    lot_id=lot_id,
                    spot_id=spot_id,
                    status=spot_state.status,
                    timestamp=spot_state.last_update,
                    sensor_type='reconciliation',
                    confidence=1.0,
                    event_id=f&quot;reconcile-{lot_id}-{spot_id}-{spot_state.last_update}&quot;
                ))
</code></pre>
<h3 id="sensor-integration-interview-questions-3-levels-deep">Sensor Integration Interview Questions (3 Levels Deep)</h3>
<div>
<h4>Level 1: What sensors would you use for a parking system?</h4>
<p><strong>Answer:</strong> The choice depends on requirements and budget. For basic occupancy tracking, <span>entry/exit inductive loop sensors</span> ($500 total) count vehicles entering and leaving - sufficient for aggregate availability. For per-spot tracking, <span>ultrasonic sensors</span> ($50-100/spot) or <span>magnetic sensors</span> ($80-150/spot) detect individual spot occupancy. For premium features like license plate recognition and security, <span>cameras with ML processing</span> can cover multiple spots per camera. Most successful parking systems start with entry/exit counters and add per-spot sensors only when the business case justifies it (premium lots, "find my car" features).</p>
<div>
<h5>Level 2: How do you handle sensor failures without corrupting availability data?</h5>
<p><strong>Answer:</strong> Sensor failure handling requires <span>confidence degradation</span> and <span>cross-validation</span>. Implementation: (1) Track "last seen" timestamp per sensor - if no heartbeat for X minutes, mark sensor as potentially failed. (2) Degrade confidence in that spot's status over time - after 30 minutes stale, show "unknown" status in UI. (3) Cross-validate with entry/exit counters - if counter says lot has 50 cars but sensors show 45 occupied spots, flag discrepancy. (4) For camera-based systems, use multiple frame confirmation before state change. (5) During sensor failure, fall back to entry/exit counter math for that zone. The key insight is to <span>never trust a single data source</span> - always have a backup validation method. See [[circuit-breaker]](/topics/system-design/circuit-breaker) patterns for handling degraded components.</p>
<div>
<h6>Level 3: How would you design the edge-to-cloud synchronization to handle intermittent connectivity?</h6>
<p><strong>Answer:</strong> Edge-cloud sync requires an <span>event sourcing</span> approach where the edge controller is authoritative for physical state. Implementation: (1) Edge controller maintains a local event log of all sensor state changes with monotonically increasing sequence numbers. (2) During connectivity, events stream to cloud via MQTT with QoS 1 (at-least-once delivery). (3) Cloud processes events <span>idempotently</span> using event_id for deduplication. (4) After outage, edge sends all events since last acknowledged sequence number. (5) Cloud reconciles by replaying events in order - edge timestamp is authoritative, not cloud receive time. Edge case: If entry/exit counters drift from per-spot sensors during long outage, trigger manual reconciliation via attendant walk-through or camera snapshot. Trade-off: Strong consistency would require blocking gate operations during outage - unacceptable. We accept eventual consistency for reporting while maintaining operational autonomy. This is the same pattern used in [[event-sourcing]](/topics/system-design/event-sourcing) for distributed systems.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-3-payment-processing">Section 3: Payment Processing</h2>
<h3 id="deep-mechanics-2">Deep Mechanics</h3>
<p><span>Payment processing</span> in parking systems involves calculating fees based on duration, processing transactions, and handling edge cases like failed payments or network outages. The fundamental principle is: <span>never trap a car</span> - revenue recovery is easier than managing traffic jams from stuck vehicles.</p>
<div>
<h4>Payment Processing Principles</h4>
<div>
<div>
<strong>1. Separation of Concerns</strong>
<p>Parking session lifecycle is independent of payment status. A car can exit even with payment pending - chase the money later, not the vehicle.</p>
</div>
<div>
<strong>2. Idempotent Transactions</strong>
<p>Network failures cause retries. Payment requests must be <span>idempotent</span> - same request produces same result. Use idempotency keys. See [[api-design]](/topics/system-design/api-design).</p>
</div>
<div>
<strong>3. Authorization vs. Capture</strong>
<p>For reservations and expected long stays, authorize at entry but capture only at exit when final amount is known.</p>
</div>
</div>
</div>
<h3 id="payment-processing-architecture">Payment Processing Architecture</h3>
<div>
<h4>PAYMENT PROCESSING FLOW</h4>
  <!-- Fee Calculation -->
<div>
<div>
<div>Fee Calculation Engine</div>
<div>Duration + Rate Rules + Discounts</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Payment Methods -->
<div>
<div>PAYMENT CHANNELS</div>
<div>
<div>
<div>Exit Kiosk</div>
<div>Card/Cash</div>
</div>
<div>
<div>Mobile App</div>
<div>Apple/Google Pay</div>
</div>
<div>
<div>Pre-Registration</div>
<div>Saved card</div>
</div>
<div>
<div>Validation</div>
<div>Business pays</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Payment Gateway -->
<div>
<div>
<div>Stripe/Square</div>
<div>Primary processor</div>
</div>
<div>
<div>Local POS</div>
<div>Offline fallback</div>
</div>
<div>
<div>Invoice System</div>
<div>Failed payment recovery</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Transaction Result -->
<div>
<div>
<div>Success</div>
<div>Open gate, close ticket</div>
</div>
<div>
<div>Failure</div>
<div>Flag plate, open gate anyway, invoice</div>
</div>
</div>
</div>
<h3 id="payment-processing-implementation">Payment Processing Implementation</h3>
<pre><code class="language-python">class PaymentService:
    &quot;&quot;&quot;
    Production payment processing with failure handling.

    Key Principle: Never trap a car. Revenue recovery is a business
    process problem, not a gate control problem.
    &quot;&quot;&quot;

    def __init__(self, stripe: StripeClient, db: Database, cache: Redis):
        self.stripe = stripe
        self.db = db
        self.cache = cache

    def calculate_fee(
        self,
        lot_id: str,
        entry_time: datetime,
        exit_time: datetime,
        spot_type: str,
        validations: List[Validation] = None
    ) -&gt; ParkingFee:
        &quot;&quot;&quot;
        Calculate parking fee with multiple rate structures.

        Rate structures:
        1. Hourly rate with daily max
        2. Time-of-day pricing (peak/off-peak)
        3. Event-based surge pricing
        4. Validation discounts (business validation)
        &quot;&quot;&quot;
        lot = self.db.get_lot(lot_id)
        duration = exit_time - entry_time
        hours = duration.total_seconds() / 3600

        # Get applicable rate based on time of entry
        rate = self._get_applicable_rate(lot_id, entry_time)

        # Calculate base fee
        if hours &lt;= 0.5:
            # Grace period or minimum charge
            base_fee = lot.minimum_charge
        elif hours &lt;= 1:
            base_fee = rate.hourly_rate
        else:
            # Hourly rate with daily cap
            base_fee = min(
                rate.hourly_rate * math.ceil(hours),
                rate.daily_max
            )

        # Apply spot type multiplier (EV, premium spots)
        spot_multiplier = self._get_spot_multiplier(spot_type)
        fee_after_spot = base_fee * spot_multiplier

        # Apply validation discounts
        discount = self._calculate_validation_discount(validations, fee_after_spot)
        final_fee = max(0, fee_after_spot - discount)

        return ParkingFee(
            base_amount=base_fee,
            spot_adjustment=fee_after_spot - base_fee,
            discount=discount,
            final_amount=final_fee,
            breakdown={
                'duration_hours': hours,
                'rate_type': rate.rate_type,
                'spot_type': spot_type,
                'validations_applied': [v.id for v in (validations or [])]
            }
        )

    async def process_exit_payment(
        self,
        ticket_id: str,
        payment_method: str,  # 'card', 'mobile', 'cash', 'account'
        payment_details: Dict
    ) -&gt; PaymentResult:
        &quot;&quot;&quot;
        Process payment at exit with comprehensive failure handling.

        Critical: Gate should open regardless of payment outcome.
        &quot;&quot;&quot;
        ticket = await self.db.get_ticket(ticket_id)

        if ticket.status == 'PAID':
            # Already paid (mobile pre-pay or duplicate request)
            return PaymentResult(success=True, already_paid=True)

        fee = self.calculate_fee(
            ticket.lot_id,
            ticket.entry_time,
            datetime.now(),
            ticket.spot_type,
            ticket.validations
        )

        # Generate idempotency key for payment processor
        idempotency_key = f&quot;parking-{ticket_id}-{fee.final_amount}&quot;

        try:
            if payment_method == 'card':
                result = await self._process_card_payment(
                    payment_details['card_token'],
                    fee.final_amount,
                    idempotency_key
                )
            elif payment_method == 'mobile':
                result = await self._process_mobile_payment(
                    payment_details['user_id'],
                    fee.final_amount,
                    idempotency_key
                )
            elif payment_method == 'account':
                # Monthly parker or business account
                result = await self._charge_account(
                    payment_details['account_id'],
                    fee.final_amount
                )
            else:
                # Cash - assume success, reconcile later
                result = PaymentProcessorResult(success=True, method='cash')

            if result.success:
                await self._finalize_successful_payment(ticket, fee, result)
            else:
                await self._handle_failed_payment(ticket, fee, result)

            # ALWAYS signal gate to open
            return PaymentResult(
                success=result.success,
                fee=fee,
                gate_action='OPEN',  # Always open
                follow_up_required=not result.success
            )

        except PaymentProcessorError as e:
            # Payment processor down - let them go, invoice later
            await self._create_pending_invoice(ticket, fee, str(e))

            return PaymentResult(
                success=False,
                fee=fee,
                gate_action='OPEN',  # Still open
                follow_up_required=True,
                error_message='Payment processor unavailable. Invoice will be sent.'
            )

    async def _handle_failed_payment(
        self,
        ticket: Ticket,
        fee: ParkingFee,
        result: PaymentProcessorResult
    ):
        &quot;&quot;&quot;
        Handle declined cards, insufficient funds, etc.

        Strategy: Flag the license plate, allow exit, recover via invoice.
        &quot;&quot;&quot;
        # Record failed attempt
        await self.db.execute(&quot;&quot;&quot;
            INSERT INTO payment_attempts (ticket_id, amount, status, error_code, timestamp)
            VALUES (%s, %s, 'FAILED', %s, NOW())
        &quot;&quot;&quot;, (ticket.id, fee.final_amount, result.error_code))

        # Create invoice for recovery
        invoice = await self._create_pending_invoice(ticket, fee, result.error_message)

        # Flag license plate for future attention
        await self._flag_license_plate(
            ticket.license_plate,
            'PAYMENT_FAILED',
            invoice.id
        )

        # After N failures, add to &quot;require prepayment&quot; list
        failure_count = await self._get_failure_count(ticket.license_plate)
        if failure_count &gt;= 3:
            await self._add_to_prepayment_required_list(ticket.license_plate)
</code></pre>
<h3 id="payment-processing-interview-questions-3-levels-deep">Payment Processing Interview Questions (3 Levels Deep)</h3>
<div>
<h4>Level 1: How would you design payment processing for a parking system?</h4>
<p><strong>Answer:</strong> Payment processing involves three stages: (1) <span>fee calculation</span> based on parking duration and rate rules, (2) <span>payment collection</span> via multiple channels (kiosk, mobile app, account billing), and (3) <span>transaction recording</span> for audit and reconciliation. The core principle is separation of concerns - the parking session (ticket creation, spot occupancy) is independent from payment status. This allows flexibility in when and how payment occurs. For implementation, I'd use a payment gateway like Stripe with <span>idempotency keys</span> to handle retries safely, and maintain a separate invoice system for failed payment recovery.</p>
<div>
<h5>Level 2: How do you handle payment failures at the exit gate?</h5>
<p><strong>Answer:</strong> The cardinal rule is <span>never trap a car</span>. Traffic flow is more important than immediate payment collection. Implementation: (1) Attempt payment normally. (2) If declined, offer retry or alternative payment method. (3) If all attempts fail, capture the license plate via LPR, create an invoice record, and open the gate anyway. (4) Flag the license plate in the system for future attention. (5) Send invoice via mail to registered address (via DMV lookup for repeat offenders). For frequent visitors, after 2-3 failures, add them to a "prepayment required" list where the system demands payment before entry on future visits. The business accepts that some small percentage of parking fees will require collection effort - this is normal accounts receivable, not a gate control problem. See [[rate-limiting]](/topics/system-design/rate-limiting) for patterns on handling abuse.</p>
<div>
<h6>Level 3: How would you handle payment processing during a complete network outage?</h6>
<p><strong>Answer:</strong> Network outages require <span>offline-first payment design</span>. Implementation layers: (1) <span>Local POS terminals</span> with store-and-forward capability - they process cards locally using cached card network rules and batch transactions when connectivity returns. (2) <span>Edge controller fee calculation</span> - all rate rules are cached locally so fee can be computed without cloud. (3) <span>Offline ticket storage</span> - entry times stored locally with unique ticket IDs that sync later. (4) <span>Cash fallback</span> - always accept cash at kiosk; cash reconciliation happens during shift close. (5) <span>Event log for reconciliation</span> - every payment event (attempted, succeeded, failed) is logged locally with timestamp and synced to cloud when connectivity returns. The cloud system processes these events idempotently, handling potential duplicates from retry storms. Critical edge case: if outage lasts multiple days, some tickets may exit without any record - accept this as cost of doing business, flag via entry/exit counter discrepancy. This pattern is similar to [[event-sourcing]](/topics/system-design/event-sourcing) where local events are the source of truth and cloud reconstructs state from event replay.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-4-real-time-availability">Section 4: Real-Time Availability</h2>
<h3 id="deep-mechanics-3">Deep Mechanics</h3>
<p><span>Real-time availability</span> provides drivers with current parking capacity information through mobile apps, display boards, and navigation systems. The key challenge is balancing <span>data freshness</span> against <span>system load</span> and <span>infrastructure cost</span>.</p>
<div>
<h4>Availability Update Strategies</h4>
<div>
<div>
<strong>Push (WebSocket)</strong>
<p>Server pushes updates on change. Lowest latency but requires persistent connections. Best for mobile apps.</p>
</div>
<div>
<strong>Poll (HTTP)</strong>
<p>Client requests every N seconds. Simple, stateless, cacheable. Best for display boards and low-priority clients.</p>
</div>
<div>
<strong>Hybrid</strong>
<p>Poll for background, push for active navigation. Balances resource usage with UX requirements.</p>
</div>
</div>
</div>
<h3 id="real-time-availability-architecture">Real-Time Availability Architecture</h3>
<div>
<h4>AVAILABILITY SYNC ARCHITECTURE</h4>
  <!-- Event Sources -->
<div>
<div>EVENT SOURCES</div>
<div>
<div>
<div>Entry/Exit Events</div>
<div>Counter increment/decrement</div>
</div>
<div>
<div>Spot Sensor Events</div>
<div>Per-spot occupancy</div>
</div>
<div>
<div>Reservation Events</div>
<div>Future capacity impact</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Redis Cache Layer -->
<div>
<div>REDIS CACHE (Source of Truth for Reads)</div>
<div>
<div>
<div>Aggregate Counts</div>
<div>
  lot:{id}:available = 234<br/>
  lot:{id}:total = 500<br/>
  lot:{id}:level:1:available = 45
</div>
</div>
<div>
<div>By Type Breakdown</div>
<div>
  lot:{id}:type:COMPACT = 78<br/>
  lot:{id}:type:REGULAR = 110<br/>
  lot:{id}:type:EV = 12
</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Distribution Layer -->
<div>
<div>DISTRIBUTION CHANNELS</div>
<div>
<div>
<div>WebSocket</div>
<div>Mobile apps (real-time)</div>
</div>
<div>
<div>REST API</div>
<div>Third-party integrations</div>
</div>
<div>
<div>Display Protocol</div>
<div>LED boards (5s poll)</div>
</div>
<div>
<div>Maps API</div>
<div>Google/Apple integration</div>
</div>
</div>
</div>
</div>
<h3 id="real-time-availability-implementation">Real-Time Availability Implementation</h3>
<pre><code class="language-python">class AvailabilityService:
    &quot;&quot;&quot;
    Real-time availability tracking with multiple update channels.

    Architecture:
    - Redis is the primary read store (fast, atomic operations)
    - PostgreSQL is the source of truth (recovery, reporting)
    - Updates flow: Event -&gt; Redis (atomic) -&gt; Subscribers
    &quot;&quot;&quot;

    def __init__(self, redis: Redis, db: Database, pubsub: PubSub):
        self.redis = redis
        self.db = db
        self.pubsub = pubsub

    async def handle_occupancy_change(self, event: OccupancyEvent):
        &quot;&quot;&quot;
        Process spot status change and update all availability views.

        Uses Redis atomic operations to prevent race conditions.
        &quot;&quot;&quot;
        lot_id = event.lot_id
        delta = -1 if event.new_status == 'OCCUPIED' else 1

        # Atomic updates using Redis pipeline
        pipe = self.redis.pipeline()

        # Update total availability
        pipe.incrby(f&quot;lot:{lot_id}:available&quot;, delta)

        # Update level-specific count
        if event.level_id:
            pipe.incrby(f&quot;lot:{lot_id}:level:{event.level_id}:available&quot;, delta)

        # Update type-specific count
        if event.spot_type:
            pipe.incrby(f&quot;lot:{lot_id}:type:{event.spot_type}:available&quot;, delta)

        # Execute all updates atomically
        await pipe.execute()

        # Publish change notification for real-time subscribers
        await self._publish_availability_update(lot_id)

        # Async write to PostgreSQL for durability
        asyncio.create_task(self._persist_to_db(event))

    async def get_availability(self, lot_id: str) -&gt; AvailabilitySnapshot:
        &quot;&quot;&quot;
        Get current availability from Redis cache.

        Returns comprehensive breakdown for different use cases:
        - Total counts for display boards
        - By-level for in-lot navigation
        - By-type for app filtering
        &quot;&quot;&quot;
        pipe = self.redis.pipeline()

        pipe.get(f&quot;lot:{lot_id}:available&quot;)
        pipe.get(f&quot;lot:{lot_id}:total&quot;)
        pipe.hgetall(f&quot;lot:{lot_id}:levels&quot;)
        pipe.hgetall(f&quot;lot:{lot_id}:types&quot;)

        available, total, levels, types = await pipe.execute()

        return AvailabilitySnapshot(
            lot_id=lot_id,
            total_spots=int(total or 0),
            available_spots=int(available or 0),
            occupancy_rate=1 - (int(available or 0) / int(total or 1)),
            by_level={k: int(v) for k, v in (levels or {}).items()},
            by_type={k: int(v) for k, v in (types or {}).items()},
            last_updated=datetime.now()
        )

    async def _publish_availability_update(self, lot_id: str):
        &quot;&quot;&quot;
        Publish availability change to all subscribers.

        Subscribers include:
        - WebSocket connections (mobile apps)
        - Display board controllers
        - Navigation system integrations
        &quot;&quot;&quot;
        availability = await self.get_availability(lot_id)

        message = {
            'type': 'availability_update',
            'lot_id': lot_id,
            'data': availability.to_dict(),
            'timestamp': datetime.now().isoformat()
        }

        # Publish to Redis pub/sub for WebSocket servers
        await self.pubsub.publish(f&quot;lot:{lot_id}:updates&quot;, json.dumps(message))

        # Check if significant change (for display boards, threshold updates only)
        if self._is_significant_change(lot_id, availability):
            await self.pubsub.publish(f&quot;displays:{lot_id}&quot;, json.dumps(message))

    def _is_significant_change(self, lot_id: str, availability: AvailabilitySnapshot) -&gt; bool:
        &quot;&quot;&quot;
        Determine if change is significant enough for display update.

        Display boards don't need every single-spot change.
        Update when: lot fills up, lot empties, crosses threshold (10, 5, 0 spots).
        &quot;&quot;&quot;
        thresholds = [0, 5, 10, 50]  # Alert levels

        previous = self.redis.get(f&quot;lot:{lot_id}:last_display_available&quot;)
        current = availability.available_spots

        if previous is None:
            return True

        previous = int(previous)

        # Check if crossed a threshold
        for threshold in thresholds:
            if (previous &gt; threshold &gt;= current) or (previous &lt;= threshold &lt; current):
                self.redis.set(f&quot;lot:{lot_id}:last_display_available&quot;, current)
                return True

        return False
</code></pre>
<h3 id="real-time-availability-interview-questions-3-levels-deep">Real-Time Availability Interview Questions (3 Levels Deep)</h3>
<div>
<h4>Level 1: How would you show real-time parking availability?</h4>
<p><strong>Answer:</strong> Real-time availability requires a <span>fast read store</span> (Redis) updated by entry/exit events. When a vehicle enters, we atomically decrement the available count; when it exits, we increment. This count is served to various channels: REST API for on-demand queries, WebSocket for mobile apps with live updates, and polling endpoints for display boards. The key is using <span>atomic operations</span> (Redis INCR/DECR) to prevent race conditions when multiple vehicles enter/exit simultaneously. For display boards in the lot, simple HTTP polling every 5-10 seconds is sufficient - they don't need sub-second updates.</p>
<div>
<h5>Level 2: How do you ensure availability data doesn't drift from actual occupancy over time?</h5>
<p><strong>Answer:</strong> Drift occurs when entry/exit events are missed or processed incorrectly. Mitigation strategies: (1) <span>Periodic reconciliation</span> - compare Redis counts against database ticket records (open tickets = occupied spots). (2) <span>Per-spot sensor validation</span> - if you have per-spot sensors, aggregate their data and compare with counter-based availability. (3) <span>Manual correction interface</span> for lot attendants to adjust counts after visual verification. (4) <span>Event logging</span> - log every increment/decrement with timestamp so you can audit drift sources. (5) <span>Scheduled recounts</span> - during low-traffic hours (2-4 AM), reset counters to match actual sensor state or manual count. The key insight is that small drift (1-2 spots) is acceptable and self-correcting over time; large drift indicates a systematic bug that needs investigation.</p>
<div>
<h6>Level 3: How would you scale real-time availability updates to support 10,000 concurrent mobile app users per lot?</h6>
<p><strong>Answer:</strong> Scaling to 10K concurrent connections requires <span>connection multiplexing</span> and <span>intelligent update throttling</span>. Architecture: (1) Use <span>Redis Pub/Sub</span> as the distribution backbone - availability service publishes changes, multiple WebSocket servers subscribe. (2) WebSocket servers are horizontally scaled behind a load balancer with sticky sessions (by lot_id). (3) <span>Throttle updates</span> - aggregate changes over 500ms windows before pushing to clients. A lot with 500 spots might have 100 changes per minute at peak, but clients don't need every individual update. (4) <span>Smart client reconnection</span> - if client disconnects and reconnects, fetch current state via HTTP, then resume WebSocket subscription (no guaranteed delivery of missed messages). (5) <span>CDN caching</span> for HTTP polling endpoints with 5-second TTL - reduces origin load for clients that fall back from WebSocket. (6) Consider <span>geographic sharding</span> if lots are spread across regions - each region has its own Redis cluster and WebSocket fleet. For reference, see [[cdn]](/topics/system-design/cdn) for caching strategies and [[api-gateway]](/topics/system-design/api-gateway) for request distribution patterns.</p>
</div>
</div>
</div>
<hr />
<h2 id="section-5-dynamic-pricing-strategies">Section 5: Dynamic Pricing Strategies</h2>
<h3 id="deep-mechanics-4">Deep Mechanics</h3>
<p><span>Dynamic pricing</span> adjusts parking rates based on demand, time, and external factors to maximize revenue and optimize utilization. The core challenge is balancing <span>revenue optimization</span> against <span>customer fairness perception</span> and <span>operational complexity</span>.</p>
<div>
<h4>Dynamic Pricing Factors</h4>
<div>
<div>
<strong>Occupancy-Based</strong>
<p>Higher prices when lot is>70% full, surge at>90%. Creates natural demand distribution across lots.</p>
</div>
<div>
<strong>Time-Based</strong>
<p>Peak hours (9-6 weekdays) vs off-peak. Early bird specials, evening event pricing.</p>
</div>
<div>
<strong>Event-Based</strong>
<p>Integrate with event calendars. Sports games, concerts trigger surge pricing for nearby lots.</p>
</div>
<div>
<strong>Duration-Based</strong>
<p>Encourage turnover with progressive rates. First hour cheap, subsequent hours progressively more expensive.</p>
</div>
</div>
</div>
<h3 id="dynamic-pricing-architecture">Dynamic Pricing Architecture</h3>
<div>
<h4>DYNAMIC PRICING ENGINE</h4>
  <!-- Input Signals -->
<div>
<div>PRICING SIGNALS</div>
<div>
<div>
<div>Current Occupancy</div>
<div>Real-time from Redis</div>
</div>
<div>
<div>Time of Day</div>
<div>Scheduled rules</div>
</div>
<div>
<div>Event Calendar</div>
<div>External API</div>
</div>
<div>
<div>Historical Data</div>
<div>ML predictions</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Pricing Engine -->
<div>
<div>PRICING CALCULATION ENGINE</div>
<div>
<div>
<div>Base Rate</div>
<div>$3/hour</div>
</div>
<div>
<div>Multipliers</div>
<div>0.8x - 2.5x</div>
</div>
<div>
<div>Caps</div>
<div>Daily max, surge limit</div>
</div>
</div>
</div>
<div>&#8595;</div>
  <!-- Output Channels -->
<div>
<div>
<div>Entry Display</div>
<div>Current rate shown</div>
</div>
<div>
<div>Mobile App</div>
<div>Estimated cost</div>
</div>
<div>
<div>Reservation System</div>
<div>Future pricing</div>
</div>
</div>
</div>
<h3 id="dynamic-pricing-implementation">Dynamic Pricing Implementation</h3>
<pre><code class="language-python">class DynamicPricingService:
    &quot;&quot;&quot;
    Calculate parking rates based on multiple demand signals.

    Philosophy: Dynamic pricing should feel fair to customers.
    - Transparency: Always show current rate before entry
    - Caps: Maximum multiplier prevents gouging
    - Grandfathering: Rate locked at entry, not recalculated at exit
    &quot;&quot;&quot;

    def __init__(self, cache: Redis, db: Database, event_api: EventAPIClient):
        self.cache = cache
        self.db = db
        self.event_api = event_api

    async def calculate_price(
        self,
        lot_id: str,
        arrival_time: datetime,
        expected_duration: timedelta = None
    ) -&gt; PriceQuote:
        &quot;&quot;&quot;
        Calculate price with full transparency on factors.

        Returns quote with breakdown so customer understands pricing.
        &quot;&quot;&quot;
        lot = await self.db.get_lot(lot_id)
        base_rate = lot.base_hourly_rate

        # Gather pricing signals
        occupancy = await self._get_occupancy(lot_id)
        time_factor = self._get_time_factor(arrival_time, lot.time_pricing_rules)
        event_factor = await self._get_event_factor(lot_id, arrival_time)
        demand_factor = await self._get_predicted_demand(lot_id, arrival_time)

        # Calculate multipliers
        multipliers = {
            'occupancy': self._occupancy_multiplier(occupancy),
            'time_of_day': time_factor,
            'events': event_factor,
            'predicted_demand': demand_factor
        }

        # Combined multiplier with cap
        combined_multiplier = 1.0
        for factor, value in multipliers.items():
            combined_multiplier *= value

        # Apply caps for fairness
        combined_multiplier = min(combined_multiplier, lot.max_surge_multiplier)
        combined_multiplier = max(combined_multiplier, lot.min_discount_multiplier)

        final_rate = base_rate * combined_multiplier

        # Calculate estimated total if duration provided
        estimated_total = None
        if expected_duration:
            hours = expected_duration.total_seconds() / 3600
            estimated_total = min(
                final_rate * math.ceil(hours),
                lot.daily_max_rate
            )

        return PriceQuote(
            lot_id=lot_id,
            base_rate=base_rate,
            final_rate=final_rate,
            multiplier=combined_multiplier,
            multiplier_breakdown=multipliers,
            estimated_total=estimated_total,
            daily_max=lot.daily_max_rate,
            valid_until=arrival_time + timedelta(minutes=15),  # Quote expires
            factors_explanation=self._generate_explanation(multipliers)
        )

    def _occupancy_multiplier(self, occupancy_rate: float) -&gt; float:
        &quot;&quot;&quot;
        Higher prices when lot is filling up.

        Thresholds:
        - &lt;50%: 1.0 (base rate)
        - 50-70%: 1.2 (slight premium)
        - 70-90%: 1.5 (high demand)
        - &gt;90%: 2.0 (surge, near capacity)
        &quot;&quot;&quot;
        if occupancy_rate &lt; 0.5:
            return 1.0
        elif occupancy_rate &lt; 0.7:
            return 1.0 + (occupancy_rate - 0.5) * 1.0  # Linear 1.0 to 1.2
        elif occupancy_rate &lt; 0.9:
            return 1.2 + (occupancy_rate - 0.7) * 1.5  # Linear 1.2 to 1.5
        else:
            return 1.5 + (occupancy_rate - 0.9) * 5.0  # Steep 1.5 to 2.0

    def _get_time_factor(
        self,
        arrival_time: datetime,
        rules: List[TimePricingRule]
    ) -&gt; float:
        &quot;&quot;&quot;
        Apply time-based pricing rules.

        Common patterns:
        - Early bird: Enter before 9am = flat rate
        - Peak hours: 9am-6pm weekdays = premium
        - Evening: After 6pm = discount
        - Weekend: Often discounted
        &quot;&quot;&quot;
        hour = arrival_time.hour
        is_weekend = arrival_time.weekday() &gt;= 5

        for rule in rules:
            if rule.matches(hour, is_weekend):
                return rule.multiplier

        return 1.0  # Default

    async def _get_event_factor(self, lot_id: str, arrival_time: datetime) -&gt; float:
        &quot;&quot;&quot;
        Check for nearby events that affect demand.

        Integrates with external event APIs (Ticketmaster, local venues).
        &quot;&quot;&quot;
        lot = await self.db.get_lot(lot_id)

        # Find events within 1km of lot in next 4 hours
        nearby_events = await self.event_api.get_nearby_events(
            lat=lot.latitude,
            lng=lot.longitude,
            radius_km=1,
            start_time=arrival_time,
            end_time=arrival_time + timedelta(hours=4)
        )

        if not nearby_events:
            return 1.0

        # Factor based on event size
        max_attendance = max(e.expected_attendance for e in nearby_events)

        if max_attendance &gt; 50000:  # Major event
            return 2.0
        elif max_attendance &gt; 10000:  # Large event
            return 1.5
        elif max_attendance &gt; 1000:  # Medium event
            return 1.2

        return 1.0

    async def lock_rate_for_ticket(self, ticket_id: str, rate: float):
        &quot;&quot;&quot;
        Lock in the entry rate for a ticket.

        Critical: Customer pays the rate shown at entry, not
        whatever the rate is when they exit. This prevents
        unfair surprises and builds trust.
        &quot;&quot;&quot;
        await self.cache.hset(f&quot;ticket:{ticket_id}&quot;, 'locked_rate', rate)
        await self.cache.hset(f&quot;ticket:{ticket_id}&quot;, 'rate_locked_at', datetime.now().isoformat())
</code></pre>
<h3 id="dynamic-pricing-interview-questions-3-levels-deep">Dynamic Pricing Interview Questions (3 Levels Deep)</h3>
<div>
<h4>Level 1: How would you implement dynamic pricing for parking?</h4>
<p><strong>Answer:</strong> Dynamic pricing adjusts rates based on <span>demand signals</span>: current occupancy, time of day, and special events. Implementation: (1) Define a base hourly rate, (2) Calculate multipliers for each signal (e.g.,>90% occupancy = 2x multiplier), (3) Combine multipliers with caps to prevent extreme pricing, (4) Display the current rate prominently at entry and in apps. The rate shown at entry is <span>locked for that customer's session</span> - they shouldn't be surprised by a different rate at exit. Most lots use simple tiered pricing (peak/off-peak) rather than fully dynamic; true dynamic pricing adds complexity that may not be worth it for smaller operations.</p>
<div>
<h5>Level 2: How do you balance revenue optimization with customer fairness?</h5>
<p><strong>Answer:</strong> Fairness is critical for customer trust and repeat business. Key principles: (1) <span>Transparency</span> - always show the current rate before the customer commits to parking; display price prominently at entrance. (2) <span>Rate locking</span> - the rate at entry is the rate they pay, even if surge pricing kicks in while they're parked. (3) <span>Maximum caps</span> - never exceed 2-3x base rate regardless of demand signals. (4) <span>Daily maximums</span> - even during surge, cap total daily charge. (5) <span>Consistent rules</span> - pricing algorithm is deterministic, not arbitrary. (6) <span>Loyalty benefits</span> - frequent parkers get stable rates or discounts, not surprise surges. The revenue optimization goal is to smooth demand (encourage off-peak usage) not to extract maximum possible revenue from captive customers.</p>
<div>
<h6>Level 3: How would you implement predictive pricing that considers future demand?</h6>
<p><strong>Answer:</strong> Predictive pricing uses <span>machine learning</span> on historical patterns to anticipate demand and price proactively. Implementation: (1) <span>Feature engineering</span> - collect training data including: day of week, hour, weather, nearby event schedules, historical occupancy at that time slot, school calendar, etc. (2) <span>Model training</span> - use time series forecasting (Prophet, ARIMA) or regression models to predict occupancy 1-4 hours ahead. (3) <span>Pricing optimization</span> - given predicted occupancy, calculate optimal price that maximizes revenue * predicted demand (price elasticity curve). (4) <span>A/B testing</span> - run experiments comparing predicted pricing vs. reactive pricing to validate model accuracy. (5) <span>Feedback loop</span> - actual occupancy feeds back into model retraining. Edge cases: Model performs poorly for unprecedented events (new venue opens, road closure) - need manual override capability. Also, be careful with <span>price anchoring</span>: if customers see $5 rate at 8am but it jumps to $8 at 9am, they may defer arrival and create artificial demand spikes. Consider graduated increases rather than step functions. This is similar to airline yield management but with shorter decision windows.</p>
</div>
</div>
</div>
<hr />
<h2 id="data-model">Data Model</h2>
<div>
<h4>PARKING LOT DATA MODEL</h4>
  <!-- Entity Relationships Diagram -->
<div>
<div>ENTITY RELATIONSHIPS</div>
<div>
  <!-- ParkingLot Entity -->
<div>
<span>ParkingLot (1)</span>
</div>
<div>
<div>&#8595;</div>
<span>has many</span>
<div>&#8595;</div>
</div>
  <!-- Level Entity -->
<div>
<span>Level (M)</span>
</div>
<div>
<div>&#8595;</div>
<span>contains</span>
<div>&#8595;</div>
</div>
  <!-- Spot Entity -->
<div>
<span>Spot (M)</span>
</div>
<div>
<div>&#8595;</div>
<span>linked via</span>
<div>&#8595;</div>
</div>
  <!-- Ticket Entity -->
<div>
<span>Ticket</span>
</div>
<div>
<div>&#8595;</div>
<span>belongs to</span>
<div>&#8595;</div>
</div>
  <!-- Vehicle Entity -->
<div>
<span>Vehicle</span>
</div>
</div>
</div>
  <!-- Tables Schema -->
<div>
<div>
<div>parking_lots</div>
<div>id, name, address, total_spots, lat, lng, base_hourly_rate, daily_max_rate, max_surge_multiplier</div>
</div>
<div>
<div>levels</div>
<div>id, lot_id, floor_number, name, total_spots</div>
</div>
<div>
<div>spots</div>
<div>id, level_id, spot_number, spot_type, status, sensor_id, distance_to_entrance</div>
<div>type: COMPACT, REGULAR, LARGE, HANDICAP, EV</div>
<div>status: AVAILABLE, OCCUPIED, RESERVED, MAINTENANCE</div>
</div>
<div>
<div>tickets</div>
<div>id, lot_id, spot_id, vehicle_id, entry_time, exit_time, status, locked_rate, amount_due, amount_paid</div>
</div>
<div>
<div>vehicles</div>
<div>id, license_plate, vehicle_type, owner_id, payment_method_id</div>
</div>
<div>
<div>reservations</div>
<div>id, spot_id, user_id, start_time, end_time, status, prepaid_amount</div>
</div>
</div>
</div>
<hr />
<h2 id="aws-technologies--alternatives">AWS Technologies &amp; Alternatives</h2>
<div>
<table>
<thead>
<tr>
<th>Component</th>
<th>AWS Service</th>
<th>Alternative</th>
<th>Trade-offs</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Database</strong></td>
<td>Aurora PostgreSQL</td>
<td>CockroachDB, Supabase</td>
<td>Aurora: Managed, multi-AZ. CockroachDB: Multi-region active-active</td>
</tr>
<tr>
<td><strong>Cache</strong></td>
<td>ElastiCache Redis</td>
<td>Redis Cloud, KeyDB</td>
<td>ElastiCache: Simpler ops. Redis Cloud: Better georeplication</td>
</tr>
<tr>
<td><strong>IoT</strong></td>
<td>IoT Core</td>
<td>HiveMQ, EMQX</td>
<td>IoT Core: Managed, integrates with Lambda. Self-hosted: More control</td>
</tr>
<tr>
<td><strong>ML (LPR)</strong></td>
<td>Rekognition</td>
<td>OpenALPR, PlateMania</td>
<td>Rekognition: Managed, pay-per-use. OpenALPR: On-prem, lower latency</td>
</tr>
<tr>
<td><strong>Events</strong></td>
<td>EventBridge + SNS</td>
<td>Kafka, RabbitMQ</td>
<td>EventBridge: Serverless. Kafka: Higher throughput, more complex</td>
</tr>
<tr>
<td><strong>WebSocket</strong></td>
<td>API Gateway WebSocket</td>
<td>Socket.io, Ably</td>
<td>API Gateway: Managed, scales. Socket.io: More features, self-managed</td>
</tr>
<tr>
<td><strong>Edge Computing</strong></td>
<td>Greengrass</td>
<td>Azure IoT Edge, Balena</td>
<td>Greengrass: AWS ecosystem. Balena: Simpler container deployment</td>
</tr>
</tbody>
</table>
</div>
<hr />
<h2 id="when-simpler-solutions-work">When Simpler Solutions Work</h2>
<div>
<div>
<h3 id="the-100month-parking-system">The &quot;$100/Month Parking System&quot;</h3>
<pre><code>**Reality Check**: Most parking lots in the world run on incredibly simple systems.

```python
# This is literally how many successful parking lots work:

class SimpleParking:
def __init__(self, total_spots):
self.total_spots = total_spots
self.occupied = 0

def car_enters(self):
if self.occupied &lt; self.total_spots:
self.occupied += 1
return True  # Open gate
return False  # Lot full

def car_exits(self):
self.occupied -= 1
return calculate_fee(entry_time)

# Cost: One counter variable
# Infrastructure: Entry sensor + Exit sensor + Gate
# Payment: Cash box or basic card terminal
# Monthly cost: ~$100 for payment processing
```
</code></pre>
<h3 id="when-you-dont-need-iot-sensors">When You DON'T Need IoT Sensors</h3>
<pre><code>| Skip Per-Spot Sensors When... | Why |
|-------------------------------|-----|
| Lot has &lt;100 spots | Visual scanning is faster than app lookup |
| No &quot;find my car&quot; requirement | Counters per level are sufficient |
| Budget is limited | Sensors cost $50-150 per spot |
| Retrofitting old structure | Wiring costs exceed sensor benefits |
| Short average stay (&lt;2 hours) | High turnover makes spot-finding less critical |
</code></pre>
<h3 id="when-you-dont-need-dynamic-pricing">When You DON'T Need Dynamic Pricing</h3>
<pre><code>| Skip Dynamic Pricing When... | Why |
|------------------------------|-----|
| Predictable demand patterns | Peak/off-peak flat rates work fine |
| Single use case (office parking) | All-day rates simpler to understand |
| Customer base expects stability | Seniors, regulars dislike variable pricing |
| Implementation cost &gt; revenue gain | Small lots won't see meaningful lift |
</code></pre>
<h3 id="simpler-alternatives-that-work">Simpler Alternatives That Work</h3>
<pre><code>| Complex Solution | Simpler Alternative | When Simple Wins |
|-----------------|---------------------|------------------|
| ML-based LPR | QR code tickets | &lt;1000 cars/day, budget constraints |
| Dynamic pricing algorithm | Peak/off-peak flat rates | Predictable demand patterns |
| Per-spot sensors | Floor-level counters | Any lot without premium features |
| Microservices architecture | Django monolith | Single location, &lt;10 developers |
| Real-time WebSocket updates | 30-second polling | Display boards, non-critical |
| Distributed Redis cache | PostgreSQL with indices | &lt;1000 concurrent users |
</code></pre>
</div>
</div>
<hr />
<h2 id="trade-off-analysis-summary">Trade-off Analysis Summary</h2>
<div>
<div>
<h3 id="critical-trade-offs-matrix">Critical Trade-offs Matrix</h3>
<div>
<div>PARKING SYSTEM TRADE-OFFS</div>
<div>
  <!-- Row 1 -->
<div>
<div>Trade-off</div>
<div>Option A</div>
<div>Option B</div>
<div>Decision Factor</div>
</div>
<div>
<div><span>Sensor Granularity</span></div>
<div>Per-spot sensors ($50-150/spot)</div>
<div>Entry/exit counters ($500 total)</div>
<div>Need "find my car" feature?</div>
</div>
<div>
<div><span>Concurrency Control</span></div>
<div>Database locks (simple)</div>
<div>Redis distributed locks (fast)</div>
<div>>1000 TPS bookings?</div>
</div>
<div>
<div><span>Offline Capability</span></div>
<div>Cloud-dependent (simpler)</div>
<div>Edge-first (resilient)</div>
<div>Internet reliability at location?</div>
</div>
<div>
<div><span>Pricing Model</span></div>
<div>Static rates (predictable)</div>
<div>Dynamic pricing (optimized)</div>
<div>Variable demand patterns?</div>
</div>
<div>
<div><span>Payment Timing</span></div>
<div>Pay on exit (simple)</div>
<div>Pre-registration (reduced exit time)</div>
<div>Exit queue congestion problem?</div>
</div>
</div>
</div>
</div>
</div>
<hr />
<h2 id="interview-tips">Interview Tips</h2>
<div>
<h3 id="key-discussion-points">Key Discussion Points</h3>
<ol>
<li><strong>Spot allocation strategies</strong>: Different approaches for different use cases (nearest entrance vs. distributed load vs. preserve larger spots)</li>
<li><strong>Sensor trade-offs</strong>: Per-spot vs. entry/exit counters - most lots don't need per-spot tracking</li>
<li><strong>Payment resilience</strong>: Never trap a car; revenue recovery is a business process, not a gate control problem</li>
<li><strong>Real-time sync</strong>: Event-driven updates with atomic Redis operations; polling for displays</li>
<li><strong>Offline operation</strong>: Edge controllers with event sourcing for resilience</li>
<li><strong>Dynamic pricing</strong>: Occupancy + time + events, but acknowledge most lots use flat rates</li>
</ol>
<h3 id="red-flags-to-avoid">Red Flags to Avoid</h3>
<table>
<thead>
<tr>
<th>Red Flag</th>
<th>Why It's Bad</th>
<th>Better Approach</th>
</tr>
</thead>
<tbody>
<tr>
<td>&quot;We need per-spot IoT sensors everywhere&quot;</td>
<td>Over-engineering for most use cases</td>
<td>&quot;Entry/exit counters work for most lots&quot;</td>
</tr>
<tr>
<td>&quot;Microservices from day one&quot;</td>
<td>Premature complexity</td>
<td>&quot;Start monolithic, extract when needed&quot;</td>
</tr>
<tr>
<td>&quot;ML-based dynamic pricing from launch&quot;</td>
<td>Most lots use simple rules</td>
<td>&quot;Peak/off-peak rates, surge during events&quot;</td>
</tr>
<tr>
<td>&quot;Blockchain for payments&quot;</td>
<td>No actual benefit</td>
<td>&quot;Standard payment gateway with idempotency&quot;</td>
</tr>
<tr>
<td>&quot;Block cars on payment failure&quot;</td>
<td>Creates operational chaos</td>
<td>&quot;Flag plate, invoice later, let car exit&quot;</td>
</tr>
<tr>
<td>Ignoring offline scenarios</td>
<td>Lots must operate without cloud</td>
<td>&quot;Edge controller with local fallback&quot;</td>
</tr>
</tbody>
</table>
<h3 id="impressive-statements">Impressive Statements</h3>
<blockquote>
<p>&quot;Most parking lots just need a counter at entry/exit - no per-spot tracking. I'd start there and add complexity only when the business case justifies the sensor investment.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;The cardinal rule of parking payments is: never trap a car. Revenue recovery is an accounts receivable problem, not a gate control problem. Let them go, invoice them later.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;I'd design for offline-first operation. The lot should function perfectly with zero cloud connectivity - mobile apps and analytics are nice-to-haves, not requirements.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;For concurrency, I'd start with simple database transactions. Redis distributed locks are only needed when we're processing thousands of simultaneous bookings - which most lots never reach.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;Dynamic pricing sounds exciting, but most successful lots use simple peak/off-peak rates. True dynamic pricing adds complexity that often doesn't justify the revenue improvement.&quot;</p>
</blockquote>
<h3 id="related-topics">Related Topics</h3>
<ul>
<li><a href="/topics/system-design/distributed-locking">[distributed-locking]</a> - Concurrent spot allocation</li>
<li><a href="/topics/system-design/event-sourcing">[event-sourcing]</a> - Offline sync and reconciliation</li>
<li><a href="/topics/system-design/rate-limiting">[rate-limiting]</a> - Preventing reservation abuse</li>
<li><a href="/topics/system-design/api-gateway">[api-gateway]</a> - Multi-channel API management</li>
<li><a href="/topics/system-design/cdn">[cdn]</a> - Caching availability data</li>
<li><a href="/topics/system-design/connection-pooling">[connection-pooling]</a> - Resource management patterns</li>
</ul>
</div>
